# github

## AI

[leptonai](https://github.com/leptonai/leptonai)
A Pythonic framework to simplify AI service building

[landscape2](https://github.com/cncf/landscape2)
Landscape2 is a tool that generates interactive landscapes websites, [sncf](https://landscape.cncf.io/)

## Tools

* [honkit](https://github.com/honkit/honkit)
* [ml-interviews-book](https://github.com/chiphuyen/ml-interviews-book)

## Triton

OpenAI [triton](https://github.com/openai/triton)

[Document](https://triton-lang.org/master/index.html)

```
      AST/Visitor     Triton/Compiler      libLLVM
Python --------> Triton-IR ------> LLVM-IR ------> PTX
```


## Lightning

[lightning](https://github.com/Lightning-AI/lightning)

## Fairscale

[fairscale](https://github.com/facebookresearch/fairscale)

## PEFT

[huggingface peft](https://github.com/huggingface/peft)

[Blog](https://huggingface.co/blog/peft)

PEFT approaches enable you to get performance comparable to full fine-tuning while only having a small number of trainable parameters.

Methods:

* LoRA: LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
* Prefix Tuning: P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks
* Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning
* P-Tuning: GPT Understands, Too


