<!DOCTYPE HTML>
<html lang="en" class="latte" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>dataloader - Aller au boulot</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="Projects excelling">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href=".././theme/catppuccin.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "latte";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('latte')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item affix "><a href="../index.html">welcome</a></li><li class="chapter-item affix "><li class="part-title">Hello World</li><li class="chapter-item affix "><li class="part-title">Open Source</li><li class="chapter-item "><a href="../vllm/overview.html"><strong aria-hidden="true">1.</strong> vllm</a></li><li class="chapter-item "><a href="../pytorch/overview.html"><strong aria-hidden="true">2.</strong> pytorch</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../pytorch/torchrun.html"><strong aria-hidden="true">2.1.</strong> torchrun</a></li><li class="chapter-item "><a href="../pytorch/tensor.html"><strong aria-hidden="true">2.2.</strong> tensor</a></li><li class="chapter-item "><a href="../pytorch/autograd.html"><strong aria-hidden="true">2.3.</strong> autograd</a></li><li class="chapter-item "><a href="../pytorch/operator.html"><strong aria-hidden="true">2.4.</strong> operator</a></li><li class="chapter-item "><a href="../pytorch/profiler.html"><strong aria-hidden="true">2.5.</strong> profiler</a></li><li class="chapter-item "><a href="../pytorch/hook.html"><strong aria-hidden="true">2.6.</strong> hook</a></li><li class="chapter-item "><a href="../pytorch/elastic.html"><strong aria-hidden="true">2.7.</strong> elastic</a></li><li class="chapter-item "><a href="../pytorch/patch.html"><strong aria-hidden="true">2.8.</strong> patch</a></li><li class="chapter-item "><a href="../pytorch/misc.html"><strong aria-hidden="true">2.9.</strong> misc</a></li></ol></li><li class="chapter-item expanded "><a href="../paddle/paddle.html"><strong aria-hidden="true">3.</strong> paddlepaddle</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../paddle/ps-code-overview.html"><strong aria-hidden="true">3.1.</strong> ps</a></li><li class="chapter-item "><a href="../paddle/framework.html"><strong aria-hidden="true">3.2.</strong> framework</a></li><li class="chapter-item "><a href="../paddle/cinn.html"><strong aria-hidden="true">3.3.</strong> cinn</a></li><li class="chapter-item expanded "><a href="../paddle/dataloader.html" class="active"><strong aria-hidden="true">3.4.</strong> dataloader</a></li></ol></li><li class="chapter-item "><a href="../horovod/horovod.html"><strong aria-hidden="true">4.</strong> horovod</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../horovod/run.html"><strong aria-hidden="true">4.1.</strong> run</a></li><li class="chapter-item "><a href="../horovod/workflow.html"><strong aria-hidden="true">4.2.</strong> workflow</a></li><li class="chapter-item "><a href="../horovod/object.html"><strong aria-hidden="true">4.3.</strong> object</a></li><li class="chapter-item "><a href="../horovod/develop.html"><strong aria-hidden="true">4.4.</strong> develop</a></li><li class="chapter-item "><a href="../horovod/pytorch.html"><strong aria-hidden="true">4.5.</strong> pytorch</a></li><li class="chapter-item "><a href="../horovod/tensorflow.html"><strong aria-hidden="true">4.6.</strong> tensorflow</a></li><li class="chapter-item "><a href="../horovod/elastic.html"><strong aria-hidden="true">4.7.</strong> elastic</a></li></ol></li><li class="chapter-item "><a href="../ray/ray.html"><strong aria-hidden="true">5.</strong> ray</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../ray/overview.html"><strong aria-hidden="true">5.1.</strong> overview</a></li><li class="chapter-item "><a href="../ray/gcs.html"><strong aria-hidden="true">5.2.</strong> gcs</a></li><li class="chapter-item "><a href="../ray/raylet.html"><strong aria-hidden="true">5.3.</strong> raylet</a></li><li class="chapter-item "><a href="../ray/api.html"><strong aria-hidden="true">5.4.</strong> api</a></li><li class="chapter-item "><a href="../ray/survey.html"><strong aria-hidden="true">5.5.</strong> survey</a></li></ol></li><li class="chapter-item "><a href="../somewhat/llama.html"><strong aria-hidden="true">6.</strong> llama</a></li><li class="chapter-item "><a href="../nccl/nccl.html"><strong aria-hidden="true">7.</strong> nccl</a></li><li class="chapter-item "><a href="../megatron/megatron.html"><strong aria-hidden="true">8.</strong> megatron</a></li><li class="chapter-item "><a href="../deepspeed/deepspeed.html"><strong aria-hidden="true">9.</strong> deepspeed</a></li><li class="chapter-item affix "><li class="part-title">Survey</li><li class="chapter-item "><a href="../survey/papers.html"><strong aria-hidden="true">10.</strong> survey</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../survey/pollux.html"><strong aria-hidden="true">10.1.</strong> pollux</a></li><li class="chapter-item "><a href="../survey/adasum.html"><strong aria-hidden="true">10.2.</strong> adasum</a></li><li class="chapter-item "><a href="../survey/adaptation_learning.html"><strong aria-hidden="true">10.3.</strong> adaptation_learning</a></li><li class="chapter-item "><a href="../survey/gradient_descent.html"><strong aria-hidden="true">10.4.</strong> gradient_descent</a></li><li class="chapter-item "><a href="../survey/auto_parallel.html"><strong aria-hidden="true">10.5.</strong> auto_parallel</a></li><li class="chapter-item "><a href="../survey/scheduling.html"><strong aria-hidden="true">10.6.</strong> scheduling</a></li><li class="chapter-item "><a href="../survey/gradient_compression/gradient_compression.html"><strong aria-hidden="true">10.7.</strong> gradient_compression</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../survey/gradient_compression/dgc.html"><strong aria-hidden="true">10.7.1.</strong> dgc</a></li><li class="chapter-item "><a href="../survey/gradient_compression/csc.html"><strong aria-hidden="true">10.7.2.</strong> csc</a></li></ol></li><li class="chapter-item "><a href="../survey/flash_attention.html"><strong aria-hidden="true">10.8.</strong> flash attention</a></li><li class="chapter-item "><a href="../survey/lora.html"><strong aria-hidden="true">10.9.</strong> LoRA</a></li></ol></li><li class="chapter-item "><a href="../llm/models.html"><strong aria-hidden="true">11.</strong> models</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../llm/llm.html"><strong aria-hidden="true">11.1.</strong> llm</a></li><li class="chapter-item "><a href="../llm/falcon.html"><strong aria-hidden="true">11.2.</strong> falcon</a></li><li class="chapter-item "><a href="../llm/llama.html"><strong aria-hidden="true">11.3.</strong> llama</a></li><li class="chapter-item "><a href="../llm/peft.html"><strong aria-hidden="true">11.4.</strong> peft</a></li><li class="chapter-item "><a href="../llm/transformer.html"><strong aria-hidden="true">11.5.</strong> transformer</a></li><li class="chapter-item "><a href="../llm/models.html"><strong aria-hidden="true">11.6.</strong> models</a></li></ol></li><li class="chapter-item "><li class="part-title">Programming</li><li class="chapter-item "><a href="../python/python.html"><strong aria-hidden="true">12.</strong> python</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../python/concurrent.html"><strong aria-hidden="true">12.1.</strong> concurrent execution</a></li><li class="chapter-item "><a href="../python/multiprocessing.html"><strong aria-hidden="true">12.2.</strong> multiprocessing</a></li><li class="chapter-item "><a href="../python/decorator.html"><strong aria-hidden="true">12.3.</strong> decorator</a></li></ol></li><li class="chapter-item "><a href="../golang/index.html"><strong aria-hidden="true">13.</strong> golang</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../tips/golang_error.html"><strong aria-hidden="true">13.1.</strong> golang error</a></li></ol></li><li class="chapter-item "><a href="../cplusplus/index.html"><strong aria-hidden="true">14.</strong> cplusplus</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../tips/enable_shared_from_this.html"><strong aria-hidden="true">14.1.</strong> enable_shared_from_this</a></li></ol></li><li class="chapter-item "><li class="part-title">Mathematics</li><li class="chapter-item "><a href="../mathematics/topics.html"><strong aria-hidden="true">15.</strong> mathematics</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../mathematics/basic.html"><strong aria-hidden="true">15.1.</strong> basic</a></li><li class="chapter-item "><a href="../mathematics/entropy.html"><strong aria-hidden="true">15.2.</strong> entropy</a></li><li class="chapter-item "><a href="../mathematics/newton.html"><strong aria-hidden="true">15.3.</strong> newton</a></li><li class="chapter-item "><a href="../mathematics/regression.html"><strong aria-hidden="true">15.4.</strong> regression</a></li><li class="chapter-item "><a href="../mathematics/conjugate_descent.html"><strong aria-hidden="true">15.5.</strong> conjugate descent</a></li><li class="chapter-item "><a href="../mathematics/gradient_descent.html"><strong aria-hidden="true">15.6.</strong> gradient descent</a></li><li class="chapter-item "><a href="../mathematics/pca.html"><strong aria-hidden="true">15.7.</strong> pca</a></li><li class="chapter-item "><a href="../mathematics/support_vector.html"><strong aria-hidden="true">15.8.</strong> support vector</a></li><li class="chapter-item "><a href="../mathematics/differentiation.html"><strong aria-hidden="true">15.9.</strong> differentiation</a></li><li class="chapter-item "><a href="../mathematics/fourier.html"><strong aria-hidden="true">15.10.</strong> fourier</a></li><li class="chapter-item "><a href="../mathematics/kmeans_cos.html"><strong aria-hidden="true">15.11.</strong> kmeans</a></li></ol></li><li class="chapter-item "><a href="../wavelets/plan.html"><strong aria-hidden="true">16.</strong> wavelets</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../wavelets/plan.html"><strong aria-hidden="true">16.1.</strong> plan</a></li><li class="chapter-item "><a href="../wavelets/preliminary.html"><strong aria-hidden="true">16.2.</strong> preliminary</a></li><li class="chapter-item "><a href="../wavelets/haar.html"><strong aria-hidden="true">16.3.</strong> haar wavelet</a></li><li class="chapter-item "><a href="../wavelets/fourier.html"><strong aria-hidden="true">16.4.</strong> fourier analysis</a></li><li class="chapter-item "><a href="../wavelets/uncertainty_principle.html"><strong aria-hidden="true">16.5.</strong> uncertainty principle</a></li><li class="chapter-item "><a href="../wavelets/multiresolution.html"><strong aria-hidden="true">16.6.</strong> multiresolution</a></li></ol></li><li class="chapter-item "><li class="part-title">Learning Deep</li><li class="chapter-item "><a href="../kubernetes/kubernetes.html"><strong aria-hidden="true">17.</strong> kubernetes</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../kubernetes/concepts.html"><strong aria-hidden="true">17.1.</strong> concepts</a></li><li class="chapter-item "><a href="../kubernetes/scheduler.html"><strong aria-hidden="true">17.2.</strong> scheduler</a></li><li class="chapter-item "><a href="../kubernetes/operator.html"><strong aria-hidden="true">17.3.</strong> operator</a></li><li class="chapter-item "><a href="../kubernetes/device_plugin.html"><strong aria-hidden="true">17.4.</strong> device plugin</a></li><li class="chapter-item "><a href="../kubernetes/docker.html"><strong aria-hidden="true">17.5.</strong> docker</a></li><li class="chapter-item "><a href="../kubernetes/install.html"><strong aria-hidden="true">17.6.</strong> install</a></li><li class="chapter-item "><a href="../kubernetes/api_service.html"><strong aria-hidden="true">17.7.</strong> api-service</a></li><li class="chapter-item "><a href="../kubernetes/controller.html"><strong aria-hidden="true">17.8.</strong> controller</a></li></ol></li><li class="chapter-item "><a href="../nvidia/nvidia.html"><strong aria-hidden="true">18.</strong> cuda</a></li><li class="chapter-item "><a href="../somewhat/todo.html"><strong aria-hidden="true">19.</strong> todo</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../somewhat/gloo.html"><strong aria-hidden="true">19.1.</strong> gloo</a></li><li class="chapter-item "><a href="../somewhat/mpi.html"><strong aria-hidden="true">19.2.</strong> mpi</a></li><li class="chapter-item "><a href="../somewhat/jax.html"><strong aria-hidden="true">19.3.</strong> jax</a></li><li class="chapter-item "><a href="../somewhat/tvm.html"><strong aria-hidden="true">19.4.</strong> tvm</a></li><li class="chapter-item "><a href="../somewhat/github.html"><strong aria-hidden="true">19.5.</strong> llm</a></li></ol></li><li class="chapter-item "><a href="../notes/index.html"><strong aria-hidden="true">20.</strong> notes</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../notes/influence_and_persuasion.html"><strong aria-hidden="true">20.1.</strong> influence and persuasion</a></li><li class="chapter-item "><a href="../notes/feynman_technique.html"><strong aria-hidden="true">20.2.</strong> freynman technique</a></li><li class="chapter-item "><a href="../notes/wavelet_tour_signal_processing_sparse.html"><strong aria-hidden="true">20.3.</strong> wavelet signal processing</a></li></ol></li><li class="chapter-item "><a href="../tips/tips.html"><strong aria-hidden="true">21.</strong> tips</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../tips/ip_local_port_range.html"><strong aria-hidden="true">21.1.</strong> ip_local_port_range</a></li></ol></li><li class="chapter-item "><a href="../infra/overview.html"><strong aria-hidden="true">22.</strong> infrastructure</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../infra/pki.html"><strong aria-hidden="true">22.1.</strong> pki</a></li><li class="chapter-item "><a href="../infra/cache.html"><strong aria-hidden="true">22.2.</strong> linux cache</a></li></ol></li><li class="chapter-item "><a href="../projects/projects.html"><strong aria-hidden="true">23.</strong> projects</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../projects/copilot.html"><strong aria-hidden="true">23.1.</strong> copilot</a></li><li class="chapter-item "><a href="../projects/library.html"><strong aria-hidden="true">23.2.</strong> library</a></li><li class="chapter-item "><a href="../projects/rag.html"><strong aria-hidden="true">23.3.</strong> RAG</a></li></ol></li><li class="chapter-item "><a href="../chronicles/2024mar.html"><strong aria-hidden="true">24.</strong> chronicles</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chronicles/2024feb.html"><strong aria-hidden="true">24.1.</strong> feb 2024</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">Aller au boulot</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/kuizhiqing/aller-au-boulot" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>


                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="dataloader"><a class="header" href="#dataloader">dataloader</a></h1>
<pre><code class="language-python"># python/paddle/io/dataloader/dataloader_iter.py


class _DataLoaderIterBase:
    &quot;&quot;&quot;
    Iterator implement of DataLoader, will load and feed mini-batch
    data by setting in given dataloader.

    Args:
        loader(instance of DataLoader): instance of `paddle.io.DataLoader`
    &quot;&quot;&quot;

    def __init__(self, loader):
        self._dataset = loader.dataset
        self._feed_list = loader.feed_list or []
        self._places = loader.places
        self._return_list = loader.return_list
        self._batch_sampler = loader.batch_sampler
        self._drop_last = loader.drop_last
        self._auto_collate_batch = loader.auto_collate_batch
        self._num_workers = loader.num_workers
        self._use_buffer_reader = loader.use_buffer_reader
        self._prefetch_factor = loader.prefetch_factor
        self._use_shared_memory = loader.use_shared_memory
        self._timeout = (
            loader.timeout if loader.timeout &gt; 0 else MP_STATUS_CHECK_INTERVAL
        )
        self._worker_init_fn = loader.worker_init_fn
        self._dataset_kind = loader.dataset_kind
        self._pin_memory = loader.pin_memory
        # LoDTensorBlockingQueue instance for create_py_reader and a thread
        # to put mini-batch data to self._blocking_queue, mini-batch data
        # will be get from:
        # 1. multi-process mode: get data from workers' result queue
        # 2. single-process mode: read mini-batch data in main process
        self._blocking_queue = None
        self._thread = None
        self._thread_done_event = threading.Event()
</code></pre>
<pre><code class="language-python"># python/paddle/io/dataloader/dataloader_iter.py

class _DataLoaderIterSingleProcess(_DataLoaderIterBase):
    &quot;&quot;&quot;
    Single process implement of DataLoaderIter, loading data from
    loader.data in main process
    &quot;&quot;&quot;

    def __init__(self, loader):
        self._dataset_fetcher = _DatasetKind.create_fetcher(
            self._dataset, ...
        )

        # NOTE: _structrue_infos used to record the data structure of
        # batch to restore batch structure after reading Tensor
        # from blocking_queue in single-process mode. Note that
        # only single process is used in single-process mode, we
        # can record the data structure sequencely in a list without
        # recording the send and recv index
        self._structure_infos = []

        self._blocking_queue_capacity = self._prefetch_factor * len(
            self._places
        )

        self._init_thread()

    def _init_thread(self):
        self._blocking_queue = core.init_lod_tensor_blocking_queue(...)
        self._reader = core.create_py_reader(...)

        self._thread = threading.Thread(
            target=self._thread_loop, args=(_current_expected_place(),)
        )
        self._thread.start()

    def _thread_loop(self, legacy_expected_place):
        while not self._thread_done_event.is_set():
            try:
                indices = next(self._sampler_iter)
                batch = self._dataset_fetcher.fetch(
                    indices, self._thread_done_event
                )

            batch, structure = _flatten_batch(batch)
            try:
                # pack as LoDTensorArray
                array = core.LoDTensorArray()
                for slot in batch:
                    if isinstance(slot, (paddle.Tensor, core.eager.Tensor)):
                        slot = slot.value().get_tensor()
                    elif not isinstance(slot, core.LoDTensor):
                        tmp = core.LoDTensor()
                        tmp.set(slot, core.CPUPlace())
                        slot = tmp

                    array.append(slot)

                try:
                    self._blocking_queue.push(array)

    def __next__(self):
        try:
            if in_dygraph_mode():
                data = core.eager.read_next_tensor_list(
                    self._reader.read_next_list()[0]
                )
                data = _restore_batch(data, self._structure_infos.pop(0))
            else:
                if self._return_list:
                    data = self._reader.read_next_list()
                else:
                    data = self._reader.read_next()
            return data
</code></pre>
<pre><code class="language-python">class _DataLoaderIterMultiProcess(_DataLoaderIterBase):
    def __init__(self, loader):
        super().__init__(loader)

        self._data_queue = None

        self._outstanding_capacity = self._prefetch_factor * max(
            self._num_workers, len(self._places)
        )

        # see _try_put_indices
        self._thread_lock = threading.Lock()
        self._init_workers()
        for _ in range(self._outstanding_capacity):
            self._try_put_indices()

        self._init_thread()

    def _init_workers(self):
        self._data_queue = multiprocessing.Queue()

        for i in range(self._num_workers):
            indices_queue = multiprocessing.Queue()
            self._indices_queues.append(indices_queue)
            worker = multiprocessing.Process( target=_worker_loop, args=(self._dataset, ...),)
            worker.start()
            self._workers.append(worker)

    def _init_thread(self):
        self._blocking_queue = core.init_lod_tensor_blocking_queue(
            core.Variable(), self._outstanding_capacity, len(self._places) &gt; 1
        )
        self._reader = core.create_py_reader(self._blocking_queue, ...)

        self._thread = threading.Thread(
            target=self._thread_loop, args=(_current_expected_place(),)
        )
        self._thread.start()

    def _reset(self):
        # resume iteration in following steps
        # 1. Resume workers, clear worker caches
        # put _ResumeIteration to all worker as resume iteration flag
        with self._thread_lock:
            self._resume_worker_cnt = self._num_workers
            for worker_id in range(self._num_workers):
                self._indices_queues[worker_id].put(_ResumeIteration())
                self._batches_outstanding += 1
        # all flag will be check in _thread_loop, simply wait here
        while self._resume_worker_cnt &gt; 0:
            time.sleep(0.5)

        # 2. clear blocking_queue caches
        # in order not to restart the thread, we just clear
        # the blocking_queue cachees instead of recreating one
        while self._blocking_queue.size() &gt;= len(self._places):
            if in_dygraph_mode():
                data = core.eager.read_next_tensor_list(
                    self._reader.read_next_list()[0]
                )
            else:
                if self._return_list:
                    self._reader.read_next_list()
                else:
                    data = self._reader.read_next()

        # 3. reset all states
        self._send_idx = 0
        self._rcvd_idx = 0
        self._batches_outstanding = 0
        self._task_infos = {}
        self._structure_infos = []

        # set all worker status available
        self._worker_status = [True] * self._num_workers

        # 4. reset _sampler_iter and put prefetch indices to start next epoch
        # init workers and indices queues and put 2 indices in each indices queue
        self._sampler_iter = iter(self._index_sampler)
        for _ in range(self._outstanding_capacity):
            self._try_put_indices()

    def _thread_loop(self, legacy_expected_place):
        while not self._thread_done_event.is_set():
            batch = self._get_data()
            if not self._thread_done_event.is_set():
                    try:
                        # pack as LoDTensorArray
                        array = core.LoDTensorArray()
                        if self._use_shared_memory:
                            for tensor in batch:
                                array.append(tensor)
                        else:
                            # LoDTensor not in shared memory is not
                            # serializable, cannot be create in workers
                            for slot in batch:
                                if isinstance(
                                    slot, (paddle.Tensor, core.eager.Tensor)
                                ):
                                    slot = slot.value().get_tensor()
                                elif not isinstance(slot, core.LoDTensor):
                                    tmp = core.LoDTensor()
                                    tmp.set(slot, core.CPUPlace())
                                    slot = tmp
                                array.append(slot)


                        if not self._blocking_queue.push(array):
                            self._blocking_queue.close()

    def _get_data(self):
        while not self._thread_done_event.is_set():
            # For IterableDataset, batch indices is generated infinitely
            # for each worker to raise StopIteration, but a StopIteration
            # raising process will discard a batch indices which is count
            # in _send_idx but will not increase _rcvd_idx, so we check
            # whether the worker is still alive here to skip the discarded
            # batch indices and increase _rcvd_idx
            if self._dataset_kind == _DatasetKind.ITER:
                while self._rcvd_idx &lt; self._send_idx:
                    info = self._task_infos[self._rcvd_idx]
                    if len(info) == 3 or self._worker_status[info[0]]:
                        break
                    del self._task_infos[self._rcvd_idx]
                    self._rcvd_idx += 1
                    self._batches_outstanding -= 1
                else:
                    # NOTE: when _rcvd_idx catch up _send_idx, which means
                    #       one of following:
                    #       1. all 2 * num_workers batches have been loaded
                    #          and stored in _blocking_queue
                    #       2. all data drained
                    #       we need to let _thread blocking at _data_queue
                    #       get_data to inoccupy CPU, otherwise may occupy
                    #       CPU time for model running
                    # NOTE: in persistent workers mode, do not check data
                    #       drained here, simply let it go to _data_queue
                    #       reading to get _ResumeIteration
                    if not self._persistent_workers:
                        # NOTE: _rcvd_idx and _send_idx only record batches among
                        #       workers, if batches among workers drained, there
                        #       may also be data in blocking queue
                        if self._batches_outstanding &lt; len(self._places):
                            return None

            if (
                self._rcvd_idx in self._task_infos
                and len(self._task_infos[self._rcvd_idx]) == 3
            ):
                info = self._task_infos.pop(self._rcvd_idx)
                self._structure_infos.append(info[2])
                return info[1]

            try:
                # [ avoid hang ]: main process may blocking at _reader.read_next when
                # KeyboardInterrupt, we do following tradeoff:
                # 1. get data with timeout, MP_STATUS_CHECK_INTERVAL(5s) as timeout
                #    default, if KeyboardInterrupt blocking, failed workers will be
                #    checked and raise RuntimeError to quit DataLoader in timeout
                #    exception handling.
                # 2. if get data timeout and check workers all alive, continue to
                #    get data again
                data = self._data_queue.get(timeout=self._timeout)
            except Exception as e:
                # check if thread done event set when waiting data
                if self._thread_done_event.is_set():
                    continue

                # check failed workers
                failed_workers = []
                for i, w in enumerate(self._workers):
                    if self._worker_status[i] and not w.is_alive():
                        failed_workers.append(w)
                        self._shutdown_worker(i)
                if len(failed_workers) &gt; 0:
                    self._exit_thread_unexpectedly()
                    pids = ', '.join(str(w.pid) for w in failed_workers)
                    raise RuntimeError(
                        &quot;DataLoader {} workers exit unexpectedly, &quot;
                        &quot;pids: {}&quot;.format(len(failed_workers), pids)
                    )

                # get(timeout) will call _poll(timeout) and may raise IOError
                if isinstance(e, queue.Empty) or isinstance(e, IOError):
                    # continue on timeout to keep getting data from queue
                    continue

                self._exit_thread_unexpectedly()
                logging.error(
                    &quot;DataLoader reader thread failed({}) to read data from &quot;
                    &quot;workers' result queue.&quot;.format(e)
                )
                raise e
            else:
                if self._dataset_kind == _DatasetKind.ITER and isinstance(
                    data, _IterableDatasetStopIteration
                ):
                    # if a worker get StopIteraion, we shutdown this worker,
                    # note that this batch indices to trigger StopIteration
                    # is discard, outstanding batch number should be decrease
                    # and another indices should be put for other workers
                    # may still working.
                    if self._persistent_workers:
                        self._worker_status[data.worker_id] = False
                    else:
                        self._shutdown_worker(data.worker_id)
                        self._batches_outstanding -= 1
                    self._try_put_indices()
                    continue

                idx, batch, structure = data

                if (
                    isinstance(idx, _ResumeIteration)
                    and batch is None
                    and structure is None
                ):
                    return idx

                if isinstance(batch, _WorkerException):
                    self._exit_thread_unexpectedly()
                    batch.reraise()

                if idx == self._rcvd_idx:
                    del self._task_infos[idx]
                    self._structure_infos.append(structure)
                    return batch
                else:
                    self._task_infos[idx] += (batch, structure)
                    continue

    def _try_put_indices(self):
        assert (
            self._batches_outstanding &lt;= self._outstanding_capacity
        ), &quot;too many indices have been put to queue&quot;
        # In multi-process mode for IterableDataset, _try_put_indices will
        # be called both in main process(for our implement has blocking queue,
        # and blocking queue read is in main process) and thread, which may
        # cause error following error
        #   1. &quot;ValueError: generator already executing&quot; in next(self._sampler_iter)
        #   2. re-enter in increase _send_idx
        # add a lock for threading save, for _try_put_indices is only a slight
        # function which is not in data reading pipeline, this lock almost no
        # influence on performance
        with self._thread_lock:
            try:
                indices = next(self._sampler_iter)
            except StopIteration:
                return

            for i in range(self._num_workers):
                worker_idx = next(self._workers_idx_cycle)
                if self._worker_status[worker_idx]:
                    break
            else:
                return

            self._indices_queues[worker_idx].put((self._send_idx, indices))
            self._task_infos[self._send_idx] = (worker_idx,)
            self._batches_outstanding += 1
            self._send_idx += 1

    def __del__(self):
        self._try_shutdown_all()

    def _shutdown_on_exit(self):
        self._try_shutdown_all(1)

    def __next__(self):
        if in_profiler_mode():
            trace_event = profiler.RecordEvent(
                name=&quot;_DataLoaderIterMultiProcess&quot;,
                event_type=profiler.TracerEventType.Dataloader,
            )
            trace_event.begin()
        try:
            benchmark().check_if_need_record(self)
            benchmark().before_reader()
            # _batches_outstanding here record the total batch data number
            # in 'from after _try_put_indices to beforeoutput data', this
            # value should be _outstanding_capacity if data is not drained,
            # if _batches_outstanding is less than _places number, there are
            # no enough data to generate next output, close blocking_queue and
            # set _thread_done_event here, py_reader will raise StopIteration,
            # end workers and indices_queues in StopIteration handling
            if self._batches_outstanding &lt; len(self._places):
                if self._persistent_workers:
                    raise StopIteration
                else:
                    self._thread_done_event.set()
                    self._blocking_queue.close()

            if in_dygraph_mode():
                data = core.eager.read_next_tensor_list(
                    self._reader.read_next_list()[0]
                )
                data = _restore_batch(data, self._structure_infos.pop(0))
            else:
                if self._return_list:
                    data = self._reader.read_next_list()
                    for i in range(len(data)):
                        data[i] = data[i]._move_to_list()
                    structs = [
                        self._structure_infos.pop(0)
                        for _ in range(len(self._places))
                    ]
                    data = [_restore_batch(d, s) for d, s in zip(data, structs)]
                    # static graph organized data on multi-device with list, if
                    # place number is 1, there is only 1 device, extra the data
                    # from list for devices to be compatible with dygraph mode
                    if len(self._places) == 1:
                        data = data[0]
                else:
                    data = self._reader.read_next()
            self._on_output_batch()
            benchmark().after_reader()
            return data
        except StopIteration:
            if not self._persistent_workers:
                self._reader.shutdown()
                self._try_shutdown_all()
            raise
        finally:
            if in_profiler_mode():
                trace_event.end()

    def _on_output_batch(self):
        for _ in range(len(self._places)):
            self._batches_outstanding -= 1
            self._try_put_indices()
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../paddle/cinn.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../horovod/horovod.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../paddle/cinn.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../horovod/horovod.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>



        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
