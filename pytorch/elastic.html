<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>elastic - Aller au boulot</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Projects excelling">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item "><a href="../index.html"><strong aria-hidden="true">1.</strong> welcome</a></li><li class="chapter-item "><a href="../survey/survey.html"><strong aria-hidden="true">2.</strong> survey</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../survey/pollux.html"><strong aria-hidden="true">2.1.</strong> pollux</a></li><li class="chapter-item "><a href="../survey/adasum.html"><strong aria-hidden="true">2.2.</strong> adasum</a></li><li class="chapter-item "><a href="../survey/adaptation_learning.html"><strong aria-hidden="true">2.3.</strong> adaptation_learning</a></li><li class="chapter-item "><a href="../survey/gradient_descent.html"><strong aria-hidden="true">2.4.</strong> gradient_descent</a></li><li class="chapter-item "><a href="../survey/auto_parallel.html"><strong aria-hidden="true">2.5.</strong> auto_parallel</a></li><li class="chapter-item "><a href="../survey/scheduling.html"><strong aria-hidden="true">2.6.</strong> scheduling</a></li><li class="chapter-item "><a href="../survey/gradient_compression/gradient_compression.html"><strong aria-hidden="true">2.7.</strong> gradient_compression</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../survey/gradient_compression/dgc.html"><strong aria-hidden="true">2.7.1.</strong> dgc</a></li><li class="chapter-item "><a href="../survey/gradient_compression/csc.html"><strong aria-hidden="true">2.7.2.</strong> csc</a></li></ol></li><li class="chapter-item "><a href="../survey/adaptive_training.html"><strong aria-hidden="true">2.8.</strong> adaptive training</a></li></ol></li><li class="chapter-item expanded "><a href="../pytorch/overview.html"><strong aria-hidden="true">3.</strong> pytorch</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../pytorch/tensor.html"><strong aria-hidden="true">3.1.</strong> tensor</a></li><li class="chapter-item "><a href="../pytorch/profiler.html"><strong aria-hidden="true">3.2.</strong> profiler</a></li><li class="chapter-item "><a href="../pytorch/hook.html"><strong aria-hidden="true">3.3.</strong> hook</a></li><li class="chapter-item expanded "><a href="../pytorch/elastic.html" class="active"><strong aria-hidden="true">3.4.</strong> elastic</a></li></ol></li><li class="chapter-item "><a href="../paddle/paddle.html"><strong aria-hidden="true">4.</strong> paddle</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../paddle/ps/ps-code-overview.html"><strong aria-hidden="true">4.1.</strong> ps</a></li><li class="chapter-item "><a href="../paddle/framework.html"><strong aria-hidden="true">4.2.</strong> framework</a></li><li class="chapter-item "><a href="../paddle/cinn.html"><strong aria-hidden="true">4.3.</strong> cinn</a></li></ol></li><li class="chapter-item "><a href="../horovod/horovod.html"><strong aria-hidden="true">5.</strong> horovod</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../horovod/run.html"><strong aria-hidden="true">5.1.</strong> run</a></li><li class="chapter-item "><a href="../horovod/workflow.html"><strong aria-hidden="true">5.2.</strong> workflow</a></li><li class="chapter-item "><a href="../horovod/object.html"><strong aria-hidden="true">5.3.</strong> object</a></li><li class="chapter-item "><a href="../horovod/develop.html"><strong aria-hidden="true">5.4.</strong> develop</a></li><li class="chapter-item "><a href="../horovod/pytorch.html"><strong aria-hidden="true">5.5.</strong> pytorch</a></li><li class="chapter-item "><a href="../horovod/tensorflow.html"><strong aria-hidden="true">5.6.</strong> tensorflow</a></li><li class="chapter-item "><a href="../horovod/elastic.html"><strong aria-hidden="true">5.7.</strong> elastic</a></li></ol></li><li class="chapter-item "><a href="../ray/ray.html"><strong aria-hidden="true">6.</strong> ray</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../ray/overview.html"><strong aria-hidden="true">6.1.</strong> overview</a></li><li class="chapter-item "><a href="../ray/gcs.html"><strong aria-hidden="true">6.2.</strong> gcs</a></li><li class="chapter-item "><a href="../ray/raylet.html"><strong aria-hidden="true">6.3.</strong> raylet</a></li><li class="chapter-item "><a href="../ray/api.html"><strong aria-hidden="true">6.4.</strong> api</a></li></ol></li><li class="chapter-item "><a href="../python/python.html"><strong aria-hidden="true">7.</strong> python</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../python/concurrent.html"><strong aria-hidden="true">7.1.</strong> concurrent execution</a></li></ol></li><li class="chapter-item "><a href="../kubernetes/kubernetes.html"><strong aria-hidden="true">8.</strong> kubernetes</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../kubernetes/scheduler.html"><strong aria-hidden="true">8.1.</strong> scheduler</a></li><li class="chapter-item "><a href="../kubernetes/operator.html"><strong aria-hidden="true">8.2.</strong> operator</a></li><li class="chapter-item "><a href="../kubernetes/device_plugin.html"><strong aria-hidden="true">8.3.</strong> device plugin</a></li><li class="chapter-item "><a href="../kubernetes/docker.html"><strong aria-hidden="true">8.4.</strong> docker</a></li></ol></li><li class="chapter-item "><a href="../leveldb/leveldb.html"><strong aria-hidden="true">9.</strong> leveldb</a></li><li class="chapter-item "><a href="../tvm/tvm.html"><strong aria-hidden="true">10.</strong> tvm</a></li><li class="chapter-item "><a href="../gloo/gloo.html"><strong aria-hidden="true">11.</strong> gloo</a></li><li class="chapter-item "><a href="../nccl/nccl.html"><strong aria-hidden="true">12.</strong> nccl</a></li><li class="chapter-item "><a href="../mpi/mpi.html"><strong aria-hidden="true">13.</strong> mpi</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">Aller au boulot</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/kuizhiqing/aller-au-boulot" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="ealstic"><a class="header" href="#ealstic">Ealstic</a></h1>
<h2 id="launchrun"><a class="header" href="#launchrun">launch/run</a></h2>
<pre><code class="language-shell">python -m torch.distributed.run
</code></pre>
<p>模块实际调用 <code>elastic_launch</code> 函数启动</p>
<pre><code class="language-python"># torch/distributed/run.py

def run(args):
    config, cmd, cmd_args = config_from_args(args)
    elastic_launch(
        config=config,
        entrypoint=cmd,
    )(*cmd_args)


@record
def main(args=None):
    args = parse_args(args)
    run(args)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>elastic_launch 调用 launch_agent 方法</p>
<ul>
<li>创建 RendezvousParameters，只包含声明</li>
<li>创建 WorkerSpec, rdzv_handler 参数处理见 rendezvous 部分</li>
<li>创建 LocalElasticAgent</li>
<li>调用 agent.run()</li>
</ul>
<pre><code class="language-python"># torch/distributed/launcher/api.py

class elastic_launch:
    def __call__(self, *args):
        return launch_agent(self._config, self._entrypoint, list(args))

def launch_agent(...)
    run_id = str(uuid.uuid4().int)

    entrypoint_name = _get_entrypoint_name(entrypoint, args)

    rdzv_parameters = RendezvousParameters(...)

    # 这里的 master 只有在 rdzv_backend == static 时等于 rdzv, 否则都是 None，将会在后面创建
    master_addr, master_port = _get_addr_and_port(rdzv_parameters)

    spec = WorkerSpec(
        role=config.role,
        local_world_size=config.nproc_per_node,
        entrypoint=entrypoint,
        args=tuple(args),
        rdzv_handler=rdzv_registry.get_rendezvous_handler(rdzv_parameters),
        max_restarts=config.max_restarts,
        monitor_interval=config.monitor_interval,
        redirects=config.redirects,
        tee=config.tee,
        master_addr=master_addr,
        master_port=master_port,
    )

    agent = LocalElasticAgent(
        spec=spec, start_method=config.start_method, log_dir=config.log_dir
    )

    result = agent.run()
</code></pre>
<h2 id="rendezvous"><a class="header" href="#rendezvous">rendezvous</a></h2>
<p>rendezvous 模块在初始化时把默认支持的 handler 都进行了初始化，注册在 handler_registry 中。</p>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/__init__.py
from .registry import _register_default_handlers
_register_default_handlers()
</code></pre>
<p>即提供了对应关系，可以通过 handler key 获取到 create handler 方法。</p>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/registry.py

from .api import rendezvous_handler_registry as handler_registry
from .dynamic_rendezvous import create_handler

def _create_c10d_handler(params: RendezvousParameters) -&gt; RendezvousHandler:
    from .c10d_rendezvous_backend import create_backend

    backend, store = create_backend(params)
    return create_handler(store, backend, params)

def _register_default_handlers() -&gt; None:
    handler_registry.register(&quot;c10d&quot;, _create_c10d_handler)
    handler_registry.register(&quot;static&quot;, _create_static_handler)


def get_rendezvous_handler(params: RendezvousParameters) -&gt; RendezvousHandler:
    return handler_registry.create_handler(params)
</code></pre>
<blockquote>
<p>注意这里有两个 create_handler，一个从注册器中取出并调用，一个是 create backend 后的封装。</p>
</blockquote>
<p>启动时调用的 <code>rdzv_registry.get_rendezvous_handler(rdzv_parameters)</code> 即通过 prameter 获取对应 handler 并初始化。</p>
<pre><code class="language-python">import torch.distributed.elastic.rendezvous.registry as rdzv_registry
</code></pre>
<pre><code class="language-python">#  torch/distributed/elastic/rendezvous/api.py

rendezvous_handler_registry = RendezvousHandlerRegistry()

class RendezvousHandlerRegistry:

    _registry: Dict[str, RendezvousHandlerCreator]

    def register(self, backend: str, creator: RendezvousHandlerCreator) -&gt; None:
        self._registry[backend] = creator

    def create_handler(self, params: RendezvousParameters) -&gt; RendezvousHandler:
        creator = self._registry[params.backend]
        handler = creator(params)
        return handler
</code></pre>
<p>以 c10d 为例说明 create_backend，即真正启动服务的部分</p>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py

def _create_tcp_store(params: RendezvousParameters) -&gt; TCPStore:
    host, port = parse_rendezvous_endpoint(params.endpoint, default_port=29400)
    # 对于同一台机器多进程启动的 case，通过重试解决
    store = TCPStore(host, port, is_master=is_server, timeout=timedelta(seconds=read_timeout))

    return store

def create_backend(params: RendezvousParameters) -&gt; Tuple[C10dRendezvousBackend, Store]:
    store_type = params.get(&quot;store_type&quot;, &quot;tcp&quot;).strip().lower()
    store = _create_tcp_store(params)
    backend = C10dRendezvousBackend(store, params.run_id)

    return backend, store
</code></pre>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/dynamic_rendezvous.py

def create_handler(
    store: Store, backend: RendezvousBackend, params: RendezvousParameters
) -&gt; DynamicRendezvousHandler:
        return DynamicRendezvousHandler.from_backend(...)

class DynamicRendezvousHandler(RendezvousHandler):
    @classmethod
    def from_backend(
        cls,
        run_id: str,
        store: Store,
        backend: RendezvousBackend,
        min_nodes: int,
        max_nodes: int,
        timeout: Optional[RendezvousTimeout] = None,
    ):
        return cls(node, settings, backend.name, store, state_holder)

    def next_rendezvous(self) -&gt; Tuple[Store, int, int]:
        self._start_heartbeats()

        rank, world_size = self._get_world()
        store = self._get_store()

        return store, rank, world_size

    def _keep_alive(self) -&gt; None:
        ...

    def _start_heartbeats(self) -&gt; None:
        ...

</code></pre>
<p><code>_keep_alive</code>  是通过 <code>_PeriodicTimer</code> 启动线程依赖 backend 实现的。</p>
<p>链路逻辑，</p>
<ul>
<li><code>_keep_alive_weak</code> 调用 <code>_keep_alive</code>，<code>_DistributedRendezvousOpExecutor.run</code> 方法声明更新</li>
<li><code>_DistributedRendezvousOpExecutor</code> 初始化时需要传入 <code>_state_holder</code></li>
<li><code>state_holder: _RendezvousStateHolder</code> 在 DynamicRendezvousHandler` 初始化时传入</li>
<li>_BackendRendezvousStateHolder(backend, settings) 使用 <code>backend</code></li>
</ul>
<h2 id="worker"><a class="header" href="#worker">worker</a></h2>
<p><strong>TL;DR;</strong></p>
<p>提供 WorkerSpec/Worker/WorkerGroup/WorkerState/RunResult 抽象, 封装 process 管理。</p>
<p>调用如前所述，初始化后使用 <code>agent.run()</code> 调用，</p>
<ul>
<li>run 调用 invoke_run</li>
<li>invoke_run 调用 _initialize_workers 实际拉起 worker 进程，然后 while 循环监控状态</li>
</ul>
<p>_initialize_workers</p>
<ul>
<li>首先调用 _rendezvous: 0 号节点在 store 中写入 master 地址，所有节点从中取出 master 地址，并不使用，只为了做同步</li>
<li>调用 _start_workers 启动 worker</li>
</ul>
<blockquote>
<p>0 号节点写入的 master 地址在使用 c10d backend （非 static）时并不是 rendevous endpoint，默认情况会通过 socket bind 获取可用端口，然后写入 store，其余节点从 store 中获取。</p>
</blockquote>
<pre><code class="language-python"># torch/distributed/elastic/agent/server/api.py 

class SimpleElasticAgent(ElasticAgent):

    def run(self, role: str = DEFAULT_ROLE) -&gt; RunResult:
        result = self._invoke_run(role)
        return result

    def _invoke_run(self, role: str = DEFAULT_ROLE) -&gt; RunResult:
        self._initialize_workers(self._worker_group)
        rdzv_handler = spec.rdzv_handler

        while True:
            run_result = self._monitor_workers(self._worker_group)
            state = run_result.state
            if state == WorkerState.SUCCEEDED:
                self._exit_barrier()
                return run_result
            elif state in {WorkerState.UNHEALTHY, WorkerState.FAILED}:
                if self._remaining_restarts &gt; 0:
                    self._remaining_restarts -= 1
                    self._restart_workers(self._worker_group)
                else:
                    self._stop_workers(self._worker_group)
                    self._worker_group.state = WorkerState.FAILED
                    self._exit_barrier()
                    return run_result
            elif state == WorkerState.HEALTHY:
                num_nodes_waiting = rdzv_handler.num_nodes_waiting()
                if num_nodes_waiting &gt; 0:
                    self._restart_workers(self._worker_group)

    def _initialize_workers(self, worker_group: WorkerGroup) -&gt; None:
        self._rendezvous(worker_group)
        worker_ids = self._start_workers(worker_group)

    def _rendezvous(self, worker_group: WorkerGroup) -&gt; None:
        store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
        workers = self._assign_worker_ranks(store, group_rank, group_world_size, spec)

        if group_rank == 0:
            self._set_master_addr_port(store, spec.master_addr, spec.master_port)

        # 获取 master 地址，起到同步作用
        master_addr, master_port = self._get_master_addr_port(store)

    @staticmethod
    def _set_master_addr_port(
        store: Store, master_addr: Optional[str], master_port: Optional[int]
    ):
        if master_port is None:
            sock = _get_socket_with_port()
            with closing(sock):
                master_port = sock.getsockname()[1]

        if master_addr is None:
            master_addr = _get_fq_hostname()

        store.set(&quot;MASTER_ADDR&quot;, master_addr.encode(encoding=&quot;UTF-8&quot;))
        store.set(&quot;MASTER_PORT&quot;, str(master_port).encode(encoding=&quot;UTF-8&quot;))

    @staticmethod
    def _get_master_addr_port(store: Store) -&gt; Tuple[str, int]:
        master_addr = store.get(&quot;MASTER_ADDR&quot;).decode(encoding=&quot;UTF-8&quot;)
        master_port = int(store.get(&quot;MASTER_PORT&quot;).decode(encoding=&quot;UTF-8&quot;))
        return (master_addr, master_port)


def _get_socket_with_port() -&gt; socket.socket:
    s = socket.socket(family, type, proto)
    s.bind((&quot;localhost&quot;, 0))
    s.listen(0)
    return s

</code></pre>
<p>_start_workers 为真正启动进程的模块，</p>
<ul>
<li>首先获取 master 地址，这个地址在非 static backend 时是 0 号节点写入 store 的</li>
<li>为 process 准备多种配置，主要包括 env，args，然后调用进程封装模块启动进程返回进程 id</li>
</ul>
<pre><code class="language-python"># torch/distributed/elastic/agent/server/local_elastic_agent.py

class LocalElasticAgent(SimpleElasticAgent):

    def _start_workers(self, worker_group: WorkerGroup) -&gt; Dict[int, Any]:
        master_addr, master_port = super()._get_master_addr_port(store)
        for worker in worker_group.workers:
            local_rank = worker.local_rank
            worker_env = {
                &quot;LOCAL_RANK&quot;: str(local_rank),
                &quot;RANK&quot;: str(worker.global_rank),
                &quot;GROUP_RANK&quot;: str(worker_group.group_rank),
                &quot;ROLE_RANK&quot;: str(worker.role_rank),
                &quot;ROLE_NAME&quot;: spec.role,
                &quot;LOCAL_WORLD_SIZE&quot;: str(spec.local_world_size),
                &quot;WORLD_SIZE&quot;: str(worker.world_size),
                &quot;GROUP_WORLD_SIZE&quot;: str(worker_group.group_world_size),
                &quot;ROLE_WORLD_SIZE&quot;: str(worker.role_world_size),
                &quot;MASTER_ADDR&quot;: master_addr,
                &quot;MASTER_PORT&quot;: str(master_port),
                &quot;TORCHELASTIC_RESTART_COUNT&quot;: str(restart_count),
                &quot;TORCHELASTIC_MAX_RESTARTS&quot;: str(spec.max_restarts),
                &quot;TORCHELASTIC_RUN_ID&quot;: spec.rdzv_handler.get_run_id(),
                &quot;TORCHELASTIC_USE_AGENT_STORE&quot;: str(use_agent_store),
                &quot;NCCL_ASYNC_ERROR_HANDLING&quot;: os.getenv(
                    &quot;NCCL_ASYNC_ERROR_HANDLING&quot;, str(1)
                ),
            }
            if &quot;OMP_NUM_THREADS&quot; in os.environ:
                worker_env[&quot;OMP_NUM_THREADS&quot;] = os.environ[&quot;OMP_NUM_THREADS&quot;]

            envs[local_rank] = worker_env
            worker_args = list(spec.args)
            worker_args = macros.substitute(worker_args, str(local_rank))
            args[local_rank] = tuple(worker_args)

        self._pcontext = start_processes(
            name=spec.role,
            entrypoint=spec.entrypoint,
            args=args,
            envs=envs,
            log_dir=attempt_log_dir,
            start_method=self._start_method,
            redirects=spec.redirects,
            tee=spec.tee,
        )

        return self._pcontext.pids()

</code></pre>
<p>子进程启动的用户脚本例如 trainer.py，会获取这里配置的环境运行。</p>
<h2 id="process"><a class="header" href="#process">process</a></h2>
<p>对进程和线程的封装，主要是 process 和 multiprocessing 库的封装。</p>
<p>通过对 entrypoint 是否是 str 判断决定启动方式。</p>
<pre><code class="language-python"># torch/distributed/elastic/multiprocessing/__init__.py

def start_processes(
    name: str,
    entrypoint: Union[Callable, str],
) -&gt; PContext:
    context: PContext
    if isinstance(entrypoint, str):
        context = SubprocessContext(...)
    else:
        context = MultiprocessContext(...)

    try:
        context.start()
        return context
    except Exception:
        context.close()
        raise
</code></pre>
<pre><code class="language-python"># torch/distributed/elastic/multiprocessing/api.py

class SubprocessHandler:
    def __init__(...):
        self.proc: subprocess.Popen = self._popen(args_str, env_vars)

class SubprocessContext(PContext):
    def __init__(...):
        self._running_local_ranks: Set[int] = set(range(self.nprocs))
        self._failures: Dict[int, ProcessFailure] = {}
        self.subprocess_handlers: Dict[int, SubprocessHandler] = {}

    def _start(self):
        self.subprocess_handlers = { local_rank: SubprocessHandler(...) }

    def _poll(self) -&gt; Optional[RunProcsResult]:
        for local_rank in self._running_local_ranks:
            exitcode = handler.proc.poll()
            if exitcode is not None:
                done_local_ranks.add(local_rank)
        self._running_local_ranks.difference_update(done_local_ranks)

    def _close(self, death_sig: signal.Signals, timeout: int = 30) -&gt; None:
        for handler in self.subprocess_handlers.values():
            if handler.proc.poll() is None:
                handler.close(death_sig=death_sig)

class PContext(abc.ABC):
    def __init__(...):
        self.entrypoint = entrypoint

    def start(self) -&gt; None:
        self._start()

    def wait(self, timeout: float = -1, period: float = 1) -&gt; Optional[RunProcsResult]:
        expiry = time.time() + timeout
        while time.time() &lt; expiry:
            pr = self._poll()
            if pr: return pr

    def close(
        self, death_sig: Optional[signal.Signals] = None, timeout: int = 30
    ) -&gt; None:
        self._close(death_sig=death_sig, timeout=timeout)
</code></pre>
<pre><code class="language-python">import torch.multiprocessing as mp

class MultiprocessContext(PContext):
    def __init__(..., entrypoint: Callable, ...):
        self._ret_vals = {
            local_rank: mp.get_context(self.start_method).SimpleQueue()
            for local_rank in range(self.nprocs)
        }
        self._pc: Optional[mp.ProcessContext] = None

    def _start(self):
        self._pc = mp.start_processes(...)

    def _poll(self) -&gt; Optional[RunProcsResult]:
        self._pc.join(-1)

    def _close(self, death_sig: signal.Signals, timeout: int = 30) -&gt; None:
        for proc in self._pc.processes:
            if proc.is_alive():
                try:
                    os.kill(proc.pid, death_sig)
</code></pre>
<h2 id="demo"><a class="header" href="#demo">demo</a></h2>
<p>上面部分的内容都是 run 模块的部分，下面是用户侧代码比如 train.py 的部分。</p>
<pre><code class="language-python">import torch

torch.distributed.init_process_group(backend=&quot;nccl&quot;, init_method=&quot;env://&quot;)
print(torch.distributed.get_world_size())
</code></pre>
<p>init_process_group 提供两种初始化方式</p>
<ul>
<li>显式提供 store, rank, world_size 以初始化</li>
<li>指定 init_method, 默认为 env:// 使用环境变量，如 launch/run 模块已配置好了环境变量</li>
</ul>
<p>在没有 store 的时候会通过 rendevous 创建 store 并获取 rank 和 size 信息。</p>
<p>然后根据这些信息创建 process group,</p>
<ul>
<li>mpi 从 orte 中获取信息，不需要通过这里指定</li>
<li>gloo/nccl 通过 store, rank, size 初始化创建通信域</li>
</ul>
<pre><code class="language-python"># torch/distributed/distributed_c10d.py

from .rendezvous import rendezvous

def init_process_group(
    backend,
    init_method=None,
    timeout=default_pg_timeout,
    world_size=-1,
    rank=-1,
    store=None,
    group_name=&quot;&quot;,
    pg_options=None,
):
    backend = Backend(backend)

    if backend == Backend.MPI:
        default_pg = _new_process_group_helper(
            -1, -1, [], Backend.MPI, None, group_name=group_name, timeout=timeout
        )
        _update_default_pg(default_pg)
    else:
        if store is None:
            rendezvous_iterator = rendezvous(
                init_method, rank, world_size, timeout=timeout
            )
            store, rank, world_size = next(rendezvous_iterator)
            store = PrefixStore(&quot;default_pg&quot;, store)

        default_pg = _new_process_group_helper(...)
        _update_default_pg(default_pg)

    if backend == Backend.MPI:
        barrier()
    else:
        _store_based_barrier(rank, store, timeout)


def _new_process_group_helper(
    world_size,
    rank,
    group_ranks,
    backend,
    store,
    pg_options=None,
    group_name=None,
    timeout=default_pg_timeout,
):
    backend = Backend(backend)
    if backend == Backend.MPI:
        pg = ProcessGroupMPI.create(group_ranks)
        _pg_map[pg] = (Backend.MPI, None)
        _pg_names[pg] = group_name
    else:
        prefix_store = PrefixStore(group_name, store)

        if backend == Backend.GLOO:
            pg = ProcessGroupGloo(prefix_store, rank, world_size, timeout=timeout)
            _pg_map[pg] = (Backend.GLOO, store)
            _pg_names[pg] = group_name
        elif backend == Backend.NCCL:
            pg = ProcessGroupNCCL(prefix_store, rank, world_size, pg_options)
            _pg_map[pg] = (Backend.NCCL, store)
            _pg_names[pg] = group_name

    return pg

</code></pre>
<p>rendevous 会创建 store 并返回 rank, size 信息，创建 store 通过 <code>_create_c10d_store</code> 实现，
在调用c api 创建 TCPStore 时通过 start_daemon 指定是否在当前调用里创建服务。</p>
<pre><code class="language-python"># torch/distributed/rendezvous.py

_rendezvous_handlers = {}

def rendezvous(url: str, rank: int = -1, world_size: int = -1, **kwargs):
    return _rendezvous_handlers[result.scheme](url, **kwargs)

def register_rendezvous_handler(scheme, handler):
    _rendezvous_handlers[scheme] = handler

register_rendezvous_handler(&quot;tcp&quot;, _tcp_rendezvous_handler)
register_rendezvous_handler(&quot;env&quot;, _env_rendezvous_handler)
register_rendezvous_handler(&quot;file&quot;, _file_rendezvous_handler)

def _file_rendezvous_handler(url: str, **kwargs):
    result = urlparse(url)
    query_dict = _query_to_dict(result.query)
    rank = int(query_dict[&quot;rank&quot;])
    world_size = int(query_dict[&quot;world_size&quot;])
    store = FileStore(path, world_size)
    yield (store, rank, world_size)


def _create_c10d_store(hostname, port, rank, world_size, timeout) -&gt; Store:
    if _torchelastic_use_agent_store():
        tcp_store = TCPStore(hostname, port, world_size, False, timeout)
        return PrefixStore(f&quot;/worker/attempt_{attempt}&quot;, tcp_store)
    else:
        start_daemon = rank == 0
        return TCPStore(
            hostname, port, world_size, start_daemon, timeout, multi_tenant=True
        )


def _tcp_rendezvous_handler(
    url: str, timeout: timedelta = default_pg_timeout, **kwargs
):
    result = urlparse(url)
    query_dict = _query_to_dict(result.query)
    rank = int(query_dict[&quot;rank&quot;])
    world_size = int(query_dict[&quot;world_size&quot;])

    store = _create_c10d_store(result.hostname, result.port, rank, world_size, timeout)

    yield (store, rank, world_size)


def _env_rendezvous_handler(
    url: str, timeout: timedelta = default_pg_timeout, **kwargs
):
    result = urlparse(url)
    query_dict: Dict[str, Union[int, str]] = _query_to_dict(result.query)

    if &quot;rank&quot; in query_dict:
        rank = int(query_dict[&quot;rank&quot;])
    else:
        rank = int(_get_env_or_raise(&quot;RANK&quot;))

    if &quot;world_size&quot; in query_dict:
        world_size = int(query_dict[&quot;world_size&quot;])
    else:
        world_size = int(_get_env_or_raise(&quot;WORLD_SIZE&quot;))

    master_addr = _get_env_or_raise(&quot;MASTER_ADDR&quot;)
    master_port = int(_get_env_or_raise(&quot;MASTER_PORT&quot;))

    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)

    yield (store, rank, world_size)

</code></pre>
<p>rendezvous_handler 的实现使用了 iterator 可以避免被多次调用，同时有 lazy init 的效果。</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../pytorch/hook.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="../paddle/paddle.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../pytorch/hook.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="../paddle/paddle.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
    </body>
</html>
