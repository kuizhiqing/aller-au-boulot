<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Aller au boulot</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Projects excelling">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item "><a href="ray/ray.html"><strong aria-hidden="true">1.</strong> ray</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="ray/overview.html"><strong aria-hidden="true">1.1.</strong> overview</a></li><li class="chapter-item "><a href="ray/gcs.html"><strong aria-hidden="true">1.2.</strong> gcs</a></li><li class="chapter-item "><a href="ray/raylet.html"><strong aria-hidden="true">1.3.</strong> raylet</a></li><li class="chapter-item "><a href="ray/api.html"><strong aria-hidden="true">1.4.</strong> api</a></li></ol></li><li class="chapter-item "><a href="pytorch/overview.html"><strong aria-hidden="true">2.</strong> pytorch</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="pytorch/tensor.html"><strong aria-hidden="true">2.1.</strong> tensor</a></li></ol></li><li class="chapter-item "><a href="paddle/paddle.html"><strong aria-hidden="true">3.</strong> paddle</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="paddle/ps/ps-code-overview.html"><strong aria-hidden="true">3.1.</strong> ps</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">Aller au boulot</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/kuizhiqing/aller-au-boulot" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="ray"><a class="header" href="#ray">Ray</a></h1>
<h2 id="reference"><a class="header" href="#reference">Reference</a></h2>
<ul>
<li><a href="https://github.com/ray-project/ray">Ray Github</a></li>
<li><a href="https://docs.ray.io/en/latest/">Ray Documentation</a></li>
</ul>
<p>源代码和官方文档永远是最好的学习资料，总结和学习笔记能辅助快速理解，抓住重点，提高效率。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<h2 id="build"><a class="header" href="#build">BUILD</a></h2>
<p>Ray 的编译使用 bazel，其中大量的 proto 编译也依赖于此，
具体定义在 <code>src/ray/protobuf/BUILD</code> 文件中，参考 <a href="https://rules-proto-grpc.com/en/latest/example.html">文档</a>.</p>
<h2 id="启动部署"><a class="header" href="#启动部署">启动部署</a></h2>
<p>安装完成后，可以直接运行的相关命令如下</p>
<pre><code class="language-python"># python/setup.py

entry_points={
    &quot;console_scripts&quot;: [
        &quot;ray=ray.scripts.scripts:main&quot;,
        &quot;rllib=ray.rllib.scripts:cli [rllib]&quot;,
        &quot;tune=ray.tune.scripts:cli&quot;,
        &quot;ray-operator=ray.ray_operator.operator:main&quot;,
        &quot;serve=ray.serve.scripts:cli&quot;,
    ]
}
</code></pre>
<p>常驻模式启动 ray 集群</p>
<pre><code class="language-shell"># 启动 head 节点
ray start --head
# 启动 worker 节点
ray start --address=RAY_HEAD_IP:6379

ray start --head --redis-password=&quot;&quot; --port=6389
</code></pre>
<p>start 命令的解析如下</p>
<pre><code class="language-python"># python/ray/scripts/scripts.py

# args 解析用的是 click

@cli.command()
@click.option(&quot;--head&quot;,...)
def start(...,head,...):
    ray_params = ray._private.parameter.RayParams(...)
    if head:
        # 启动 head 节点
        ray_params.update_if_absent(...)
        node = ray.node.Node(ray_params, head=True,...)
    else:
        # 启动 worker 节点
        bootstrap_address = services.canonicalize_bootstrap_address(address)
        ray_params.gcs_address = bootstrap_address
        node = ray.node.Node(ray_params, head=False,...)

cli.add_command(start)
def main():
    return cli()
</code></pre>
<p>可以看出本质上都是初始化了节点 Node 对象，是否为 head 则通过参数指定。</p>
<h3 id="node"><a class="header" href="#node">Node</a></h3>
<p>Node 节点的初始化</p>
<pre><code class="language-python"># python/ray/node.py

class Node:
    def __init__(self, ray_params, head=False,...):
        self.head = head

        if not head:
            # GCS GRPC client, 确保 gcs 已启动
            self.get_gcs_client()

        # 初始化持久化存储
        storage._init_storage(ray_params.storage, is_head=head) 

        if head:
            self.validate_external_storage()

        if ...:
            # 启动 reaper 进程，负责在主进程意外退出后回收进程
            self.start_reaper_process()

        if head:
            self.start_head_processes()
            # 尝试写入 gcs
            self.get_gcs_client().internal_kv_put(...)

        if not connect_only:
            self.start_ray_processes()
            ray._private.services.wait_for_node(...)
</code></pre>
<p>Node 的初始化包括启动 start_head_processes 和 start_ray_processes 两部分。</p>
<pre><code class="language-python"># python/ray/node.py

class Node:
    def start_head_processes(self):
        # 如果使用外部 redis，需要配置
        # 这里的逻辑目前有点 confuse，external 和 local 不够明确
        if self._ray_params.external_addresses is not None:
            self.start_or_configure_redis()
            self.create_redis_client()

        # 启动 gcs，包含 redis 服务, 默认端口 6379
        self.start_gcs_server()

        self.start_ray_client_server()

    def start_or_configure_redis(self):
        # 如果 external 有配置，并不真正启动
        ray._private.services.start_redis(...)

    def start_gcs_server(self):
        process_info = ray._private.services.start_gcs_server(self.redis_address,...)
        # 等待启动
        self.get_gcs_client()

    def start_ray_client_server(self):
        process_info = ray._private.services.start_ray_client_server(self.address, self._node_ip_address, ...)

    def start_ray_processes(self):
        # 启动节点上所有的进程
        self.destroy_external_storage()
        # 启动 raylet
        self.start_raylet(plasma_directory, object_store_memory)

    def start_raylet(self, ...):
        process_info = ray._private.services.start_raylet(
            self.redis_address,
            self.gcs_address,
            self._node_ip_address,
            ...)

</code></pre>
<ul>
<li>Head 节点启动 gcs 服务和 ray_client 服务</li>
<li>Head 和 Worker 节点都启动 raylet 服务</li>
</ul>
<p>这些服务的具体启动都被封装在 services 里。</p>
<h3 id="services"><a class="header" href="#services">Services</a></h3>
<p>Services 提供多种服务启动的封装，包括 redis 服务启动。</p>
<blockquote>
<p>1.11 之前的版本 ray 通过启动 redis-server 二进制启动 redis，新版本中已经移除。</p>
</blockquote>
<pre><code class="language-python"># python/ray/_private/services.py

def start_gcs_server(redis_address, ...):
    # 调用 gcs 二进制启动服务，包含 redis 服务
    # GCS_SERVER_EXECUTABLE &quot;core/src/ray/gcs/gcs_server&quot;
    command = [GCS_SERVER_EXECUTABLE, &quot;--redis_xxxx=&quot;, ...]
    process_info = start_ray_process(command, ...)

def start_ray_client_server(address, ray_client_server_ip,...):
    command = [
        sys.executable,    # python
        setup_worker_path, # ray/workers/setup_worker.py
        &quot;-m&quot;,
        &quot;ray.util.client.server&quot;,
        ...]
    process_info = start_ray_process(command, ...)

def start_raylet(redis_address, gcs_address, ...):
    # 启动 raylet，包括 local scheduler 和 object manager
    # 支持 python、java 和 cpp
    # RAYLET_EXECUTABLE &quot;core/src/ray/raylet/raylet&quot;
    command = [
        RAYLET_EXECUTABLE,
        f&quot;--python_worker_command={subprocess.list2cmdline(start_worker_command)}&quot;,  # noqa
        f&quot;--java_worker_command={subprocess.list2cmdline(java_worker_command)}&quot;,  # noqa
        f&quot;--cpp_worker_command={subprocess.list2cmdline(cpp_worker_command)}&quot;,  # noqa
        ...]
    command.append(&quot;--agent_command={}&quot;.format(subprocess.list2cmdline(agent_command)))
    process_info = start_ray_process(command, ...)

def start_ray_process(command, ...):
    process = ConsolePopen(
        command,
        env=modified_env,
        cwd=cwd,
        stdout=stdout_file,
        stderr=stderr_file,
        stdin=subprocess.PIPE if pipe_stdin else None,
        preexec_fn=preexec_fn if sys.platform != &quot;win32&quot; else None,
        creationflags=CREATE_SUSPENDED if win32_fate_sharing else 0,
    )

class ConsolePopen(subprocess.Popen):
    pass

</code></pre>
<h3 id="setup-worker--runtime-env-context"><a class="header" href="#setup-worker--runtime-env-context">setup worker &amp; runtime env context</a></h3>
<p>setup worker 的作用是执行不同的程序，</p>
<pre><code class="language-python"># ray/workers/setup_worker.py

parser.add_argument(&quot;--serialized-runtime-env-context&quot;,...)
parser.add_argument(&quot;--language&quot;, ...)

if __name__ == &quot;__main__&quot;:
    args, remaining_args = parser.parse_known_args()
    runtime_env_context = RuntimeEnvContext.deserialize(
        args.serialized_runtime_env_context or &quot;{}&quot;
    )
    runtime_env_context.exec_worker(remaining_args, Language.Value(args.language))
</code></pre>
<pre><code class="language-python"># python/ray/_private/runtime_env/context.py

class RuntimeEnvContext:
    def exec_worker(self, passthrough_args: List[str], language: Language):
        os.environ.update(self.env_vars)

        # exec [python] passthrough_args
        command_str = &quot; &amp;&amp; &quot;.join(...)

        if sys.platform == &quot;win32&quot;:
            os.system(command_str)
        else:
            os.execvp(&quot;bash&quot;, args=[&quot;bash&quot;, &quot;-c&quot;, command_str])
</code></pre>
<h3 id="client-server"><a class="header" href="#client-server">client server</a></h3>
<pre><code class="language-bash">python -m ray.util.client.server --address=x.x.x.x:6379 --host=0.0.0.0 --port=10001 --mode=proxy --redis-password=
</code></pre>
<pre><code class="language-python"># python/ray/util/client/server/__main__.py
# -&gt; server.py main
# python/ray/util/client/server/server.py

def main():
    server = serve(hostport, ray_connect_handler)
    while True:
        ray.experimental.internal_kv._internal_kv_put(..., HEALTHCHECK)

def serve(connection_str, ray_connect_handler=None):
    server = grpc.server(
        futures.ThreadPoolExecutor(
            max_workers=CLIENT_SERVER_MAX_THREADS,
            thread_name_prefix=&quot;ray_client_server&quot;,
        ),
    )
    # mode proxy
    task_servicer = RayletServicerProxy(None, proxy_manager)
    data_servicer = DataServicerProxy(proxy_manager)
    logs_servicer = LogstreamServicerProxy(proxy_manager)
    # else
    task_servicer = RayletServicer(ray_connect_handler)
    data_servicer = DataServicer(task_servicer)
    logs_servicer = LogstreamServicer()
    ray_client_pb2_grpc.add_RayletDriverServicer_to_server(task_servicer, server)
    ray_client_pb2_grpc.add_RayletDataStreamerServicer_to_server(data_servicer, server)
    ray_client_pb2_grpc.add_RayletLogStreamerServicer_to_server(logs_servicer, server)
    server.start()
</code></pre>
<pre><code class="language-python"># python/ray/util/client/server/server.py

# class RayletServicerProxy(ray_client_pb2_grpc.RayletDriverServicer):
class RayletServicer(ray_client_pb2_grpc.RayletDriverServicer):
    def KVPut(self, request, context=None) -&gt; ray_client_pb2.KVPutResponse:
    def KVGet(self, request, context=None) -&gt; ray_client_pb2.KVGetResponse:
    def KVDel(self, request, context=None) -&gt; ray_client_pb2.KVDelResponse:
    def KVList(self, request, context=None) -&gt; ray_client_pb2.KVListResponse:
    def ListNamedActors(...):
    def ClusterInfo(self, request, context=None) -&gt; ray_client_pb2.ClusterInfoResponse:
    def release(self, client_id: str, id: bytes) -&gt; bool:
    def release_all(self, client_id):
    def Terminate(self, req, context=None):
    def GetObject(self, request: ray_client_pb2.GetRequest, context):
    def PutObject( self, request: ray_client_pb2.PutRequest, context=None) -&gt; ray_client_pb2.PutResponse:
    def WaitObject(self, request, context=None) -&gt; ray_client_pb2.WaitResponse:
    def Schedule( self, task: ray_client_pb2.ClientTask, context=None) -&gt; ray_client_pb2.ClientTaskTicket:
    def lookup_or_register_func( self, id: bytes, client_id: str, options: Optional[Dict]) -&gt; ray.remote_function.RemoteFunction:
    def lookup_or_register_actor( self, id: bytes, client_id: str, options: Optional[Dict]):
    def unify_and_track_outputs(self, output, client_id):
</code></pre>
<h3 id="总结"><a class="header" href="#总结">总结</a></h3>
<p><code>ray start [--head]</code>, 将启动以下进程</p>
<pre><code class="language-shell"># 以下进程只在 head 节点运行
# GCS_SERVER_EXECUTABLE 
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/gcs/gcs_server 
/usr/bin/python3.7 -m ray.util.client.server --host=0.0.0.0 --port=10001 --mode=proxy

# worker 进程
# RAYLET_EXECUTABLE
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/raylet/raylet
/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/dashboard/agent.py

/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/monitor.py
/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/dashboard/dashboard.py
/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/_private/log_monitor.py
</code></pre>
<pre><code class="language-shell"># 新版本中的以下进程已被移除
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/thirdparty/redis/src/redis-server *:6379
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/thirdparty/redis/src/redis-server *:64712
</code></pre>
<pre><code class="language-shell"># java worker command
python ray/workers/setup_worker.py java -Dx=x -cp xx RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker

#  cpp worker command
cpp/default_worker
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="gcs-server"><a class="header" href="#gcs-server">GCS Server</a></h1>
<p>服务由以下二进制启动</p>
<pre><code class="language-shell">&quot;core/src/ray/gcs/gcs_server&quot;
</code></pre>
<p>程序入口</p>
<pre><code class="language-cpp">// src/ray/gcs/gcs_server/gcs_server_main.cc

int main(int argc, char *argv[]) {
  // 初始化配置
  RayConfig::instance().initialize(config_list);
  // 启动 IO service
  // class instrumented_io_context : public boost::asio::io_context {...}
  instrumented_io_context main_service;
  boost::asio::io_service::work work(main_service);
  // 初始化状态模块
  ray::stats::Init(global_tags, metrics_agent_port);

  // 启动 grpc 服务
  ray::gcs::GcsServerConfig gcs_server_config;
  gcs_server_config.grpc_server_name = &quot;GcsServer&quot;;
  ray::gcs::GcsServer gcs_server(gcs_server_config, main_service);
  gcs_server.Start();

  main_service.run();
}
</code></pre>
<p>主服务</p>
<pre><code class="language-cpp">// src/ray/gcs/gcs_server/gcs_server.cc

// 服务初始化，根据配置使用外置 redis 存储或者内置存储
GcsServer::GcsServer(...) {
  if (storage_type_ == &quot;redis&quot;) {
    gcs_table_storage_ = std::make_shared&lt;gcs::RedisGcsTableStorage&gt;(GetOrConnectRedis());
  } else if (storage_type_ == &quot;memory&quot;) {
    gcs_table_storage_ = std::make_shared&lt;InMemoryGcsTableStorage&gt;(main_service_);
  }
}

void GcsServer::Start() {
  // 异步加载 gcs tables 数据
  auto gcs_init_data = std::make_shared&lt;GcsInitData&gt;(gcs_table_storage_);
  gcs_init_data-&gt;AsyncLoad([this, gcs_init_data] { DoStart(*gcs_init_data); });
}

void GcsServer::DoStart(const GcsInitData &amp;gcs_init_data) {
  // Init cluster resource scheduler.
  // Init gcs resource manager.
  // Init synchronization service
  // Init gcs node manager.
  // Init gcs heartbeat manager.
  // Init KV Manager
  // Init function manager
  // Init Pub/Sub handler
  // Init RuntimeENv manager
  // Init gcs job manager.
  // Init gcs placement group manager.
  // Init gcs actor manager.
  // Init gcs worker manager.
  // Init stats handler.
  // Install event listeners.

  // 启动 rpc 服务，依赖 tables 数据加载完成
  // rpc::GrpcServer rpc_server_;
  rpc_server_.Run();
  // 心跳服务
  gcs_heartbeat_manager_-&gt;Start();

  RecordMetrics();
}
</code></pre>
<p>Table storage</p>
<pre><code class="language-cpp">// src/ray/gcs/gcs_server/gcs_table_storage.h

class GcsTable {}

class GcsTableWithJobId : public GcsTable&lt;Key, Data&gt; {}

class GcsTableStorage {};

class RedisGcsTableStorage : public GcsTableStorage {};

class InMemoryGcsTableStorage : public GcsTableStorage {};
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="raylet"><a class="header" href="#raylet">Raylet</a></h1>
<p>服务由以下二进制启动</p>
<pre><code class="language-shell">core/src/ray/raylet/raylet
</code></pre>
<p>程序入口</p>
<pre><code class="language-cpp">// src/ray/raylet/main.cc

int main(int argc, char *argv[]) {

  // 启动 IO service
  // class instrumented_io_context : public boost::asio::io_context {...}
  instrumented_io_context main_service;
  boost::asio::io_service::work main_work(main_service);

  std::unique_ptr&lt;ray::raylet::Raylet&gt; raylet;
  ray::raylet::NodeManagerConfig node_manager_config;
  ray::ObjectManagerConfig object_manager_config;
  raylet = std::make_unique&lt;ray::raylet::Raylet&gt;(main_service,
                                                 raylet_socket_name,
                                                 node_ip_address,
                                                 node_manager_config,
                                                 object_manager_config,
                                                 gcs_client,
                                                 metrics_export_port);
  raylet-&gt;Start();
  main_service.run();
}

</code></pre>
<p>主服务类</p>
<pre><code class="language-cpp">// src/ray/raylet/raylet.cc

class Raylet {
  // 用于和 gcs 连接的客户端
  std::shared_ptr&lt;gcs::GcsClient&gt; gcs_client_;
  NodeManager node_manager_;
}

void Raylet::Start() {
  RAY_CHECK_OK(RegisterGcs());

  // Start listening for clients.
  DoAccept();
}

ray::Status Raylet::RegisterGcs() {
  node_manager_.RegisterGcs();

  gcs_client_-&gt;Nodes().RegisterSelf(self_node_info_, register_callback);
}

void Raylet::DoAccept() {
  acceptor_.async_accept(
      socket_,
      boost::bind(&amp;Raylet::HandleAccept, this, boost::asio::placeholders::error));
}

void Raylet::HandleAccept(const boost::system::error_code &amp;error) {
  // 建立本地连接并分发到 node manager 处理
  auto new_connection = ClientConnection::Create(
      client_handler, // node_manager_.ProcessNewClient(client);
      message_handler, // node_manager_.ProcessClientMessage(client, message_type, message.data());
      std::move(socket_),
      &quot;worker&quot;,
      node_manager_message_enum,
      static_cast&lt;int64_t&gt;(protocol::MessageType::DisconnectClient),
      message_data);
  // 处理连接
  DoAccept();
}
</code></pre>
<p>Node Manager</p>
<p>NodeManager 本身是一个 ServiceHandler，所以在初始化 node_manager_service_ 时，使用 this 作为 handler 传递。</p>
<pre><code class="language-cpp">// src/ray/raylet/node_manager.h

class NodeManager : public rpc::NodeManagerServiceHandler {
  std::shared_ptr&lt;gcs::GcsClient&gt; gcs_client_;
  std::unique_ptr&lt;HeartbeatSender&gt; heartbeat_sender_;
  WorkerPool worker_pool_;
  ObjectManager object_manager_;
  rpc::GrpcServer node_manager_server_;
  rpc::NodeManagerGrpcService node_manager_service_;

  std::unique_ptr&lt;rpc::AgentManagerServiceHandler&gt; agent_manager_service_handler_;
  rpc::AgentManagerGrpcService agent_manager_service_;

  std::shared_ptr&lt;ClusterResourceScheduler&gt; cluster_resource_scheduler_;
  std::shared_ptr&lt;LocalTaskManager&gt; local_task_manager_;

  std::shared_ptr&lt;PlacementGroupResourceManager&gt; placement_group_resource_manager_;
}

// src/ray/raylet/node_manager.cc

// Push
// Pull

NodeManager::NodeManager(...) {
  // 非常多的初始化配置
  node_manager_service_(io_service, *this),
  // 然后注册服务并启动
  node_manager_server_.RegisterService(node_manager_service_);
  node_manager_server_.RegisterService(agent_manager_service_);
  node_manager_server_.Run();
}
</code></pre>
<p>NodeManager 的 rpc 接口</p>
<pre><code class="language-cpp">// src/ray/rpc/node_manager/node_manager_server.h

// `NodeManagerService` 的接口, 对应 `src/ray/protobuf/node_manager.proto`.
class NodeManagerServiceHandler {}
// 目前有以下接口
// UpdateResourceUsage
// RequestResourceReport
// RequestWorkerLease
// ReportWorkerBacklog
// ReturnWorker
// ReleaseUnusedWorkers
// CancelWorkerLease
// PinObjectIDs
// GetNodeStats
// GlobalGC
// FormatGlobalMemoryInfo
// PrepareBundleResources
// CommitBundleResources
// CancelResourceReserve
// RequestObjectSpillage
// ReleaseUnusedBundles
// GetSystemConfig
// GetGcsServerAddress
// ShutdownRaylet

class NodeManagerGrpcService : public GrpcService {
  NodeManagerGrpcService(instrumented_io_context &amp;io_service,
                         NodeManagerServiceHandler &amp;service_handler)
}
</code></pre>
<blockquote>
<p>关于怎么增加新的接口可以参考: <code>src/ray/core_worker/core_worker.h</code>.</p>
</blockquote>
<p>ObjectManager </p>
<pre><code class="language-cpp">// src/ray/object_manager/object_manager.h

class ObjectManager : public ObjectManagerInterface, public rpc::ObjectManagerServiceHandler {
  instrumented_io_context rpc_service_;
  boost::asio::io_service::work rpc_work_;

  rpc::GrpcServer object_manager_server_;
  rpc::ObjectManagerGrpcService object_manager_service_;
}

// 主要接口
// Push
// Pull

// src/ray/object_manager/object_manager.cc

ObjectManager::ObjectManager(...){
  rpc_work_(rpc_service_),
  object_manager_server_(&quot;ObjectManager&quot;,...)
  object_manager_service_(rpc_service_, *this),
  StartRpcService();
}

void ObjectManager::StartRpcService() {
  // for i in config_.rpc_service_threads_number
  rpc_threads_[i] = std::thread(&amp;ObjectManager::RunRpcService, this, i);
  object_manager_server_.RegisterService(object_manager_service_);
  object_manager_server_.Run();
}

void ObjectManager::RunRpcService(int index) {
  rpc_service_.run();
}
</code></pre>
<pre><code class="language-cpp">// src/ray/rpc/object_manager/object_manager_server.h


class ObjectManagerGrpcService : public GrpcService {
  ObjectManagerGrpcService(instrumented_io_context &amp;io_service,
                           ObjectManagerServiceHandler &amp;service_handler)
      : GrpcService(io_service), service_handler_(service_handler){};
</code></pre>
<p>Worker Pool</p>
<pre><code class="language-cpp">// src/ray/raylet/worker_pool.cc
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="api"><a class="header" href="#api">API</a></h1>
<pre><code class="language-python">import ray
ray.init()
# ray.init(address='ray://localhost:10001')

@ray.remote
def f(x):
    return x * x

futures = [f.remote(i) for i in range(4)]
print(ray.get(futures))
</code></pre>
<pre><code class="language-python"># python/ray/worker.py

def init(address: Optional[str] = None, ...):
    # if address
    builder = ray.client(address, _deprecation_warn_enabled=False)
    builder._init_args(**passed_kwargs)
    return builder.connect()

    # if bootstrap_address is None:
    _global_node = ray.node.Node(head=True, shutdown_at_exit=False, spawn_reaper=True, ray_params=ray_params)
    # else
    _global_node = ray.node.Node(ray_params, head=False, shutdown_at_exit=False, spawn_reaper=False, connect_only=True)

    connect(...)
    return RayContext(...)

def connect(node, worker=global_worker, ...):
    worker.node = node
    worker.core_worker = ray._raylet.CoreWorker(...)
</code></pre>
<p>CoreWorker</p>
<pre><code class="language-cpp">// src/ray/core_worker/core_worker.h

class CoreWorker : public rpc::CoreWorkerServiceHandler {
  instrumented_io_context io_service_;
  boost::asio::io_service::work io_work_;

  rpc::CoreWorkerGrpcService grpc_service_;
  std::unique_ptr&lt;rpc::GrpcServer&gt; core_worker_server_;
  
  // std::unique_ptr&lt;ObjectRecoveryManager&gt; object_recovery_manager_;

  std::shared_ptr&lt;TaskManager&gt; task_manager_;
  std::unique_ptr&lt;ActorManager&gt; actor_manager_;
}


// src/ray/core_worker/core_worker.cc

CoreWorker::CoreWorker(...) {
  io_work_(io_service_),
  grpc_service_(io_service_, *this),

  core_worker_server_-&gt;RegisterService(grpc_service_);
  core_worker_server_-&gt;Run();
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="pytorch"><a class="header" href="#pytorch">pytorch</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="tensor"><a class="header" href="#tensor">tensor</a></h1>
<p>The dependancy of tensor related API</p>
<p><img src="pytorch/tensor-api.png" alt="Tensor View API Dependance" /></p>
<p>Tensor view explication</p>
<p><img src="pytorch/tensor-view.png" alt="Tensor View API Dependance" /></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="paddle"><a class="header" href="#paddle">paddle</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="paddle-ps-代码分析"><a class="header" href="#paddle-ps-代码分析">paddle ps 代码分析</a></h1>
<h2 id="python-前端"><a class="header" href="#python-前端">python 前端</a></h2>
<h3 id="api-1"><a class="header" href="#api-1">API</a></h3>
<pre><code class="language-python">import paddle.distributed.fleet as fleet

fleet.init()

if fleet.is_server():
    fleet.init_server()
    fleet.run_server()
elif fleet.is_worker():
    run_worker()
    fleet.stop_worker()

def run_worker():
    # paddle.static.Executor(place)
    exe.run(paddle.static.default_startup_program())
    fleet.init_worker()
    exe.train_from_dataset(...)

# Fin, fleet is optimizer
</code></pre>
<h3 id="fleet-initoptimizer"><a class="header" href="#fleet-initoptimizer">fleet init/optimizer</a></h3>
<pre><code class="language-python"># python/paddle/distributed/fleet/base/fleet_base.py

def init(self, role_maker=None, is_collective=False, strategy=None):
    # 配置之集大成者，就是各种配置，细到训练参数，粗到训练模式，开关
    strategy = DistributedStrategy()
    # role maker 包含分布式信息，基本上对接 launch 信息
    # 也负责初始化如 gloo 之类的工具
    self._role_maker._generate_role()

def minimize(...)
    def _minimize_impl(...)
        # runtime handle 做映射 init_server/_init_server, run_server/_run_server
        self._runtime_handle = RuntimeFactory()._create_runtime(context)
</code></pre>
<h3 id="runtime"><a class="header" href="#runtime">runtime</a></h3>
<pre><code class="language-python"># 使用实例
# python/paddle/distributed/ps/the_one_ps.py
class TheOnePSRuntime(RuntimeBase):
    def __init__(self):
        super(TheOnePSRuntime, self).__init__()
        self._communicator = None
        self._server = None
        self._worker = fluid.core.DistFleetWrapper()
        self._server_sub_program = []
        self._heter_client = None
        self._send_ctx = None
</code></pre>
<h3 id="pybind"><a class="header" href="#pybind">pybind</a></h3>
<pre><code class="language-cpp">void BindDistFleetWrapper(py::module* m) {
  py::class_&lt;FleetWrapper, std::shared_ptr&lt;FleetWrapper&gt;&gt;(*m,
                                                          &quot;DistFleetWrapper&quot;)
      .def(py::init([]() { return FleetWrapper::GetInstance(); }))
      .def(&quot;load_sparse&quot;, &amp;FleetWrapper::LoadSparseOnServer)
      .def(&quot;load_model&quot;, &amp;FleetWrapper::LoadModel)
      .def(&quot;load_one_table&quot;, &amp;FleetWrapper::LoadModelOneTable)
      .def(&quot;init_server&quot;, &amp;FleetWrapper::InitServer)
      .def(&quot;run_server&quot;,
           (uint64_t (FleetWrapper::*)(void)) &amp; FleetWrapper::RunServer)
      .def(&quot;run_server&quot;, (uint64_t (FleetWrapper::*)(          // NOLINT
                             const std::string&amp;, uint32_t)) &amp;  // NOLINT
                             FleetWrapper::RunServer)
      .def(&quot;init_worker&quot;, &amp;FleetWrapper::InitWorker)
      .def(&quot;push_dense_params&quot;, &amp;FleetWrapper::PushDenseParamSync)
      .def(&quot;pull_dense_params&quot;, &amp;FleetWrapper::PullDenseVarsSync)
      .def(&quot;save_all_model&quot;, &amp;FleetWrapper::SaveModel)
      .def(&quot;save_one_model&quot;, &amp;FleetWrapper::SaveModelOneTable)
      .def(&quot;recv_and_save_model&quot;, &amp;FleetWrapper::RecvAndSaveTable)
      .def(&quot;sparse_table_stat&quot;, &amp;FleetWrapper::PrintTableStat)
      .def(&quot;stop_server&quot;, &amp;FleetWrapper::StopServer)
      .def(&quot;stop_worker&quot;, &amp;FleetWrapper::FinalizeWorker)
      .def(&quot;barrier&quot;, &amp;FleetWrapper::BarrierWithTable)
      .def(&quot;shrink_sparse_table&quot;, &amp;FleetWrapper::ShrinkSparseTable)
      .def(&quot;set_clients&quot;, &amp;FleetWrapper::SetClients)
      .def(&quot;get_client_info&quot;, &amp;FleetWrapper::GetClientsInfo)
      .def(&quot;create_client2client_connection&quot;,
           &amp;FleetWrapper::CreateClient2ClientConnection);
}
</code></pre>
<h2 id="fleet-run_server"><a class="header" href="#fleet-run_server">fleet run_server</a></h2>
<pre><code class="language-python"># runtime 层初始化
class TheOnePSRuntime(RuntimeBase):
    def _init_server(self, dirname=None, var_names=None, **kwargs):
        # cpp instance
        self._server = fluid.core.DistFleetWrapper()
        self._server.init_server(server_desc, self.string_hosts, role_id,
                                 trainers, self._server_sub_program)
        # load_sparse 
        for var_name in load_varnames:
            table_id = sparse_table_maps[var_name]
            self._server.load_sparse(dirname, &quot;0&quot;, table_id)

    def _run_server(self):
        self._server.run_server(host, int(port))
</code></pre>
<h3 id="fleetwrapper"><a class="header" href="#fleetwrapper">FleetWrapper</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/wrapper/fleet.cc
// FleetWrapper 层
void FleetWrapper::InitServer(...){
    pserver_ptr_ = std::shared_ptr&lt;paddle::distributed::PSCore&gt;(
        new paddle::distributed::PSCore());
    pserver_ptr_-&gt;init_server(...)
}

uint64_t FleetWrapper::RunServer(...){
    auto ret = pserver_ptr_-&gt;run_server(ip, port);
}

void FleetWrapper::LoadSparseOnServer(...){
    // _server_ptr is PSServer
    pserver_ptr_-&gt;_server_ptr-&gt;table(table_id)-&gt;load(path, meta);
}
</code></pre>
<h3 id="pscore"><a class="header" href="#pscore">PSCore</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/ps_service/service.cc
// PSCore layer

int PSCore::init_server(...){
  _ps_env = paddle::distributed::PaddlePSEnvironment();
  _ps_env.set_ps_servers(host_sign_list, node_num);
  _ps_env.set_trainers(trainers); // 没啥用
  _server_ptr = std::shared_ptr&lt;paddle::distributed::PSServer&gt;(
      paddle::distributed::PSServerFactory::create(_ps_param));
  ret = _server_ptr-&gt;configure(_ps_param, _ps_env, index, server_sub_program);
}

uint64_t PSCore::run_server(const std::string&amp; ip, uint32_t port) {
  return _server_ptr-&gt;start(ip, port);
}
</code></pre>
<h3 id="psserver"><a class="header" href="#psserver">PSServer</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/server.cc
// PSServer layer

PSServer *PSServerFactory::create(const PSParameter &amp;ps_config) {
    PSServer *server =
      CREATE_PSCORE_CLASS(PSServer, service_param.server_class());
    TableManager::instance().initialize();
}

int32_t PSServer::configure(...){
    // for i in downpour_param.downpour_table_param_size()
    auto *table = CREATE_PSCORE_CLASS(
        Table, downpour_param.downpour_table_param(i).table_class());
    table-&gt;set_program_env(scope_.get(), place_, &amp;server_sub_program);
    table-&gt;set_shard(_rank, shard_num);
    table-&gt;initialize(downpour_param.downpour_table_param(i),
                      config.fs_client_param());
    _table_map[downpour_param.downpour_table_param(i).table_id()].reset(table);

    return initialize();
}
</code></pre>
<h3 id="brpcpsserver"><a class="header" href="#brpcpsserver">BrpcPsServer</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/brpc_ps_server.h
class BrpcPsServer : public PSServer {
    brpc::Server _server;
}

// paddle/fluid/distributed/ps/service/brpc_ps_server.cc
int32_t BrpcPsServer::initialize() {
    auto *service =
      CREATE_PSCORE_CLASS(PsBaseService, service_config.service_class());
    _server.AddService(service, brpc::SERVER_DOESNT_OWN_SERVICE)
}
uint64_t BrpcPsServer::start(const std::string &amp;ip, uint32_t port) {
    auto trainers = _environment-&gt;get_trainers(); // 可以去掉
    _server.Start(ip_port.c_str(), &amp;options)
    _environment-&gt;registe_ps_server(ip, port, _rank);
}
</code></pre>
<h3 id="brpcpsservice"><a class="header" href="#brpcpsservice">BrpcPsService</a></h3>
<pre><code class="language-cpp">class BrpcPsService : public PsBaseService {
  int32_t initialize_shard_info(...)
  int32_t pull_dense(...)
  int32_t push_dense(...)
  int32_t push_dense_param(...)
  int32_t push_sparse_param(...)
  int32_t pull_sparse(...)
  int32_t pull_geo_param(...)
  int32_t barrier(...)
  int32_t push_sparse(...)
  int32_t load_one_table(...)
  int32_t load_all_table(...)
  int32_t save_one_table(...)
  int32_t save_all_table(...)
  int32_t shrink_table(...)
  int32_t clear_one_table(...)
  int32_t clear_all_table(...)
  int32_t stop_server(...)
  int32_t start_profiler(...)
  int32_t stop_profiler(...)
  int32_t print_table_stat(...)
  int32_t push_global_step(...)
}
</code></pre>
<h2 id="fleet-run_worker"><a class="header" href="#fleet-run_worker">fleet run_worker</a></h2>
<h3 id="runtime-1"><a class="header" href="#runtime-1">runtime</a></h3>
<pre><code class="language-python"># runtime 层初始化
class TheOnePSRuntime(RuntimeBase):
    def _init_worker(self, scopes=None):
        # in init
        # self._worker = fluid.core.DistFleetWrapper()
        self._worker.init_worker(proto_txt, self.string_hosts, role_id)
        # GEO mode
        self._communicator = Communicator(...)
        self._communicator.init_with_ctx(...)
        # 
        info = self._worker.get_client_info()
        self._worker.set_clients(all_info) # _all_gather info is all_info
        self._worker.create_client2client_connection()
        #
        self._pull_all_dense(scopes, send_ctx, dense_map)
        # GEO mode
        self._communicator.start()    

    def _pull_all_dense(self, scopes, send_ctx, recv_map):
        for name, ctx in send_ctx.items():
            self._worker.pull_dense_params(scope, table_id, var_names)
</code></pre>
<h3 id="init-worker"><a class="header" href="#init-worker">init worker</a></h3>
<h3 id="fleetwrapper-1"><a class="header" href="#fleetwrapper-1">FleetWrapper</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/wrapper/fleet.cc
void FleetWrapper::InitWorker(...){
    ps_env_.set_ps_servers(&amp;host_sign_list, servers);
    worker_ptr_ = std::shared_ptr&lt;paddle::distributed::PSClient&gt;(
          paddle::distributed::PSClientFactory::create(ps_param));
    worker_ptr_-&gt;configure(ps_param, dense_pull_regions, ps_env_, index);
}

void FleetWrapper::PullDenseVarsSync(...){
    auto status = worker_ptr_-&gt;pull_dense(regions.data(), regions.size(), tid);
    status.wait();
}

int FleetWrapper::SetClients(std::vector&lt;uint64_t&gt;&amp; host_sign_list) {
    return ps_env_.set_ps_clients(host_sign_list.data(), node);
}
void FleetWrapper::CreateClient2ClientConnection() {
    worker_ptr_-&gt;create_client2client_connection(...)
}
</code></pre>
<h3 id="psclient"><a class="header" href="#psclient">PSClient</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/ps_client.cc

PSClient *PSClientFactory::create(const PSParameter &amp;ps_config) {
    PSClient *client = CREATE_PSCORE_CLASS(PSClient, service_param.client_class());
    TableManager::instance().initialize();
}

int32_t PSClient::configure(...){
    // for i in work_param.downpour_table_param_size()
    auto *accessor = CREATE_PSCORE_CLASS(
        ValueAccessor,
        work_param.downpour_table_param(i).accessor().accessor_class());
    accessor-&gt;configure(work_param.downpour_table_param(i).accessor());
    accessor-&gt;initialize();
    _table_accessors[work_param.downpour_table_param(i).table_id()].reset(accessor);
    return initialize();
}
</code></pre>
<h3 id="brpcpsclient"><a class="header" href="#brpcpsclient">BrpcPsClient</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/brpc_ps_client.cc
class BrpcPsClient : public PSClient {
    brpc::Server _server;
    DownpourPsClientService _service;
}

int32_t BrpcPsClient::initialize() {
    // for i in server_list.size()
    _server_channels[i][j].reset(new brpc::Channel());
    _server_channels[i][j]-&gt;Init(server_ip_port.c_str(), &quot;&quot;, &amp;options)
    // 启动client探听接口, 并相互建立连接
    start_client_service();
    // 异步push 请求队列初始化
    _push_dense_task_queue_map[table_id] = paddle::framework::MakeChannel&lt;DenseAsyncTask *&gt;();
    _push_sparse_task_queue_map[table_id] = paddle::framework::MakeChannel&lt;SparseAsyncTask *&gt;();
    // 启动异步push线程
    _async_push_sparse_thread = std::thread(std::bind(&amp;BrpcPsClient::push_sparse_task_consume, this));
    // _async_push_sparse_thread.detach();
    _async_push_dense_thread = std::thread(std::bind(&amp;BrpcPsClient::push_dense_task_consume, this));
}

// 启动client端RpcService 用于数据互发等操作
int32_t BrpcPsClient::start_client_service() {
    _service.configure(this, _client_id)
    _server.AddService(&amp;_service, brpc::SERVER_DOESNT_OWN_SERVICE);
    _server.Start(butil::my_ip_cstr(), brpc::PortRange(start_port, max_port), &amp;options)
    _env-&gt;registe_ps_client(...)
}

// how 弹性？？？
int32_t BrpcPsClient::create_client2client_connection(...){
    // for i in client_list.size()
    _client_channels[i].reset(new brpc::Channel());
    _client_channels[i]-&gt;Init(server_ip_port.c_str(), &quot;&quot;, &amp;options)
}
</code></pre>
<h3 id="downpourpsclientservice"><a class="header" href="#downpourpsclientservice">DownpourPsClientService</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/brpc_ps_client.cc

class DownpourPsClientService : public PsService {
    PSClient *_client;
    void service(...)
}
</code></pre>
<h2 id="communicator"><a class="header" href="#communicator">communicator</a></h2>
<pre><code class="language-python"># python/paddle/fluid/communicator.py

class Communicator(object):
    def init_with_ctx(self,...):
        self.communicator_ = core.DistCommunicator(self.mode,...)
    def start(self):
        # Start communicator. Should call before training process.
        self.communicator_.start()
</code></pre>
<h3 id="bind"><a class="header" href="#bind">bind</a></h3>
<pre><code class="language-cpp">// paddle/fluid/pybind/communicator_py.cc
void BindCommunicator(py::module* m) {
  // Communicator is already used by nccl, change to DistCommunicator
  py::class_&lt;Communicator, std::shared_ptr&lt;Communicator&gt;&gt;(*m, &quot;DistCommunicator&quot;)
  .def(py::init([](...){Communicator::InitInstance&lt;GeoCommunicator&gt;(...)}
  .def(&quot;start&quot;, &amp;Communicator::Start)
// paddle/fluid/distributed/ps/service/communicator/communicator.h
static Communicator *InitInstance(...){
    std::call_once(init_flag_, &amp;Communicator::InitWithRpcCtx&lt;T&gt;,...);
}
static void InitWithRpcCtx(...){
    communicator_.reset(new T(std::ref(envs)));
    communicator_-&gt;InitEnvs();
    communicator_-&gt;InitBrpcClient(dist_desc, host_sign_list);
    communicator_-&gt;InitImpl(send_ctx, recv_ctx, recv_scope);
}
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/communicator/communicator.cc
void Communicator::InitBrpcClient(...){
    auto fleet = paddle::distributed::FleetWrapper::GetInstance();
    _worker_ptr = fleet-&gt;worker_ptr_;
}
void AsyncCommunicator::InitImpl(...){
    // for varnames
    send_varname_to_queue_[var_name] = std::make_shared&lt;BlockingQueue&lt;std::shared_ptr&lt;Variable&gt;&gt;&gt;(send_queue_size_);
    send_threadpool_.reset(new ::ThreadPool(thread_pool_size_));
    }

void AsyncCommunicator::Start() {
    main_thread_.reset(new std::thread(std::bind(&amp;AsyncCommunicator::MainThread, this))); // MainThread/RecvThread
}

void AsyncCommunicator::MainThread() {
    while (running_) {
        SendByCommunicator();
        RpcProfilerControl();
    }
}
void AsyncCommunicator::RecvThread() {
    while (running_) {
        RecvByCommunicator();
    }
}
</code></pre>
<h2 id="train_from_dataset"><a class="header" href="#train_from_dataset">train_from_dataset</a></h2>
<pre><code class="language-python"># dataset
dataset = paddle.distributed.InMemoryDataset() # &quot;MultiSlotInMemoryDataFeed&quot;
dataset.load_into_memory()
dataset.init(...)
dataset.set_filelist(train_files_list)

# InMemoryDataset -- MultiSlotInMemoryDataFeed  -- InMemoryDataFeed -- DataFeed
# QueueDataset -- MultiSlotDataFeed -- PrivateQueueDataFeed -- DataFeed
# python/paddle/fluid/executor.py
</code></pre>
<pre><code class="language-python"># class Executor(object):
def train_from_dataset(self,...):
    return self._run_from_dataset(...)

def _run_from_dataset(self,...):
    # dataset
    dataset = paddle.fluid.DatasetFactory().create_dataset(...)
    dataset.set_xxx(...)
    dataset._prepare_to_run()
    # trainer
    scope, trainer = self._prepare_trainer(...)
    trainer._gen_trainer_desc()
    # self._default_executor = core.Executor(p)
    trainer_instance = self._default_executor.init_for_dataset(
                    program.desc, trainer._desc(), scope, dataset.dataset)
    # run
    self._default_executor.run_from_dataset(trainer_instance)

def _prepare_trainer(self,...):
    trainer = TrainerFactory()._create_trainer(program.program._fleet_opt)
    # trainer._set_thread(thread)
</code></pre>
<h3 id="excutor"><a class="header" href="#excutor">excutor</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/executor.cc

std::shared_ptr&lt;TrainerBase&gt; Executor::InitForDataset(...){
  // MultiTrainer
  std::shared_ptr&lt;TrainerBase&gt; trainer;
  trainer = TrainerFactory::CreateTrainer(trainer_desc.class_name());
  // initialize trainer
  trainer-&gt;Initialize(trainer_desc, dataset);
  trainer-&gt;SetScope(scope);
  // prepare training environment and helper environment
  trainer-&gt;InitTrainerEnv(main_program, place_);
  // Try to init other environment
  trainer-&gt;InitOtherEnv(main_program);
}

void Executor::RunFromDataset(std::shared_ptr&lt;TrainerBase&gt; trainer) {
    trainer-&gt;Run();
}
</code></pre>
<h3 id="multitrainer"><a class="header" href="#multitrainer">MultiTrainer</a></h3>
<pre><code class="language-cpp">//paddle/fluid/framework/trainer.h
class MultiTrainer : public TrainerBase {
    std::vector&lt;DataFeed*&gt; readers_;
    std::vector&lt;std::shared_ptr&lt;DeviceWorker&gt;&gt; workers_;
}

// paddle/fluid/framework/multi_trainer.cc
void MultiTrainer::Initialize(const TrainerDesc&amp; trainer_desc, Dataset* dataset) {
    // Dataset -&gt; DataFeed
    const std::vector&lt;paddle::framework::DataFeed*&gt; readers = dataset-&gt;GetReaders();
    thread_num_ = readers.size(); // !!! thread num
    workers_.resize(thread_num_); 
    // for i in thread_num_
    workers_[i] = DeviceWorkerFactory::CreateDeviceWorker(...)
    workers_[i]-&gt;Setxxx()
    workers_[i]-&gt;Initialize(trainer_desc);
    workers_[i]-&gt;SetDataFeed(readers[i]);
}

void MultiTrainer::Run() {
    // for i in thread_num_
    threads_.push_back(std::thread(&amp;DeviceWorker::TrainFiles, workers_[thidx].get()));
    // for th in threads_
    th.join();
}
</code></pre>
<h3 id="hogwildworker"><a class="header" href="#hogwildworker">HogwildWorker</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/device_worker.cc
void DeviceWorker::SetDataFeed(DataFeed* data_feed) {
  device_reader_ = data_feed;
}

// paddle/fluid/framework/hogwild_worker.cc
void HogwildWorker::Initialize(const TrainerDesc &amp;desc) {
}

void HogwildWorker::TrainFiles() {
    device_reader_-&gt;Start();
    while ((cur_batch = device_reader_-&gt;Next()) &gt; 0) {
        // for op in ops_
        op-&gt;Run(*thread_scope_, place_);
    }
}
</code></pre>
<h3 id="multislotinmemorydatafeed"><a class="header" href="#multislotinmemorydatafeed">MultiSlotInMemoryDataFeed</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/data_feed.cc

class InMemoryDataFeed : public DataFeed {
    // 下面的 channel 赋值在 DatasetImpl&lt;T&gt;::CreateReaders()
    // input 为全局，output 和 consume 独立
    paddle::framework::ChannelObject&lt;T&gt;* input_channel_;
    paddle::framework::ChannelObject&lt;T&gt;* output_channel_;
    paddle::framework::ChannelObject&lt;T&gt;* consume_channel_;
}

bool InMemoryDataFeed&lt;T&gt;::Start() {
    //  input
    channel
    global channel
    input_channel_-&gt;Read(data); 
    output_channel_-&gt;Write(std::move(data));
}

int InMemoryDataFeed&lt;T&gt;::Next() {
    while (index &lt; this-&gt;default_batch_size_) {
        output_channel_-&gt;Get(instance);
        ins_vec.push_back(instance);
        ++index;
        consume_channel_-&gt;Put(std::move(instance));
    }
    PutToFeedVec(ins_vec);
}

class MultiSlotInMemoryDataFeed : public InMemoryDataFeed&lt;Record&gt; {
}
</code></pre>
<h3 id="multislotdatafeed"><a class="header" href="#multislotdatafeed">MultiSlotDataFeed</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/data_feed.cc

class PrivateQueueDataFeed : public DataFeed {
    std::shared_ptr&lt;paddle::framework::ChannelObject&lt;T&gt;&gt; queue_;
}

bool PrivateQueueDataFeed&lt;T&gt;::Start() {
    read_thread_ = std::thread(&amp;PrivateQueueDataFeed::ReadThread, this);
}
void PrivateQueueDataFeed&lt;T&gt;::ReadThread() {
    while (PickOneFile(&amp;filename)) {
        fp_ = fs_open_read(filename, &amp;err_no, pipe_command_);
        while (ParseOneInstanceFromPipe(&amp;instance)) {
            queue_-&gt;Put(instance);
        }
    }
}
int PrivateQueueDataFeed&lt;T&gt;::Next() {
    while (index &lt; default_batch_size_) {
        queue_-&gt;Get(instance)
        AddInstanceToInsVec(&amp;ins_vec, instance, index++);
    }
    PutToFeedVec(ins_vec);
}

class MultiSlotDataFeed : public PrivateQueueDataFeed&lt;std::vector&lt;MultiSlotType&gt;&gt; {
}
</code></pre>
<h4 id="misc"><a class="header" href="#misc">Misc</a></h4>
<ol>
<li>InMemoryDataset 流程分析</li>
</ol>
<ul>
<li>
<p>LoadIntoMemory 把文件读取进 input_channel_，注意 input_channel_ 是全局共享，由 GetReaders() 返回时设定；</p>
</li>
<li>
<p>Start() 从 input_channel_ 读取一份数据进 output_channel_</p>
</li>
<li>
<p>Next() 从 output_channel_ 取数据进 consume_channel_</p>
</li>
</ul>
<ol start="2">
<li>input_channel_ 在哪里初始化？
data_set.cc 中 DatasetImpl<T>::CreateChannel()，它是全局的，最终调用在 dataset.py 中 self.dataset.create_channel()，所以 InMemoryDataset 有调用，QueueDataset 没有调用</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
