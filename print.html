<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Aller au boulot</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Projects excelling">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item "><a href="index.html"><strong aria-hidden="true">1.</strong> welcome</a></li><li class="chapter-item "><a href="survey/survey.html"><strong aria-hidden="true">2.</strong> survey</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="survey/pollux.html"><strong aria-hidden="true">2.1.</strong> pollux</a></li><li class="chapter-item "><a href="survey/adasum.html"><strong aria-hidden="true">2.2.</strong> adasum</a></li><li class="chapter-item "><a href="survey/adaptation_learning.html"><strong aria-hidden="true">2.3.</strong> adaptation_learning</a></li><li class="chapter-item "><a href="survey/gradient_descent.html"><strong aria-hidden="true">2.4.</strong> gradient_descent</a></li><li class="chapter-item "><a href="survey/auto_parallel.html"><strong aria-hidden="true">2.5.</strong> auto_parallel</a></li><li class="chapter-item "><a href="survey/scheduling.html"><strong aria-hidden="true">2.6.</strong> scheduling</a></li><li class="chapter-item "><a href="survey/gradient_compression/gradient_compression.html"><strong aria-hidden="true">2.7.</strong> gradient_compression</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="survey/gradient_compression/dgc.html"><strong aria-hidden="true">2.7.1.</strong> dgc</a></li><li class="chapter-item "><a href="survey/gradient_compression/csc.html"><strong aria-hidden="true">2.7.2.</strong> csc</a></li></ol></li><li class="chapter-item "><a href="survey/adaptive_training.html"><strong aria-hidden="true">2.8.</strong> adaptive training</a></li></ol></li><li class="chapter-item "><a href="pytorch/overview.html"><strong aria-hidden="true">3.</strong> pytorch</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="pytorch/tensor.html"><strong aria-hidden="true">3.1.</strong> tensor</a></li><li class="chapter-item "><a href="pytorch/autograd.html"><strong aria-hidden="true">3.2.</strong> autograd</a></li><li class="chapter-item "><a href="pytorch/profiler.html"><strong aria-hidden="true">3.3.</strong> profiler</a></li><li class="chapter-item "><a href="pytorch/hook.html"><strong aria-hidden="true">3.4.</strong> hook</a></li><li class="chapter-item "><a href="pytorch/elastic.html"><strong aria-hidden="true">3.5.</strong> elastic</a></li><li class="chapter-item "><a href="pytorch/patch.html"><strong aria-hidden="true">3.6.</strong> patch</a></li></ol></li><li class="chapter-item "><a href="paddle/paddle.html"><strong aria-hidden="true">4.</strong> paddle</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="paddle/ps/ps-code-overview.html"><strong aria-hidden="true">4.1.</strong> ps</a></li><li class="chapter-item "><a href="paddle/framework.html"><strong aria-hidden="true">4.2.</strong> framework</a></li><li class="chapter-item "><a href="paddle/cinn.html"><strong aria-hidden="true">4.3.</strong> cinn</a></li></ol></li><li class="chapter-item "><a href="horovod/horovod.html"><strong aria-hidden="true">5.</strong> horovod</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="horovod/run.html"><strong aria-hidden="true">5.1.</strong> run</a></li><li class="chapter-item "><a href="horovod/workflow.html"><strong aria-hidden="true">5.2.</strong> workflow</a></li><li class="chapter-item "><a href="horovod/object.html"><strong aria-hidden="true">5.3.</strong> object</a></li><li class="chapter-item "><a href="horovod/develop.html"><strong aria-hidden="true">5.4.</strong> develop</a></li><li class="chapter-item "><a href="horovod/pytorch.html"><strong aria-hidden="true">5.5.</strong> pytorch</a></li><li class="chapter-item "><a href="horovod/tensorflow.html"><strong aria-hidden="true">5.6.</strong> tensorflow</a></li><li class="chapter-item "><a href="horovod/elastic.html"><strong aria-hidden="true">5.7.</strong> elastic</a></li></ol></li><li class="chapter-item "><a href="ray/ray.html"><strong aria-hidden="true">6.</strong> ray</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="ray/overview.html"><strong aria-hidden="true">6.1.</strong> overview</a></li><li class="chapter-item "><a href="ray/gcs.html"><strong aria-hidden="true">6.2.</strong> gcs</a></li><li class="chapter-item "><a href="ray/raylet.html"><strong aria-hidden="true">6.3.</strong> raylet</a></li><li class="chapter-item "><a href="ray/api.html"><strong aria-hidden="true">6.4.</strong> api</a></li></ol></li><li class="chapter-item "><a href="python/python.html"><strong aria-hidden="true">7.</strong> python</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="python/concurrent.html"><strong aria-hidden="true">7.1.</strong> concurrent execution</a></li><li class="chapter-item "><a href="python/multiprocessing.html"><strong aria-hidden="true">7.2.</strong> multiprocessing</a></li><li class="chapter-item "><a href="python/decorator.html"><strong aria-hidden="true">7.3.</strong> decorator</a></li></ol></li><li class="chapter-item "><a href="kubernetes/kubernetes.html"><strong aria-hidden="true">8.</strong> kubernetes</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="kubernetes/scheduler.html"><strong aria-hidden="true">8.1.</strong> scheduler</a></li><li class="chapter-item "><a href="kubernetes/operator.html"><strong aria-hidden="true">8.2.</strong> operator</a></li><li class="chapter-item "><a href="kubernetes/device_plugin.html"><strong aria-hidden="true">8.3.</strong> device plugin</a></li><li class="chapter-item "><a href="kubernetes/docker.html"><strong aria-hidden="true">8.4.</strong> docker</a></li></ol></li><li class="chapter-item "><a href="tvm/tvm.html"><strong aria-hidden="true">9.</strong> tvm</a></li><li class="chapter-item "><a href="gloo/gloo.html"><strong aria-hidden="true">10.</strong> gloo</a></li><li class="chapter-item "><a href="nccl/nccl.html"><strong aria-hidden="true">11.</strong> nccl</a></li><li class="chapter-item "><a href="mpi/mpi.html"><strong aria-hidden="true">12.</strong> mpi</a></li><li class="chapter-item "><a href="nlp/nlp.html"><strong aria-hidden="true">13.</strong> nlp</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="nlp/transformer.html"><strong aria-hidden="true">13.1.</strong> transformer</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">Aller au boulot</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/kuizhiqing/aller-au-boulot" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="aller-au-boulot"><a class="header" href="#aller-au-boulot">Aller au boulot!</a></h1>
<p>Welcome to my notes space, I really appreciate if you find something helpful here.</p>
<p>Host on <a href="http://excel.kuizhiqing.cn/">excel.kuizhiqing.cn</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="survey"><a class="header" href="#survey">Survey</a></h1>
<p>Paper survey of personal interest.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="pollux"><a class="header" href="#pollux">Pollux</a></h1>
<h2 id="pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning"><a class="header" href="#pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning">Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning</a></h2>
<p>Aurick Qiao et al. Petuum, Inc, CMU, UCB, MBZUAI.</p>
<p>Award: Jay Lepreau Best Paper</p>
<p>集群调度的目标是为任务分配资源使得</p>
<ul>
<li>训练时间小</li>
<li>集群资源利用率高</li>
<li>同时保证公平</li>
</ul>
<p>一般的调度场景是提交任务时声明所需要的资源，
但是在深度学习任务中，资源分配之后如何高效地利用这些资源取决于如 batch size 和 learning rate 之类的配置，
这些配置一般是不属于调度器管理的。</p>
<p>由此，推出</p>
<p>Pollux: Co-adaptive Cluster Scheduler for DL</p>
<p>Pollux, 一个深度学习模型训练的互适应集群调度器。</p>
<p>它自动且动态地，</p>
<ul>
<li>从整个集群性能和公平性的角度进行资源分配</li>
<li>动态地为每个训练任务调整 batch size 和 learning rate</li>
</ul>
<p>什么是互适用呢？</p>
<ul>
<li>从整个集群的角度做调度决策，同时在任务级别来调整配置参数</li>
<li>单个任务会根据分配到的资源进行动态地调整</li>
</ul>
<p>结果：减少用户对任务的手动配置，缩短平均训练时常达 37-50%.</p>
<h3 id="背景"><a class="header" href="#背景">背景</a></h3>
<h4 id="分布式-深度学习模型训练-数据并行"><a class="header" href="#分布式-深度学习模型训练-数据并行">分布式-深度学习模型训练-数据并行</a></h4>
<ul>
<li>mini-batch 组装 [batch size]</li>
<li>计算梯度 [计算密集]</li>
<li>梯度聚合 [通信密集]</li>
<li>更新参数 [learning rate]</li>
</ul>
<h4 id="batch-size-对系统吞吐量的影响"><a class="header" href="#batch-size-对系统吞吐量的影响">batch size 对系统吞吐量的影响</a></h4>
<p>总体而言，大 batch size 能够获得更高的吞吐，同时，这个关系</p>
<ul>
<li>次/非线性 sub-linearly</li>
<li>一定量后，系统吞吐量不再随 gpu 数量提高</li>
</ul>
<p>问题在与多少 gpu 合适呢？这取决于</p>
<ul>
<li>模型结构</li>
<li>集群硬件</li>
<li>batch size 等等</li>
</ul>
<h4 id="batch-size-对实际效率statistical-efficiency的影响"><a class="header" href="#batch-size-对实际效率statistical-efficiency的影响">batch size 对实际效率（statistical efficiency）的影响</a></h4>
<p>batch size 并不是越大越好，因为</p>
<ul>
<li>需要同时调整 lr 确保模型质量（quality）[应该包括精度等指标]，而且很困难</li>
<li>增大 batch size 会降低训练的实际效率</li>
<li>大 batch size 训练的模型往往泛化能力较差</li>
</ul>
<p>对于同样的数据吞吐量，大 batch size 所需要的训练步数较少（二者乘积一定），
但从模型实际效率上看，大 batch size 需要更多步数才能取得同样的效果。</p>
<h4 id="整体训练性能"><a class="header" href="#整体训练性能">整体训练性能</a></h4>
<p>经过以上分析可以看出，系统的吞吐和实际的训练效率相对于 batch size 存在经典的 trade-off 曲线关系，
所以，我们需要也可以找出他们的交叉点以获得优化的整体训练性能。</p>
<p>然而，这个优化的 batch size 在不同的训练阶段是不一样的（即随时间变化），最多能差 10 倍多 [McCandlish et al. 2018]，
即需要随训练进度动态地调整 batch size 以获得最优。</p>
<h4 id="集群调度"><a class="header" href="#集群调度">集群调度</a></h4>
<ul>
<li>所需的 GPU 的取决于 batch size，反过来，合适的 batch size 取决于分配到的 GPU 资源</li>
<li>集群的 GPU 分配是一个全局的决策，需要考虑公平和竞争</li>
<li>batch size 的选取还取决于具体的任务，如拓展性和实际效率等</li>
</ul>
<p>用户在提交任务时决定上述配置是困难的，所以由集群调度器来调整这些配置参数可以优化深度学习模型的训练。</p>
<h4 id="pollux-集群调度器"><a class="header" href="#pollux-集群调度器">Pollux 集群调度器</a></h4>
<ul>
<li>计算模型训练性能</li>
<li>计算最优的资源需求、batch size、learning rate</li>
<li>重新调整资源分配，相应地调整任务的 batch size 和 learning rate</li>
</ul>
<h4 id="key-idea-goodput-not-throughput"><a class="header" href="#key-idea-goodput-not-throughput">Key Idea: Goodput, not Throughput</a></h4>
<p>Pollux 的优化目标是新定义的深度学习训练性能指标 goodput</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中，</p>
<ul>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> 资源分配向量，如 a_n = #GPU, 表示节点 n 上分配的 gpu 数</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> 每个 gpu 的 batch size</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> 梯度聚合步数</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 总 batch size，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span></li>
</ul>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span> 会在训练过程中由 Pollux 自动计算, 
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span> 表示的是系统吞吐量（examples/second），
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span> 表示实际训练效率（progress/example）.</p>
<h4 id="系统吞吐"><a class="header" href="#系统吞吐">系统吞吐</a></h4>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05556em;">γ</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.224108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05556em;">γ</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.05556em;">γ</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，</p>
<ul>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 每步训练的时间</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 计算梯度的时间</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 网络通信的时间</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> 梯度聚合的步数</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 计算和通信重合度</li>
</ul>
<p>Pollux 自动，</p>
<ul>
<li>确定合适的 gpu 数量和 batch size</li>
<li>使用梯度聚合提高 batch size 达到 gpu 显存上限</li>
<li>把任务尽可能放置（pack）在尽量少的节点上以减少网络负载</li>
</ul>
<h4 id="实际训练效率"><a class="header" href="#实际训练效率">实际训练效率</a></h4>
<p>每一个任务的实际训练效率可以表示为
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中，</p>
<ul>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示用户定义的 baseline batch size</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 表示 batch size</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 梯度噪声 [McCandlish et al. 2018]</li>
</ul>
<blockquote>
<p>用户可以选择较小的初始 batch size <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，Pollux 会选择不同的 bs 去平衡系统吞吐和实际训练效率。</p>
</blockquote>
<p>关于梯度噪声 Gradient noise scale</p>
<ul>
<li>较大的梯度噪声 -&gt; 使用较大的 mini-batch 能够获得较高的实际效率</li>
<li>接近收敛的低信噪比 -&gt; 更好的实际训练效率</li>
</ul>
<p>Pollux 能够在不进行提前训练的情况下使用 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span> 计算出任务的 GOODPUT.</p>
<h4 id="任务优化"><a class="header" href="#任务优化">任务优化</a></h4>
<p>在特定分配 gpu 为 a 的前提下，计算最优</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.933136em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.130248em;vertical-align:-0.380248em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.057252000000000025em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.380248em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></span></p>
<p>改变 batch size 的同时，learning rate 也需要同步改变。
Pollux 为用户提供更新策略</p>
<ul>
<li>Linear scaling</li>
<li>Square-root scaling</li>
<li>AdaScale (Johnson et al. 2020)</li>
</ul>
<h4 id="集群优化"><a class="header" href="#集群优化">集群优化</a></h4>
<p>优化目标</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.5200130000000005em;vertical-align:-1.4137769999999998em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:2.106236000000001em;"><span style="top:-4.281236000000001em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.399108em;vertical-align:-0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>p 是可变参数，用于控制任务间的公平性。</p>
<p>找到分配矩阵 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal">n</span></span></span></span> 表示节点 n 上分配给任务 j 的 gpu 数量。</p>
<ul>
<li>对 A 的寻找使用 metaheuristic algorithm</li>
<li>调度要避免频繁的重新分配</li>
<li>避免分布式任务共享节点</li>
</ul>
<h4 id="pollux-效果评估"><a class="header" href="#pollux-效果评估">Pollux 效果评估</a></h4>
<p>Pollux 带来的主要收益是在共享集群上自动配置任务。</p>
<p>重点评估目标：即使任务已经给定理想的静态配置，Pollux 仍然能够相比于传统集群调度器有所提升。
包括以下方面，</p>
<ul>
<li>真实的 Microsoft 深度学习分布式训练集群 (Jeon et al. 2019).</li>
<li>不同场景训练任务混合：图像分类、目标检测、语音识别、问答、推荐</li>
<li>手动配置 gpu 数量、batch size、learning rate、梯度聚合参数 (不使用Pollux，设定强baseline)</li>
</ul>
<p>实验数据表明 Pollux 能比专家配置的任务缩短 37-50% 的平均训练时间。</p>
<h4 id="总结"><a class="header" href="#总结">总结</a></h4>
<ul>
<li>Pollux 同时从集群和任务的角度对任务参数进行优化</li>
<li>Pollux 引入 goodput 概念，一种结合系统吞吐和实际效率的衡量标准</li>
<li>Pollux 实测缩短 37-50% 的平均训练时间</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="scaling-distributed-training-with-adaptive-summation"><a class="header" href="#scaling-distributed-training-with-adaptive-summation">Scaling distributed training with adaptive summation</a></h1>
<p>Saeed Maleki et al. Microsoft Research</p>
<h3 id="key-point"><a class="header" href="#key-point">Key point</a></h3>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9084399999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.391em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">∣</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.391em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">∣</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p align="center"> <img src="survey/./assets/adasum.png" /> </p>
<h3 id="reference"><a class="header" href="#reference">Reference</a></h3>
<ul>
<li><a href="https://horovod.readthedocs.io/en/stable/adasum_user_guide_include.html">AdaSum with Horovod</a></li>
<li><a href="https://arxiv.org/abs/2006.02924">Arxiv</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="adaptation-调研"><a class="header" href="#adaptation-调研">Adaptation 调研</a></h1>
<p>分布式训练的参数调整基本有以下共识：</p>
<ul>
<li>learning rate 需要根据 batch size 调整，以保证训练速度和收敛速度</li>
<li>learning rate 需要在不同的训练阶段进行调整以保证收敛速度
这个方向早期已经有比较多的研究，包括</li>
<li>Adam 2015，在 variance 较大时使用较小的 lr</li>
<li>LARS 2017，在每一层上根据 wieghts 和 gradient 适配 lr</li>
<li>LARM 2019，LARS + Adam</li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>最新的一些参数适配相关的研究进展：</p>
<div class="table-wrapper"><table><thead><tr><th>方法</th><th>年份</th><th>适用</th><th>作用于</th><th>Key Idea</th><th>会议</th><th>开源</th></tr></thead><tbody>
<tr><td>GNS</td><td>2018</td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>K-FAC</td><td>2019</td><td>-</td><td>gradients</td><td>Gradient second-order</td><td>cvpr2019</td><td></td></tr>
<tr><td>AdaScale</td><td>2020</td><td>SGD</td><td>lr</td><td>Gradient variance</td><td>ICML2020</td><td></td></tr>
<tr><td>Resource Elasticity...</td><td>2020</td><td>tf</td><td>framework</td><td>Worker performance</td><td>mlsys2020</td><td></td></tr>
<tr><td>Kungfu</td><td>2020</td><td>tf/torch</td><td>-</td><td>implementation</td><td>osdi20</td><td><a href="https://github.com/lsds/KungFu">KungFu</a></td></tr>
<tr><td>Pollux</td><td>2021</td><td></td><td></td><td></td><td>osdi21</td><td><a href="https://github.com/petuum/adaptdl">adaptdl</a></td></tr>
<tr><td>Adasum</td><td>2021</td><td>Momentum-SGD, Adam, and LAMB</td><td>gradients</td><td>combine gradient</td><td>mlsys2021</td><td><a href="https://github.com/horovod/horovod">horovod</a></td></tr>
<tr><td>DeepPool</td><td>2022</td><td>burst parallelism</td><td>gpu multiplexing</td><td>mlsys2022</td><td><a href="https://github.com/DeepPoolML/DeepPool">DeepPool</a></td><td></td></tr>
</tbody></table>
</div>
<p>An Empirical Model of Large-Batch Training
Sam McCandlish et al. OpenAI
总结：文章提出了 gradient noise scale (GNS) 指标，</p>
<ul>
<li>GNS 较小，保持 batch size</li>
<li>GNS 较大，增大 batch size
GNS 定义如下：</li>
</ul>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.767331em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">G</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord">Σ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中：</p>
<ul>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">G</span></span></span></span> true gradient</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span> true Hessian at parameter values</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Σ</span></span></span></span>  covariance matrix</li>
</ul>
<h3 id="adascale-sgd-a-scale-invariant-algorithm-for-distributed-training"><a class="header" href="#adascale-sgd-a-scale-invariant-algorithm-for-distributed-training">AdaScale SGD: A Scale-Invariant Algorithm for Distributed Training</a></h3>
<p>Tyler B. Johnson et al. APPLE</p>
<p>Key: Gradient variance</p>
<p>总结：adascale 根据 gradient variance 来调整 learning rate，提供稳定算法保证在不同的 batch size 下都能找到合适的 lr 保证快速收敛。</p>
<h3 id="scaling-distributed-training-with-adaptive-summation-1"><a class="header" href="#scaling-distributed-training-with-adaptive-summation-1">Scaling distributed training with adaptive summation</a></h3>
<p>Saeed Maleki et al. Microsoft Research</p>
<p>总结：adasum 利用 gradients 自身的数学性质，提出了一种新的 combine 方法，使得 merge 结果受 outlier 影响较小，更加“合理”，从而加快收敛。
算法公式</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9084399999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.391em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">∣</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.391em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">∣</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>示意图</p>
<p align="center"> <img src="survey/./assets/adasum.png" /> </p>
<h3 id="large-scale-distributed-second-order-optimization-using-kronecker-factored-approximate-curvature-for-deep-convolutional-neural-networks"><a class="header" href="#large-scale-distributed-second-order-optimization-using-kronecker-factored-approximate-curvature-for-deep-convolutional-neural-networks">Large-Scale Distributed Second-Order Optimization Using Kronecker-Factored Approximate Curvature for Deep Convolutional Neural Networks</a></h3>
<p>Kazuki Osawa et al. Tokyo Institute of Technology, NVIDIA</p>
<p>Key: Gradient second-order metrics</p>
<p>总结：通过计算 Fisher 矩阵二阶信息来更新梯度，每一步的计算速度会慢于sgd，但收敛所需步数减少，特别是在large scale 的场景，整体效率接近。</p>
<h3 id="resource-elasticity-in-distributed-deep-learning"><a class="header" href="#resource-elasticity-in-distributed-deep-learning">Resource Elasticity in Distributed Deep Learning</a></h3>
<p>Andrew Or et al. Princeton University, Google AI</p>
<p>autoscaling engine/system</p>
<p>总结：文章对分布式场景深度学习场景下的弹性系统进行了比较全面的梳理，着墨较多在弹性触发条件，但是对系统实现没有什么深入描述，这块创新性存疑。文中提到了依赖 tensorflow 和 horovod，姑且认为，默认实现方案为 horovod 吧。
文中涉及到了类似慢节点检测的机制（STRAGGLER DETECTION）。</p>
<h3 id="kungfu-making-training-in-distributed-machine-learning-adaptive"><a class="header" href="#kungfu-making-training-in-distributed-machine-learning-adaptive">KungFu: Making Training in Distributed Machine Learning Adaptive</a></h3>
<p>Luo Mai et al. Imperial College London</p>
<p>总结：kungfu 提供了一个统一的框架/库用来在分布式训练场景下进行不同 adaptation 操作，包括 api、monitor、control 等部分。</p>
<ul>
<li>提供 adaption policies 来定义不同 adaption</li>
<li>内置 monitoring，使得依赖各种 metric 做 adapt 决策变得容易</li>
<li>分布式参数 adpating 机制：提供弹性、异步 collective</li>
</ul>
<h3 id="pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning-1"><a class="header" href="#pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning-1">Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning</a></h3>
<p>Aurick Qiao et al. Petuum, Inc, CMU, UCB, MBZUAI.</p>
<p>总结：提出 goodput 指标用于计算优化配置，包括资源和参数 lr、bs。兼容其他如 adascale 策略。</p>
<h3 id="efficient-strong-scaling-through-burst-parallel-training"><a class="header" href="#efficient-strong-scaling-through-burst-parallel-training">Efficient Strong Scaling Through Burst Parallel Training</a></h3>
<p>Seo Jin Park et al.</p>
<p>DeepPool key ideas: 引入 foreground/background jobs</p>
<ul>
<li>burst parallelism</li>
<li>GPU multiplixing ： gpu 共享</li>
</ul>
<p>batch-optimal scaling : find (throughtput , sample efficienncy) for best time to accuracy</p>
<ul>
<li>Optimizing time-to-accuracy requires small per-GPU batches at large scale</li>
<li>Strong scaling and small per-GPU batches are more effective with fast networks</li>
<li>None of the approaches achieve perfect linear scaling</li>
</ul>
<p>实现特点：</p>
<ul>
<li>控制粒度到 layer 级别</li>
<li>针对静态图，生成 parallel training plan</li>
<li>stage 级别分配 gpu</li>
<li>backgroud job 为单机低优任务，现实场景中可能比较难有这样类型任务</li>
</ul>
<p>总结：依靠并行调度和 gpu 共享技术，引入foreground/background 区分任务优先级，计算最优资源需求和参数配置以获得高资源利用率和任务完成时效。
有点偏向于自动并行和 gpu 共享的混合产物。</p>
<p>strong scaling :  hold global batch size constant, decrease per-GPU batch size
weak scaling: increase the global batch size correspondingly, per-GPU batch size kept constant</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="gradient-descent"><a class="header" href="#gradient-descent">Gradient Descent</a></h1>
<h2 id="an-overview-of-gradient-descent-optimization-algorithms"><a class="header" href="#an-overview-of-gradient-descent-optimization-algorithms">An overview of gradient descent optimization algorithms</a></h2>
<p>Sebastian Ruder, Insight Centre for Data Analytics, NUI Galway Aylien Ltd., Dublin, 2017</p>
<h4 id="gradient-descent-1"><a class="header" href="#gradient-descent-1">Gradient Descent</a></h4>
<p>Multi-variable function <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69989em;vertical-align:-0.011em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">↦</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span>, 
defined differentiable in a neighborhood of a point <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span>,
for <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.897221em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.25833100000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> small enough,</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>leads to <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</p>
<p>If <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> convex and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> Lipschitz, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> converge to a local mimimum.</p>
<h4 id="optimization--momentum"><a class="header" href="#optimization--momentum">Optimization : Momentum</a></h4>
<p>Let <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>,</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">λ</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.</p>
<h4 id="optimization--nesterov"><a class="header" href="#optimization--nesterov">Optimization : Nesterov</a></h4>
<p>Version with correction,</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">λ</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>This anticipatory update prevents us from going too fast and results in increased responsiveness, which has significantly increased the performance of RNNs on a number of tasks.</p>
<h4 id="adagrad"><a class="header" href="#adagrad">Adagrad</a></h4>
<p>It adapts the learning rate to the parameters, performing larger updates for infrequent and smaller updates for frequent parameters. For this reason, it is well-suited for dealing with sparse data.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.30144em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.2583349999999998em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.851665em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.811665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18833500000000003em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>Application : learned to recognize cats in Youtube videos; GloVe word embeddings.</p>
<h4 id="adadelta"><a class="header" href="#adadelta">Adadelta</a></h4>
<p>Adadelta is an extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate. Instead of accumulating all past squared gradients, Adadelta restricts the window of accumulated past gradients to some fixed size w.</p>
<h4 id="rmsprop"><a class="header" href="#rmsprop">RMSprop</a></h4>
<p>RMSprop and Adadelta have both been developed independently around the same time stemming from the need to resolve Adagrad’s radically diminishing learning rates. RMSprop in fact is identical to the first update vector of Adadelta.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.2375599999999998em;vertical-align:-1.13em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.175em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.935em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span><span style="top:-2.8950000000000005em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30499999999999994em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.13em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<h4 id="adam"><a class="header" href="#adam">Adam</a></h4>
<p>Adaptive Moment Estimation (Adam) is another method that computes adaptive learning rates for each parameter. 
In addition to storing an exponentially decaying average of past squared gradients <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> like Adadelta and RMSprop, Adam also keeps an exponentially decaying average of past gradients <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, similar to momentum.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.024108em;vertical-align:-1.262054em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.762054em;"><span style="top:-3.922054em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.397946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.262054em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.762054em;"><span style="top:-3.922054em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-2.397946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.262054em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.5760000000000005em;vertical-align:-2.0380000000000003em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5380000000000003em;"><span style="top:-4.538em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">u</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.0380000000000003em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5380000000000003em;"><span style="top:-4.538em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.0380000000000003em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.03756em;vertical-align:-0.93em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.25278em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<h2 id="pytorch-implementation"><a class="header" href="#pytorch-implementation">PyTorch Implementation</a></h2>
<h4 id="sgd-momentum"><a class="header" href="#sgd-momentum">SGD, Momentum</a></h4>
<p>The implementation of SGD with Momentum/Nesterov subtly differs from
Sutskever et. al. and implementations in some other frameworks.</p>
<p>Considering the specific case of Momentum, the update can be written as</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000000000000004em;vertical-align:-1.2500000000000002em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord text"><span class="mord">lr</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span></span></span></span> denote the
parameters, gradient, velocity, and momentum respectively.</p>
<p>This is in contrast to Sutskever et. al. and
other frameworks which employ an update of the form</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000000000000004em;vertical-align:-1.2500000000000002em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord text"><span class="mord">lr</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>The Nesterov version is analogously modified.</p>
<pre><code class="language-python"># torch/optim/sgd.py

def _single_tensor_sgd(params: List[Tensor],
                       d_p_list: List[Tensor],
                       momentum_buffer_list: List[Optional[Tensor]],
                       *,
                       weight_decay: float,
                       momentum: float,
                       lr: float,
                       dampening: float,
                       nesterov: bool,
                       maximize: bool,
                       has_sparse_grad: bool):

    for i, param in enumerate(params):

        d_p = d_p_list[i]
        if weight_decay != 0:
            d_p = d_p.add(param, alpha=weight_decay)

        if momentum != 0:
            buf = momentum_buffer_list[i]

            if buf is None:
                buf = torch.clone(d_p).detach()
                momentum_buffer_list[i] = buf
            else:
                buf.mul_(momentum).add_(d_p, alpha=1 - dampening)

            if nesterov:
                d_p = d_p.add(buf, alpha=momentum)
            else:
                d_p = buf

        alpha = lr if maximize else -lr
        param.add_(d_p, alpha=alpha)

</code></pre>
<h4 id="adagrad-1"><a class="header" href="#adagrad-1">Adagrad</a></h4>
<p>Algorithm</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:22.068667999999995em;vertical-align:-10.999833999999998em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:11.068833999999999em;"><span style="top:-13.336393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-11.836393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-10.336393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-8.836393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-7.7673939999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-6.2673939999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-4.7673939999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-3.267393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-1.767393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:-0.267393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:1.256714000000001em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:3.0242740000000006em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:5.094274em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:6.1632739999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span><span style="top:7.2322739999999985em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:10.999833999999998em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:11.068833999999999em;"><span style="top:-13.336393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span><span style="top:-11.836393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">input</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord text"><span class="mord"> (lr)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> (params)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord text"><span class="mord"> (objective)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">λ</span><span class="mord text"><span class="mord"> (weight decay)</span></span><span class="mpunct">,</span></span></span><span style="top:-10.336393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:3.414330708661417em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mord text"><span class="mord"> (initial accumulator value)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord text"><span class="mord"> (lr decay)</span></span></span></span><span style="top:-8.836393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">initialize</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span><span style="top:-7.7673939999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span><span style="top:-6.2673939999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">for</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord text"><span class="mord textbf">to</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord textbf">do</span></span></span></span><span style="top:-4.7673939999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.267393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mclose">)</span></span></span><span style="top:-1.767393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord text"><span class="mord textbf">if</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span><span style="top:-0.267393999999999em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:1.256714000000001em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:3.0242740000000006em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.2924599999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.81754em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.77754em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.22246em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:5.094274em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span><span style="top:6.1632739999999995em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord"><span class="mord mathbf">r</span><span class="mord mathbf">e</span><span class="mord mathbf">t</span><span class="mord mathbf">u</span><span class="mord mathbf">r</span><span class="mord mathbf">n</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29444400000000004em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathbf mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span style="top:7.2322739999999985em;"><span class="pstrut" style="height:3.10756em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:10.999833999999998em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<pre><code class="language-python"># torch/optim/adagrad.py

def _single_tensor_adagrad(params: List[Tensor],
                           grads: List[Tensor],
                           state_sums: List[Tensor],
                           state_steps: List[Tensor],
                           *,
                           lr: float,
                           weight_decay: float,
                           lr_decay: float,
                           eps: float,
                           has_sparse_grad: bool):

    for (param, grad, state_sum, step_t) in zip(params, grads, state_sums, state_steps):
        # update step
        step_t += 1
        step = step_t.item()

        if weight_decay != 0:
            if grad.is_sparse:
                raise RuntimeError(&quot;weight_decay option is not compatible with sparse gradients&quot;)
            grad = grad.add(param, alpha=weight_decay)

        clr = lr / (1 + (step - 1) * lr_decay)

        if grad.is_sparse:
            grad = grad.coalesce()  # the update is non-linear so indices must be unique
            grad_indices = grad._indices()
            grad_values = grad._values()
            size = grad.size()

            state_sum.add_(_make_sparse(grad, grad_indices, grad_values.pow(2)))
            std = state_sum.sparse_mask(grad)
            std_values = std._values().sqrt_().add_(eps)
            param.add_(_make_sparse(grad, grad_indices, grad_values / std_values), alpha=-clr)
        else:
            is_complex = torch.is_complex(param)
            if is_complex:
                grad = torch.view_as_real(grad)
                state_sum = torch.view_as_real(state_sum)
                param = torch.view_as_real(param)
            state_sum.addcmul_(grad, grad, value=1)
            std = state_sum.sqrt().add_(eps)
            param.addcdiv_(grad, std, value=-clr)
            if is_complex:
                param = torch.view_as_complex(param)
                state_sum = torch.view_as_complex(state_sum)

</code></pre>
<h4 id="adam-1"><a class="header" href="#adam-1">Adam</a></h4>
<p>Algorithm</p>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:35.08656400000001em;vertical-align:-17.508782000000007em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:17.577782000000006em;"><span style="top:-19.759083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-18.259083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-16.759083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-15.259083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-14.190083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-12.690083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-11.190083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-9.690083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-8.190083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-6.690083000000006em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-5.190083000000006em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-3.690083000000004em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-2.190083000000004em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:-0.6659750000000026em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:0.8440249999999994em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:2.354025000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:3.854025000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:5.354025000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:7.035326000000002em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:8.535326000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:10.189481em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:11.689481em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:12.758481000000003em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span><span style="top:13.827481000000006em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:17.508782000000007em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:17.577782000000006em;"><span style="top:-19.759083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span><span style="top:-18.259083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">input</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord text"><span class="mord"> (lr)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> (betas)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> (params)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord text"><span class="mord"> (objective)</span></span></span></span><span style="top:-16.759083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:3.6988582677165356em;"></span><span class="mord mathnormal">λ</span><span class="mord text"><span class="mord"> (weight decay)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord textit">amsgrad</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord textit">maximize</span></span></span></span><span style="top:-15.259083000000008em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">initialize</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span><span class="mord text"><span class="mord"> ( first moment)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span><span class="mord text"><span class="mord"> (second moment)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7248519999999999em;"><span style="top:-3.12346em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span><span style="top:-14.190083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span><span style="top:-12.690083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">for</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord text"><span class="mord textbf">to</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord textbf">do</span></span></span></span><span style="top:-11.190083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord text"><span class="mord textbf">if</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord text"><span class="mord textit">maximize</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span><span style="top:-9.690083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">−</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-8.190083000000005em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord text"><span class="mord textbf">else</span></span></span></span><span style="top:-6.690083000000006em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-5.190083000000006em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord text"><span class="mord textbf">if</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span><span style="top:-3.690083000000004em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.190083000000004em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-0.6659750000000026em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span><span style="top:0.8440249999999994em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size1">)</span></span></span></span><span style="top:2.354025000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size1">)</span></span></span></span><span style="top:3.854025000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord text"><span class="mord textbf">if</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span></span></span><span style="top:5.354025000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7248519999999999em;"><span style="top:-3.12346em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7248519999999999em;"><span style="top:-3.12346em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:7.035326000000002em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.021301em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7248519999999999em;"><span style="top:-3.12346em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.981301em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.21869899999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span><span class="mord"><span class="delimsizing size1">)</span></span></span></span><span style="top:8.535326000000001em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226377952755906em;"></span><span class="mord text"><span class="mord textbf">else</span></span></span></span><span style="top:10.189481em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8452755905511813em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.994155em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6705599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-2.954155em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24584499999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span><span class="mord"><span class="delimsizing size1">)</span></span></span></span><span style="top:11.689481em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span><span style="top:12.758481000000003em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord"><span class="mord mathbf">r</span><span class="mord mathbf">e</span><span class="mord mathbf">t</span><span class="mord mathbf">u</span><span class="mord mathbf">r</span><span class="mord mathbf">n</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29444400000000004em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathbf mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span style="top:13.827481000000006em;"><span class="pstrut" style="height:3.0213010000000002em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298031496062993em;border-top-width:0.04000000000000001em;bottom:0em;"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:17.508782000000007em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<pre><code class="language-python"># torch/optim/adam.py

def _single_tensor_adam(params: List[Tensor],
                        grads: List[Tensor],
                        exp_avgs: List[Tensor],
                        exp_avg_sqs: List[Tensor],
                        max_exp_avg_sqs: List[Tensor],
                        state_steps: List[Tensor],
                        *,
                        amsgrad: bool,
                        beta1: float,
                        beta2: float,
                        lr: float,
                        weight_decay: float,
                        eps: float,
                        maximize: bool):

    for i, param in enumerate(params):

        grad = grads[i] if not maximize else -grads[i]
        exp_avg = exp_avgs[i]
        exp_avg_sq = exp_avg_sqs[i]
        step_t = state_steps[i]
        # update step
        step_t += 1
        step = step_t.item()

        bias_correction1 = 1 - beta1 ** step
        bias_correction2 = 1 - beta2 ** step

        if weight_decay != 0:
            grad = grad.add(param, alpha=weight_decay)

        # Decay the first and second moment running average coefficient
        exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)
        exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)
        if amsgrad:
            # Maintains the maximum of all 2nd moment running avg. till now
            torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])
            # Use the max. for normalizing running avg. of gradient
            denom = (max_exp_avg_sqs[i].sqrt() / math.sqrt(bias_correction2)).add_(eps)
        else:
            denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)



        step_size = lr / bias_correction1
        # param = param - step_size * (exp_avg / denom)
        # element-wise division
        param.addcdiv_(exp_avg, denom, value=-step_size)

</code></pre>
<p>AdamW is Adam with correct Weight Decay, when weight decay is 0, there is no difference between Adam and AdamW.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="auto-parallel"><a class="header" href="#auto-parallel">Auto Parallel</a></h1>
<h2 id="a-survey-on-auto-parallelism-of-neural-networks-training"><a class="header" href="#a-survey-on-auto-parallelism-of-neural-networks-training">A Survey on Auto-Parallelism of Neural Networks Training</a></h2>
<p>Peng Liang et. al. National University of Defense Technology</p>
<h3 id="abstract"><a class="header" href="#abstract">Abstract.</a></h3>
<p>DL --&gt; large model --&gt; distributed training --&gt; heterogeneous cluster --&gt; auto-parallelism --&gt; large scale DL model</p>
<ul>
<li>basic parallelism schemes, communication cost and memory consumption</li>
<li>current works, strategies, common methods</li>
<li>promising trends</li>
</ul>
<h3 id="introduction"><a class="header" href="#introduction">Introduction</a></h3>
<p>Parallelism strategy</p>
<ul>
<li>intra-operator parallelism: data parallelism, tensor parallelism (intra-layer model parallelism)</li>
<li>inter-operator parallelism: inter-layer model parallelism, pipeline parallelism</li>
</ul>
<p>Hybrid parallelism</p>
<ul>
<li>data + model + pipeline</li>
<li>Megatron-LM, DeepSpeed(3D parallelism)</li>
</ul>
<p>Manual --&gt; Auto</p>
<p>All practicable works: a few combinations of parallelism schemes, weak scalability</p>
<ul>
<li>e.g. cost model</li>
<li>automatic parallelism search space can be further expanded</li>
<li>heterogeneous devices, communication pace/topology</li>
</ul>
<h3 id="challenges"><a class="header" href="#challenges">Challenges</a></h3>
<ul>
<li>detailed analysis of different parallelism schemes</li>
<li>trade-offs between different parallelism schemes</li>
<li>load-balance across heterogeneous devices</li>
<li>optimization of network communication</li>
<li>trade-off between runtime and strategy performance in finding strategy</li>
</ul>
<h3 id="parallelism-schemes"><a class="header" href="#parallelism-schemes">Parallelism schemes</a></h3>
<p>Data parallelism</p>
<ul>
<li>Vanilla DP</li>
<li>ZeRO-Powered DP</li>
<li>Communication of DP, Centralized/Decentralized architecture</li>
</ul>
<p>ZeRO-DP</p>
<ul>
<li>three stages: 1 partition optimizer states, 2 partition gradients and optimizer states, 3 partition parameters</li>
<li>stage 1 and 2: reduce-scatter accumulated gradients, stage 3: all-gather updated parameters</li>
<li>solve redundancy problem with 50% more communication volume (all-gather)</li>
</ul>
<p>Model parallelism</p>
<ul>
<li>Intra-layer MP, tensor parallelism, partition weight tensor</li>
<li>Inter-layer MP</li>
</ul>
<p align="center"> <img src="survey/./assets/auto_mp.png" /> </p>
<p>Pipeline parallelism</p>
<p>The partition pattern of PP is the same as that of MP</p>
<ul>
<li>inter-layer MP = PP</li>
<li>PP = well scheduled pipelined MP</li>
<li>overlap computation, solve low-utility of MP</li>
</ul>
<p>PipeDream (Microsoft), GPipe (Google)</p>
<p align="center"> <img src="survey/./assets/auto_wise_mp.png" /> </p>
<h3 id="strategy-searching-methods-for-auto-parallelism"><a class="header" href="#strategy-searching-methods-for-auto-parallelism">Strategy Searching Methods for Auto-Parallelism</a></h3>
<ul>
<li>NP-hard problem</li>
<li>classic-algorithm-based v.s. machine-learning-based</li>
</ul>
<p>Classic-algorithm based methods</p>
<ul>
<li>recursive algorithm</li>
<li>dynamic programming algorithm</li>
<li>integer linear programming algorithm</li>
<li>breath-first-search (BFS) algorithm</li>
</ul>
<p>Machine-learning based methods</p>
<ul>
<li>Monte-Carlo Markov Chain (MCMC)</li>
<li>Monte-Carlo Tree Search (MCTS)</li>
<li>reinforcement learning</li>
</ul>
<h3 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h3>
<p>Accelerating strategy searching</p>
<ul>
<li>grouping</li>
<li>profiling-base cost model</li>
<li>using heuristics</li>
</ul>
<p>Optimizing parallelism strategies</p>
<ul>
<li>topology-aware computation</li>
<li>topology-aware communication</li>
</ul>
<p>Supporting more parallelism schemes</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="scheduling"><a class="header" href="#scheduling">Scheduling</a></h1>
<h2 id="osdi-2021"><a class="header" href="#osdi-2021">OSDI 2021</a></h2>
<h3 id="pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning-2"><a class="header" href="#pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning-2">Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning</a></h3>
<p>Aurick Qiao et al. Petuum, Inc, CMU, UCB. Cite 14</p>
<p>Award: Jay Lepreau Best Paper</p>
<h3 id="oort-efficient-federated-learning-via-guided-participant-selection"><a class="header" href="#oort-efficient-federated-learning-via-guided-participant-selection">Oort: Efficient Federated Learning via Guided Participant Selection</a></h3>
<p>Fan Lai et al. University of Michigan. Cite 17</p>
<h3 id="pet-optimizing-tensor-programs-with-partially-equivalent-transformations-and-automated-corrections"><a class="header" href="#pet-optimizing-tensor-programs-with-partially-equivalent-transformations-and-automated-corrections">PET: Optimizing Tensor Programs with Partially Equivalent Transformations and Automated Corrections</a></h3>
<p>Haojie Wang et al. Tsinghua, CMU, FB. Cite 4</p>
<h3 id="privacy-budget-scheduling"><a class="header" href="#privacy-budget-scheduling">Privacy Budget Scheduling</a></h3>
<p>Tao Luo et al. Columbia University, Microsoft Research. Cite 2</p>
<h2 id="osdi-2020"><a class="header" href="#osdi-2020">OSDI 2020</a></h2>
<h3 id="providing-slos-for-resource-harvesting-vms-in-cloud-platforms"><a class="header" href="#providing-slos-for-resource-harvesting-vms-in-cloud-platforms">Providing SLOs for Resource-Harvesting VMs in Cloud Platforms</a></h3>
<p>Pradeep Ambati et al. Microsoft Azure, Microsoft Research. </p>
<h3 id="the-cachelib-caching-engine-design-and-experiences-at-scale"><a class="header" href="#the-cachelib-caching-engine-design-and-experiences-at-scale">The CacheLib Caching Engine: Design and Experiences at Scale</a></h3>
<p>Benjamin Berg et al. CMU, FB, MS</p>
<h3 id="twine-a-unified-cluster-management-system-for-shared-infrastructure"><a class="header" href="#twine-a-unified-cluster-management-system-for-shared-infrastructure">Twine: A Unified Cluster Management System for Shared Infrastructure</a></h3>
<p>Chunqiang Tang et al. FB</p>
<h3 id="firm-an-intelligent-fine-grained-resource-management-framework-for-slo-oriented-microservices"><a class="header" href="#firm-an-intelligent-fine-grained-resource-management-framework-for-slo-oriented-microservices">FIRM: An Intelligent Fine-Grained Resource Management Framework for SLO-Oriented Microservices</a></h3>
<p>Haoran Qiu et al. UIUC</p>
<h3 id="building-scalable-and-flexible-cluster-managers-using-declarative-programming"><a class="header" href="#building-scalable-and-flexible-cluster-managers-using-declarative-programming">Building Scalable and Flexible Cluster Managers Using Declarative Programming</a></h3>
<p>Lalith Suresh et al. VMware, IST, UIUC ...</p>
<h3 id="protean-vm-allocation-service-at-scale"><a class="header" href="#protean-vm-allocation-service-at-scale">Protean: VM Allocation Service at Scale</a></h3>
<p>Ori Hadary et al. MS</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h2 id="1-bit-stochastic-gradient-descent-and-its-application-to-data-parallel-distributed-training-of-speech-dnns"><a class="header" href="#1-bit-stochastic-gradient-descent-and-its-application-to-data-parallel-distributed-training-of-speech-dnns">1-Bit Stochastic Gradient Descent and its Application to Data-Parallel Distributed Training of Speech DNNs</a></h2>
<p>Frank Seide et. al. MRA, Tsinghua, MR. INTERSPEECH 2014</p>
<p>1-BitSGDwithErrorFeedback</p>
<p>总结：1 bit 量化的思路是把每个 32 位的值按照正负分别用 1 或 0 量化，然后通信，更新时 1 则更新 +1，0 则更新 -1，同时本地量化差异保留补偿。这样的效果应该相当于本地梯度累积，每次通信根据正负同步 1 个单位的量。当然，每次更新带上系数，最终得到收敛效果。</p>
<h2 id="1-bit-adam-communication-efficient-large-scale-training-with-adams-convergence-speed"><a class="header" href="#1-bit-adam-communication-efficient-large-scale-training-with-adams-convergence-speed">1-bit Adam: Communication Efficient Large-Scale Training with Adam’s Convergence Speed</a></h2>
<p>Hanlin Tang et. al. Microsoft 2021</p>
<p>总结：adam 的梯度更新是非线性的，沿用 1bit sgd 的梯度累积或者说梯度补偿策略无法保证收敛性，文章提出了针对 adam 的保证收敛性的 1 bit 梯度量化方法并给出了理论证明。方法的核心在于在 warm-up 阶段计算 momentum 方差，用于后面进行误差补偿的计算。</p>
<h2 id="deep-gradient-compression-reducing-the-communication-bandwidth-for-distributed-training"><a class="header" href="#deep-gradient-compression-reducing-the-communication-bandwidth-for-distributed-training">Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</a></h2>
<p>Yujun Lin et. al. Tsinghua University, ICLR 2018</p>
<p><a href="https://github.com/synxlin/deep-gradient-compression">DGC</a></p>
<h2 id="optimizing-network-performance-for-distributed-dnn-training-on-gpu-clusters-imagenetalexnet-training-in-15-minutes"><a class="header" href="#optimizing-network-performance-for-distributed-dnn-training-on-gpu-clusters-imagenetalexnet-training-in-15-minutes">Optimizing Network Performance for Distributed DNN Training on GPU Clusters: ImageNet/AlexNet Training in 1.5 Minutes</a></h2>
<p>Peng Sun et. al. SenseTime 2019</p>
<h2 id="grace-a-compressed-communication-framework-for-distributed-machine-learning"><a class="header" href="#grace-a-compressed-communication-framework-for-distributed-machine-learning">GRACE: A Compressed Communication Framework for Distributed Machine Learning</a></h2>
<p>Hang Xu et. al. 2021</p>
<p><a href="https://github.com/sands-lab/grace">GRACE</a></p>
<h2 id="sidco-an-efficient-statistical-based-gradient-compression-technique-for-distributed-training-systems"><a class="header" href="#sidco-an-efficient-statistical-based-gradient-compression-technique-for-distributed-training-systems">SIDCo An Efficient Statistical-based Gradient Compression Technique for Distributed Training Systems</a></h2>
<p>Ahmed M. Abdelmoniem et. al. CEMSE, KAUST. MLSys 2021</p>
<p><a href="https://github.com/sands-lab/SIDCo">SIDCo</a></p>
<h2 id="powersgd-practical-low-rank-gradient-compression-for-distributed-optimization"><a class="header" href="#powersgd-practical-low-rank-gradient-compression-for-distributed-optimization">PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization</a></h2>
<p>Thijs Vogels et. al. EPFL. NeurIPS 2019</p>
<p><a href="https://github.com/epfml/powersgd">PowerSGD</a></p>
<h2 id="dont-use-large-mini-batches-use-local-sgd"><a class="header" href="#dont-use-large-mini-batches-use-local-sgd">Don't Use Large Mini-Batches, Use Local SGD</a></h2>
<p>Tao Lin et. al.  EPFL. ICLR 2020</p>
<p><a href="https://github.com/epfml/LocalSGD-Code">LocalSGD-Code</a></p>
<p>总结：为减轻同步模式中慢节点的影响，可以减少通信，这会带来精度损失。使用 local SGD 的方法可以现在节点内进行 SGD 更新，多步之后再同步各个节点上的参数。 post local SGD 的方法将训练过程分成两阶段：先使用同步 SGD，再增大同步间隔提高训练吞吐。</p>
<h2 id="adaptive-communication-strategies-to-achieve-the-best-error-runtime-trade-off-in-local-update-sgd"><a class="header" href="#adaptive-communication-strategies-to-achieve-the-best-error-runtime-trade-off-in-local-update-sgd">Adaptive Communication Strategies to Achieve the Best Error-Runtime Trade-off in Local-Update SGD</a></h2>
<p>Jianyu Wang et. al. Carnegie Mellon University. SysML 2019</p>
<p>总结：动态调整参数同步间隔来平衡训练吞吐和精度。</p>
<h2 id="overlap-local-sgd-an-algorithmic-approach-to-hide-communication-delays-in-distributed-sgd"><a class="header" href="#overlap-local-sgd-an-algorithmic-approach-to-hide-communication-delays-in-distributed-sgd">Overlap Local-SGD: An Algorithmic Approach to Hide Communication Delays in Distributed SGD</a></h2>
<p>Jianyu Wang et. al. ICASSP 2020</p>
<p><a href="https://github.com/JYWa/Overlap_Local_SGD">Overlap_Local_SGD</a></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="deep-gradient-compression"><a class="header" href="#deep-gradient-compression">Deep Gradient Compression</a></h1>
<h2 id="deep-gradient-compression-reducing-the-communication-bandwidth-for-distributed-training-1"><a class="header" href="#deep-gradient-compression-reducing-the-communication-bandwidth-for-distributed-training-1">Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</a></h2>
<p>Yujun Lin et. al. Tsinghua University, ICLR 2018</p>
<p>Gradient exchange require hight bandwidth,</p>
<ul>
<li>high latency</li>
<li>low throughput</li>
<li>poor connnection</li>
</ul>
<p>Since
<strong>99.9% of the gradient exchange in SGD are redundant,</strong>
propose
<strong>deep gradient compression (DGC)</strong>
to 
<strong>reduce communication bandwidth</strong>.</p>
<p>To preserve accuracy,</p>
<ul>
<li>momentum correction</li>
<li>local gradient clipping</li>
<li>momentum factor masking, alleviate staleness</li>
<li>warm-up training</li>
</ul>
<p>improving local gradient accumulation and overcomming the staleness effect</p>
<p>DGC </p>
<ul>
<li>pushes the gradient compression ratio to up to 600×</li>
<li>not need to change the model structure</li>
<li>no loss of accuracy</li>
</ul>
<p>How</p>
<ul>
<li>only gradients larger than a threshold are transmitted</li>
<li>accumulate the rest of the gradients locally, local gradient accumulation is equivalent to increasing the batch size over time</li>
</ul>
<p>DGC naively perform fine-grained (i.e., element-wise) top-k to select gradients, and thus the communication will suffer from increased allgather data volume as #nodes increases.</p>
<p>CSC modified the process with coarse-grained sparsification: gradients are partioned into chunks, allreduce the gradient chunks selected based on allreduced L1-norm of each chunk, which gets rid of the allgather and solves the problem.</p>
<p><a href="https://github.com/synxlin/deep-gradient-compression">deep-gradient-compression github</a></p>
<p>配置</p>
<pre><code class="language-python"># configs/dgc/__init__.py
</code></pre>
<p>训练流程</p>
<pre><code class="language-python"># train.py

from dgc.horovod.optimizer import DistributedOptimizer

# from dgc.compression import DGCCompressor
compression = configs.train.compression()
# cpr_parameters 即 dgc 处理的范围
compression.initialize(cpr_parameters.items())

# from dgc.optim import DGCSGD
optimizer = configs.train.optimizer(model.parameters())

# Horovod: wrap optimizer with DistributedOptimizer.
optimizer = DistributedOptimizer(
    optimizer, named_parameters=model.named_parameters(),
    compression=compression,
    backward_passes_per_step=configs.train.num_batches_per_step,
    op=hvd.Average
)

# 训练基本循环 zero_grad -&gt; loss.backward -&gt; optimizer.step
# 特别注意这里多次 backward 才走一次 step 更新
model.train()
for step, (inputs, targets) in enumerate(...):
    optimizer.zero_grad()

    # 这里用了内置循环累积梯度，比直接使用大 batch 剩显存
    # 注意这个 for 循环，对于 optimizer 里面理解 synchronize 过程非常重要
    for b in range(0, step_size, batch_size):
        _inputs = inputs[b:b+batch_size]
        _targets = targets[b:b+batch_size]
        _outputs = model(_inputs)
        _loss = criterion(_outputs, _targets)
        _loss.mul_(_r_num_batches_per_step)
        _loss.backward()
        loss += _loss.item()
    optimizer.step()
</code></pre>
<p>Optimizer</p>
<pre><code class="language-python"># dgc/horovod/optimizer.py

class _DistributedOptimizer(torch.optim.Optimizer):

    def __init__(self, ...):
        # 初始化最后注册 通信 hook
        self._register_hooks()
        
    def _register_hooks(self):
        for param_group in self.param_groups:
            for p in param_group['params']:
                if p.requires_grad:
                    # 注册函数只执行一次，这里 zero grad 不是每次调用 hook
                    p.grad = p.data.new(p.size()).zero_()
                    self._requires_update.add(p)
                    # 创建幽灵 tensor 来累积梯度，节点间同步，直至更新；
                    # p_tmp 和 p 使用同样的 storage，不占用额外显存
                    p_tmp = p.expand_as(p)
                    grad_acc = p_tmp.grad_fn.next_functions[0][0]
                    # 注册 _make_hook 这个关键 hook
                    grad_acc.register_hook(self._make_hook(p))
                    self._grad_accs.append(grad_acc)

    def _make_hook(self, p):
        # 这个 hook 有一个计数器，_allreduce_delay, 根据对象 p 不一样可以取不一样的值
        # 计数器不为零时跳过，这样可以让 grad 在本地累积，因为这个 hook 是做通信的
        # 效果为这个 hook 在多次调用才会被执行一次
        def hook(*ignore):
            handle, ctx = None, None
            self._allreduce_delay[p] -= 1
            if self._allreduce_delay[p] == 0:
                handle, ctx = self._allreduce_grad_async(p)
            self._handles[p] = (handle, ctx)
        return hook

    # 然后主要流程 step
    def step(self, closure=None):
        self.synchronize()
        return super(self.__class__, self).step(closure)

    # step 调用 synchronize, 可以有跳过逻辑
    def synchronize(self):
        # 处理 hook 注册不成功，或者说 hook 没有被调用
        # hook 被调用后会添加 self._handles
        missing_p = self._requires_update - set(self._handles.keys())
        for p in missing_p:
            handle, ctx = self._allreduce_grad_async(p)
            self._handles[p] = (handle, ctx)

        # handle 为 None 的 hook 跳过又不跳过了？
        # 需要注意 synchronize 函数每个 step 被调用，但不是每次 backward 都会被调用
        # 在之前的 train 中有每个 step 会多次 backward，所以 grad 的 hook 会被多次调用，次数匹配
        # 所以代码执行到这里 handle 应该是一次调用_allreduce_grad_async 如果不是就补上
        for p, (handle, ctx) in self._handles.items():
            if handle is None:
                handle, ctx = self._allreduce_grad_async(p)
                self._handles[p] = (handle, ctx)

        # for 循环处理异步通信的结果
        for p, (handle, ctx) in self._handles.items():
            output = self._synchronize_(handle)
            # 重置本地累积次数
            self._allreduce_delay[p] = self.backward_passes_per_step
            # 解压更新梯度
            p.grad.set_(self._compression.decompress(output, ctx))

        # 执行完毕，清理
        self._handles.clear()

    # 异步通信的 op，核心逻辑在 compression 中
    def _allreduce_grad_async(self, p):
        name = self._parameter_names.get(p)
        tensor_compressed, ctx = self._compression.compress(p.grad, name)

        handle = self._communicate_(tensor_compressed, name=name, op=self.op)
        return handle, ctx

</code></pre>
<ul>
<li>hook 函数是一次注册，多次调用，所以 <code>self._handles</code> 会不断被填充，每次 synchronize 后可以被 clear</li>
</ul>
<pre><code class="language-python"># dgc/compression.py

class DGCCompressor:
    def __init__(self, ...):
        self.attributes = {}

    def initialize(self, named_parameters):
        # 工作范围
        for name, param in named_parameters:
            self.attributes[name] = (numel, shape, num_selects, num_samples, top_k_samples, sample_stride)

    def _sparsify(self, tensor, name):
        # 选出稀疏的 tensor 去通信
        # 原实现中比较复杂
        # 先随机选取部分梯度值的 TOPK 来计算阈值
        # 然后通过该阈值对原 tensor 做稀疏化
        importance = tensor.abs()
        mask = torch.ge(importance, threshold)
        indices = mask.nonzero().view(-1)
        num_indices = indices.numel()
        # 这里实现上有个 for 循环确保选出的 topk 满足要求
        indices = indices[:num_selects]
        values = tensor[indices]
        return values, indices, numel, shape, num_selects

    def compress(self, tensor, name):
        if self.compress_ratio &lt; 1.0 and name in self.attributes:
            # compress
            tensor_compensated = self.memory.compensate(tensor, name, accumulate=True)
            values, indices, numel, shape, num_selects = self._sparsify(tensor_compensated, name)
            self.memory.update(name, (indices, ))
            return tensor, ctx
        else:
            return tensor, ctx

    def decompress(self, tensor, ctx):
        name, numel, shape, vdtype, idtype, grad = ctx
        if self.compress_ratio &lt; 1.0 and name in self.attributes:
            # 这里的 tensor 是个 tuple
            # decompress
            values, indices = tensor
            # 把同步回来的稀疏 tensor 对应位置更新
            # accumulate=True 处理 indices 中有重复的情况
            grad.zero_().index_put_([indices], values, accumulate=True)
            if self.op == Average:
                grad.mul_(1. / self.world_size)
            return grad.view(shape)
        else:
            return self.memory.compensate(tensor, name, accumulate=False)

    # optimizer _communicate_
    def communicate(self, tensor_compressed, name, op):
        # 两个分支
        if self.compress_ratio &lt; 1.0 and name in self.attributes:
            # dgc 分支，tensor_compressed 是 tuple，各个节点选的 topk index 不相同
            # 所以使用 allgather 交换，然后各自解压、更新
            return [allgather_async_(t, name=f'{name}.t{e}')
                    for e, t in enumerate(tensor_compressed)]
        else:
            # 普通分支，直接 allreduce 完整 tensor
            return allreduce_async_(tensor_compressed, name=name, op=op)

    # optimizer _synchronize_
    def synchronize(self, handle):
        # from horovod.torch.mpi_ops import synchronize as synchronize_
        if isinstance(handle, (tuple, list)):
            return [synchronize_(h) for h in handle]
        else:
            return synchronize_(handle)
</code></pre>
<p>为了保证精度文章中介绍了下面几种补偿策略</p>
<ul>
<li>momentum correction</li>
<li>local gradient clipping</li>
<li>momentum factor masking, alleviate staleness</li>
<li>warm-up training</li>
</ul>
<p>前三种策略在 Memory 实现</p>
<pre><code class="language-python"># dgc/memory.py

class DGCSGDMemory(Memory):

    def compensate(self, grad, name, accumulate=True):
        if self.gradient_clipping is not None:
            grad = self.gradient_clipping(grad)
        mmt = self.momentums[name]
        if accumulate:
            # Momentum Correction
            vec = self.velocities[name]
            if self.nesterov:
                mmt.add_(grad).mul_(self.momentum)
                vec.add_(mmt).add_(grad)
            else:
                mmt.mul_(self.momentum).add_(grad)
                vec.add_(mmt)
            return vec
        else:
            if self.nesterov:
                mmt.add_(grad).mul_(self.momentum)
                return mmt.add(grad)
            else:
                mmt.mul_(self.momentum).add_(grad)
                return mmt.clone()  # TODO: save this clone

    def update(self, name, ctx):
        indices = ctx[0]
        if self.momentum_masking:
            self.momentums[name].view(-1).index_fill_(0, indices, 0)
        self.velocities[name].view(-1).index_fill_(0, indices, 0)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h2 id="optimizing-network-performance-for-distributed-dnn-training-on-gpu-clusters-imagenetalexnet-training-in-15-minutes-1"><a class="header" href="#optimizing-network-performance-for-distributed-dnn-training-on-gpu-clusters-imagenetalexnet-training-in-15-minutes-1">Optimizing Network Performance for Distributed DNN Training on GPU Clusters: ImageNet/AlexNet Training in 1.5 Minutes</a></h2>
<p>Peng Sun et. al. SenseTime 2019</p>
<p>Communication backend: GradientFlow</p>
<ul>
<li>ring-based allreduce</li>
<li>mixed-precision training</li>
<li>computation/communication overlap</li>
<li>lazy allreduce: fusing multiple communication operations</li>
<li>coarse-grained sparse communication: only transmitting important gradient chunks</li>
</ul>
<p>and also,</p>
<ul>
<li>momentum SGD correction</li>
<li>warm-up dense training</li>
</ul>
<p>DGC naively perform fine-grained (i.e., element-wise) top-k to select gradients, and thus the communication will suffer from increased allgather data volume as #nodes increases.</p>
<p>CSC modified the process with coarse-grained sparsification: gradients are partioned into chunks, allreduce the gradient chunks selected based on allreduced L1-norm of each chunk, which gets rid of the allgather and solves the problem.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="adaptive-training"><a class="header" href="#adaptive-training">adaptive training</a></h1>
<embed src="assets/adaptive_training.pdf" width="100%" height="600" type="application/pdf" allowfullscreen>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="pytorch"><a class="header" href="#pytorch">pytorch</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="tensor"><a class="header" href="#tensor">Tensor</a></h1>
<h2 id="tensor-api-dependency"><a class="header" href="#tensor-api-dependency">Tensor API dependency</a></h2>
<p>The dependency of tensor related API</p>
<p><img src="pytorch/tensor-api.png" alt="Tensor View API Dependence" /></p>
<h2 id="view"><a class="header" href="#view">View</a></h2>
<p>Tensor view explication</p>
<p><img src="pytorch/tensor-view.png" alt="Tensor View API Dependence" /></p>
<h2 id="data-structure"><a class="header" href="#data-structure">Data Structure</a></h2>
<pre><code class="language-cpp">// torch/csrc/Module.cpp

extern &quot;C&quot;
TORCH_API PyObject* initModule();
PyObject* initModule() {
  THPUtils_addPyMethodDefs(methods, TorchMethods);

  static struct PyModuleDef torchmodule = {
     PyModuleDef_HEAD_INIT,
     &quot;torch._C&quot;,
     nullptr,
     -1,
     methods.data()
  };
  ASSERT_TRUE(module = PyModule_Create(&amp;torchmodule));
  ASSERT_TRUE(THPGenerator_init(module));
  ASSERT_TRUE(THPException_init(module));
  THPSize_init(module);
  THPDtype_init(module);
  THPDTypeInfo_init(module);
  THPLayout_init(module);
  THPMemoryFormat_init(module);
  THPQScheme_init(module);
  THPDevice_init(module);
  THPStream_init(module);
  ASSERT_TRUE(THPVariable_initModule(module));
  ASSERT_TRUE(THPFunction_initModule(module));
  ASSERT_TRUE(THPEngine_initModule(module));

  at::init();

  return module;
}
</code></pre>
<pre><code class="language-cpp">// torch/csrc/autograd/python_variable.cpp

bool THPVariable_initModule(PyObject *module)
{
  THPVariableMetaType.tp_base = &amp;PyType_Type;
  if (PyType_Ready(&amp;THPVariableMetaType) &lt; 0)
    return false;
  Py_INCREF(&amp;THPVariableMetaType);
  PyModule_AddObject(module, &quot;_TensorMeta&quot;,   (PyObject *)&amp;THPVariableMetaType);

  static std::vector&lt;PyMethodDef&gt; methods;
  THPUtils_addPyMethodDefs(methods, torch::autograd::variable_methods);
  THPUtils_addPyMethodDefs(methods, extra_methods);
  THPVariableType.tp_methods = methods.data();
  if (PyType_Ready(&amp;THPVariableType) &lt; 0)
    return false;
  Py_INCREF(&amp;THPVariableType);
  PyModule_AddObject(module, &quot;_TensorBase&quot;,   (PyObject *)&amp;THPVariableType);
  torch::autograd::initTorchFunctions(module);
  torch::autograd::initTensorImplConversion(module);
  return true;
}

PyTypeObject THPVariableType = {
    PyVarObject_HEAD_INIT(
        &amp;THPVariableMetaType,
        0) &quot;torch._C._TensorBase&quot;, /* tp_name */
    sizeof(THPVariable), /* tp_basicsize */
    0, /* tp_itemsize */
    ...
    THPVariable_pynew, /* tp_new */
};

PyTypeObject THPVariableMetaType = {
  PyVarObject_HEAD_INIT(DEFERRED_ADDRESS(&amp;PyType_Type), 0)
  &quot;torch._C._TensorMeta&quot;,                      /* tp_name */
  sizeof(THPVariableMeta),
  ...
  THPVariableMetaType_init,                    /* tp_init */
  nullptr,                                     /* tp_alloc */
  nullptr,                                     /* tp_new */
};
</code></pre>
<p>python 的 <code>_TensorBase</code> 绑定在 <code>THPVariableType</code> 上，python 相关的 <code>Tensor</code> 都继承自 <code>torch._C._TensorBase</code>.</p>
<pre><code class="language-cpp">// torch/csrc/autograd/python_variable.h

// Python object that backs torch.autograd.Variable
// NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)
struct THPVariable {
  PyObject_HEAD;
  // Payload
  c10::MaybeOwned&lt;at::Tensor&gt; cdata;
  // Hooks to be run on backwards pass (corresponds to Python attr
  // '_backwards_hooks', set by 'register_hook')
  PyObject* backward_hooks = nullptr;
};
</code></pre>
<pre><code class="language-cpp">// torch/csrc/autograd/function_hook.h

namespace torch { namespace autograd {

using Variable = at::Tensor;
using variable_list = std::vector&lt;Variable&gt;;

} }
</code></pre>
<p>PyTorch Tensor 相关主要数据结构和关系</p>
<p><img src="pytorch/1.png" alt="1" /></p>
<p>Tensor v.s. TensorBase</p>
<pre><code class="language-cpp">// aten/src/ATen/core/TensorBase.h

// Convert Tensor to TensorBase without any need to include Tensor.h
TORCH_API const TensorBase&amp; get_tensor_base(const Tensor&amp; t);

// NOTE: [Tensor vs. TensorBase]
//
// Tensor, being the central data structure in PyTorch, gets used and
// it's header included almost everywhere. Unfortunately this means
// every time an operator signature is updated or changed in
// native_functions.yaml, you (and every other PyTorch developer) need
// to recompile all of ATen and it's dependencies.
//
// TensorBase aims to break up these header dependencies, and improve
// incremental build times for all PyTorch developers. TensorBase
// represents a reference counted handle to TensorImpl, exactly the
// same as Tensor. However, TensorBase doesn't have code generated
// methods in it's API and thus no dependence on native_functions.yaml.
//
// Usage tips
// ----------
// - You can `#define TORCH_ASSERT_NO_OPERATORS` at the top of a .cpp
//   or .cu file to ensure it has no header dependencies on
//   native_functions.yaml (direct or indirect).
// - Tensor inherits from TensorBase, so functions taking
//   `const TensorBase &amp;` are callable with Tensor as well.
// - TensorBase can be converted to tensor with `Tensor(tensor_base)`,
//   but this requires a reference-count bump. OptionalTensorRef on
//   the other hand can materialize a `const Tensor &amp;` without
//   touching the reference-count.
class TORCH_API TensorBase {
 public:
  const c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt;&amp; getIntrusivePtr() const {
    return impl_;
  }

  c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt; unsafeReleaseIntrusivePtr() {
    return std::move(impl_);
  }

  DispatchKeySet key_set() const {
    return impl_-&gt;key_set();
  }
  ScalarType scalar_type() const {
    return typeMetaToScalarType(impl_-&gt;dtype());
  }
  const Storage&amp; storage() const {
    return impl_-&gt;storage();
  }

  Layout layout() const noexcept {
    return impl_-&gt;layout();
  }

  caffe2::TypeMeta dtype() const noexcept {
    return impl_-&gt;dtype();
  }

  inline Device device() const {
    return impl_-&gt;device();
  }

  int64_t get_device() const {
    // NB: this is not a native function to avoid dispatching overhead.
    return impl_-&gt;get_device();
  }

  TensorOptions options() const {
    return TensorOptions().dtype(dtype())
                          .device(device())
                          .layout(layout());
  }

  void* data_ptr() const {
    return this-&gt;unsafeGetTensorImpl()-&gt;data();
  }

  template &lt;typename T&gt;
  T * data_ptr() const;

  at::TensorBase tensor_data() const;

  at::TensorBase variable_data() const;

  const std::shared_ptr&lt;torch::autograd::Node&gt;&amp; grad_fn() const;

protected:
  c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt; impl_;
};
</code></pre>
<p><code>Tensor</code> 继承自 <code>TensorBase</code>, <code>TensorBase</code> 不依赖 function 自动生成，使用 <code>TensorBase</code> 可以避免自动生成部分有改动时全量编译，其次是引用计数问题。</p>
<p>Tensor 的继承关系</p>
<p><img src="pytorch/2.png" alt="1" /></p>
<p><code>at:Tensor</code> 本质是 Tensor 的 API，底层是 <code>TensorImpl</code></p>
<pre><code class="language-cpp">// c10/core/TensorImpl.h

/**
 * The low-level representation of a tensor, which contains a pointer
 * to a storage (which contains the actual data) and metadata (e.g., sizes and
 * strides) describing this particular view of the data as a tensor.
 *
 */

struct C10_API TensorImpl : public c10::intrusive_ptr_target {
  enum ImplType { VIEW };

 public:

  virtual IntArrayRef strides() const;

  TENSORIMPL_MAYBE_VIRTUAL const Storage&amp; storage() const {
    return storage_;
  }

  Device device() const {
    return *device_opt_;
  }

  Layout layout() const {
    // This keyset must also be kept in sync with the logic in
    // is_sparse() / is_sparse_csr() / is_mkldnn()
    constexpr auto sparse_and_sparsecsr_and_mkldnn_ks =
        c10::sparse_ks | c10::sparse_csr_ks | c10::mkldnn_ks;
    ...
  }

  Storage storage_;

  inline T* data() const {
      return data_ptr_impl&lt;T&gt;();
  }
  inline T* data_ptr_impl() const {
      return storage_.unsafe_data&lt;T&gt;() + storage_offset_;
  }

  inline void* data() const {
      return static_cast&lt;void*&gt;(
        static_cast&lt;char*&gt;(storage_.data()) +
        data_type_.itemsize() * storage_offset_);
  }

  const caffe2::TypeMeta dtype() const {
    return data_type_;
  }

  DeviceType device_type() const {
    return (*device_opt_).type();
  }

 private:
  // This pointer points to an AutogradMeta struct that stores autograd-specific
  // fields (such as grad_ / grad_fn_ / grad_accumulator_). This pointer always
  // has unique ownership (meaning only one TensorImpl can own it at a time).
  //
  std::unique_ptr&lt;c10::AutogradMetaInterface&gt; autograd_meta_ = nullptr;

 protected:
  std::unique_ptr&lt;c10::NamedTensorMetaInterface&gt; named_tensor_meta_ = nullptr;

  c10::VariableVersion version_counter_;

  PyObject* pyobj_;

  c10::impl::SizesAndStrides sizes_and_strides_;

  caffe2::TypeMeta data_type_;

  c10::optional&lt;c10::Device&gt; device_opt_;

  const at::Tensor&amp; grad() const;
}
</code></pre>
<p>Storage</p>
<pre><code class="language-cpp">// c10/core/Storage.h

struct C10_API Storage {

  void* data() const {
    return storage_impl_.get()-&gt;data();
  }

  at::DataPtr&amp; data_ptr() {
    return storage_impl_-&gt;data_ptr();
  }

  const at::DataPtr&amp; data_ptr() const {
    return storage_impl_-&gt;data_ptr();
  }

 protected:
  c10::intrusive_ptr&lt;StorageImpl&gt; storage_impl_;
};
</code></pre>
<p>StorageImpl</p>
<pre><code class="language-cpp">// c10/core/StorageImpl.h 

struct C10_API StorageImpl : public c10::intrusive_ptr_target {
 private:
  DataPtr data_ptr_;
  size_t size_bytes_;
  bool resizable_;
  bool received_cuda_;
  Allocator* allocator_;
</code></pre>
<p>UniqueVoidPtr </p>
<pre><code class="language-cpp">// c10/util/UniqueVoidPtr.h

namespace c10 {

using DeleterFnPtr = void (*)(void*);

namespace detail {

class UniqueVoidPtr {
 private:
  void* data_;
  std::unique_ptr&lt;void, DeleterFnPtr&gt; ctx_;
}

} }
</code></pre>
<p><code>detail::UniqueVoidPtr</code> is an owning smart pointer like <code>unique_ptr</code></p>
<ul>
<li>specialized to void </li>
<li>specialized for a function pointer deleter <code>void(void* ctx)</code></li>
<li>deleter is guaranteed to be called when the unique pointer is destructed and the context is non-null</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="autograd"><a class="header" href="#autograd">Autograd</a></h1>
<pre><code class="language-cpp">// torch/csrc/autograd/variable.h

struct TORCH_API AutogradMeta : public c10::AutogradMetaInterface {
  std::string name_;

  Variable grad_;
  std::shared_ptr&lt;Node&gt; grad_fn_;
  std::weak_ptr&lt;Node&gt; grad_accumulator_;

  std::shared_ptr&lt;ForwardGrad&gt; fw_grad_;

  std::vector&lt;std::shared_ptr&lt;FunctionPreHook&gt;&gt; hooks_;
  std::shared_ptr&lt;hooks_list&gt; cpp_hooks_list_;
}
</code></pre>
<p>AutogradMeta 中包含 autograd 所需的元素</p>
<ul>
<li>grad_: Tensor 对应的 grad</li>
<li>grad_fn_: 反向 op</li>
<li>grad_accumulator_: 反向梯度累加器，Node 类型</li>
<li>cpp_hooks_list_, hooks_: 反向调用时的 hook</li>
</ul>
<h2 id="node"><a class="header" href="#node">Node</a></h2>
<p>Node</p>
<ul>
<li>The most important method on <code>Node</code> is the call operator, which takes in a list of variables and produces a list of variables. </li>
<li>The precise size of these lists can be determined with <code>num_inputs()</code> and <code>num_outputs()</code>.</li>
<li><code>Node</code>s are stitched together via their <code>next_edge</code> interface, which let you manipulate the set of outgoing edges of a <code>Node</code>. </li>
<li>You can add an edge with <code>add_next_edge()</code>, retrieve an edge with <code>next_edge(index)</code> and iterate over them via the <code>next_edges()</code> method. </li>
</ul>
<pre><code class="language-cpp">// torch/csrc/autograd/function.h

using edge_list = std::vector&lt;Edge&gt;;

struct TORCH_API Node : std::enable_shared_from_this&lt;Node&gt; {
 public:
  explicit Node(
      uint64_t sequence_nr,
      edge_list&amp;&amp; next_edges = edge_list())
      : sequence_nr_(sequence_nr),
      next_edges_(std::move(next_edges)) {

    for (const Edge&amp; edge: next_edges_) {
      update_topological_nr(edge);
    }
  }

  variable_list operator()(variable_list&amp;&amp; inputs) {
    ...
    return apply(std::move(inputs));
  }


  void update_topological_nr(const Edge&amp; edge) {
    Node* node = edge.function.get();
    if (node) {
      auto topo_nr = node-&gt;topological_nr();
      if (topological_nr_ &lt;= topo_nr) {
        topological_nr_ = topo_nr + 1;
      }
    }
  }

  void set_next_edge(size_t index, Edge edge) {
    update_topological_nr(edge);
    next_edges_[index] = std::move(edge);
  }

  void add_next_edge(Edge edge) {
    update_topological_nr(edge);
    next_edges_.push_back(std::move(edge));
  }

  void set_next_edges(edge_list&amp;&amp; next_edges) {
    next_edges_ = std::move(next_edges);
    for (const auto&amp; next_edge : next_edges_) {
      update_topological_nr(next_edge);
    }
  }

  const Edge&amp; next_edge(size_t index) const noexcept {
    return next_edges_[index];
  }

  const edge_list&amp; next_edges() const noexcept {
    return next_edges_;
  }

  edge_list&amp; next_edges() noexcept {
    return next_edges_;
  }

 protected:
  virtual variable_list apply(variable_list&amp;&amp; inputs) = 0;

  const uint64_t sequence_nr_;
  uint64_t topological_nr_ = 0;
  uint64_t thread_id_ = 0;
  edge_list next_edges_;
  std::vector&lt;std::unique_ptr&lt;FunctionPreHook&gt;&gt; pre_hooks_;
  std::vector&lt;std::unique_ptr&lt;FunctionPostHook&gt;&gt; post_hooks_;
  at::SmallVector&lt;InputMetadata, 2&gt; input_metadata_;
};
</code></pre>
<p>可以看到</p>
<ul>
<li>Node 的创建由 Edge 来完成，Node 中保存了连接情况和需要执行的方法。</li>
<li>Node 本身是 callable object, 通过虚函数 apply 被子类重载实现。</li>
<li>set_next_edge 方法可以添加 Edge</li>
</ul>
<p>Edge</p>
<pre><code class="language-cpp">// torch/csrc/autograd/edge.h

struct Edge {
  Edge() noexcept : function(nullptr), input_nr(0) {}

  Edge(std::shared_ptr&lt;Node&gt; function_, uint32_t input_nr_) noexcept
      : function(std::move(function_)), input_nr(input_nr_) {}

  // Required for use in associative containers.
  bool operator==(const Edge&amp; other) const noexcept {
    return this-&gt;function == other.function &amp;&amp; this-&gt;input_nr == other.input_nr;
  }

  bool operator!=(const Edge&amp; other) const noexcept {
    return !(*this == other);
  }

  /// The function this `Edge` points to.
  std::shared_ptr&lt;Node&gt; function;

  /// The identifier of a particular input to the function.
  uint32_t input_nr;
};
</code></pre>
<h2 id="workflow"><a class="header" href="#workflow">Workflow</a></h2>
<pre><code class="language-python">import torch
a = torch.tensor(1.0, requires_grad=True)
b = torch.tensor(2.0, requires_grad=True)
c = torch.add(a, b)
d = torch.mul(a, c)
d.backward()
print(f&quot;a grad:{a.grad} grad_fn:{a.grad_fn}&quot;)
print(f&quot;b grad:{b.grad} grad_fn:{b.grad_fn}&quot;)
print(f&quot;c grad:{c.grad} grad_fn:{c.grad_fn}&quot;)
print(f&quot;d grad:{d.grad} grad_fn:{d.grad_fn}&quot;)
'''
a grad:4.0 grad_fn:None
b grad:1.0 grad_fn:None
c grad:None grad_fn:&lt;AddBackward0 object at 0x7f6862dc76d0&gt;
d grad:None grad_fn:&lt;MulBackward0 object at 0x7f6862dc76d0&gt;
'''
</code></pre>
<p>以上代码的网络构建如图所示</p>
<p><img src="pytorch/4.png" alt="1" /></p>
<p>下面解析详细过程.</p>
<p>在之前的版本中，<code>torch.tensor()</code> 的 bind 来自于自动代码生成，相关生成逻辑参考以下两个部分，</p>
<pre><code class="language-cpp">// tools/autograd/templates/python_torch_functions.cpp

static PyMethodDef torch_functions_shard[] = {
  {py_method_defs}
};
</code></pre>
<pre><code class="language-python"># tools/autograd/gen_python_functions.py

def create_python_bindings(...
def create_python_bindings_sharded(...
</code></pre>
<p>最新的 pytorch 使用 python object 暴露 python tensor. 对应类型 THPVariable_tensor.</p>
<pre><code class="language-cpp">// torch/csrc/autograd/python_torch_functions_manual.cpp

// implemented on python object to allow torch.tensor to be constructed with
// arbitrarily nested python objects - list, tuple, np array, scalar, etc.
static PyObject* THPVariable_tensor( PyObject* self, PyObject* args, PyObject* kwargs) {
  jit::tracer::warn(&quot;torch.tensor&quot;, jit::tracer::WARN_CONSTRUCTOR);
  return THPVariable_Wrap(torch::utils::tensor_ctor(
      torch::tensors::get_default_dispatch_key(),
      torch::tensors::get_default_scalar_type(),
      r));
}
</code></pre>
<ul>
<li>torch::utils::tensor_ctor() 返回 cpp tensor</li>
<li>torch::tensors::get_default_dispatch_key() 获取默认 dispatch key</li>
<li>torch::tensors::get_default_scalar_type() 获取默认数据类型</li>
<li>THPVariable_Wrap 把 tensor 封装成 python 可使用的 THPVariable</li>
</ul>
<p><img src="pytorch/3.png" alt="1" /></p>
<h3 id="tensor_new"><a class="header" href="#tensor_new">tensor_new</a></h3>
<pre><code class="language-cpp">// torch/csrc/utils/tensor_new.cpp

Tensor tensor_ctor(
    c10::DispatchKey dispatch_key,
    at::ScalarType scalar_type,
    PythonArgs&amp; r) {
  if (r.idx == 0) {
    PyObject* data = r.pyobject(0);
    bool type_inference = r.isNone(1);
    bool pin_memory = r.toBool(3);
    bool args_requires_grad = r.toBool(4);
    auto new_tensor = internal_new_from_data(
        typeIdWithDefault(r, 2, dispatch_key),
        r.scalartypeWithDefault(1, scalar_type),
        r.deviceOptional(2),
        data,
        /*copy_variables=*/true,
        /*copy_numpy=*/true,
        /*type_inference=*/type_inference,
        pin_memory);
    auto names = r.toDimnameListOptional(5);
    if (names) {
      at::namedinference::propagate_names(
          new_tensor, *names, /*validate_names=*/true);
    }
    new_tensor.detach_(); // ensure new_tensor a leaf node
    new_tensor.set_requires_grad(args_requires_grad);
    return new_tensor;
  }
}
</code></pre>
<ul>
<li>解析参数</li>
<li>调用 internal_new_from_data 创建 cpp tensor，初始化 storage_</li>
<li>new_tensor.detach_() 确保是叶子结点，初始化 autograd_meta_</li>
</ul>
<h3 id="internal_new_from_data"><a class="header" href="#internal_new_from_data">internal_new_from_data</a></h3>
<pre><code class="language-cpp">// torch/csrc/utils/tensor_new.cpp

Tensor internal_new_from_data(
    c10::TensorOptions options,
    at::ScalarType scalar_type,
    c10::optional&lt;Device&gt; device_opt,
    PyObject* data,
    bool copy_variables,
    bool copy_numpy,
    bool type_inference,
    bool pin_memory = false) {
  if (THPVariable_Check(data)) {
    auto var = THPVariable_Unpack(data);
    return var.to(...);
  }

  if (PyObject_HasAttrString(data, &quot;__cuda_array_interface__&quot;)) {
    auto tensor = tensor_from_cuda_array_interface(data);
    return tensor.to(...);
  }

  if (is_numpy_available() &amp;&amp; PyArray_Check(data)) {
     auto tensor = tensor_from_numpy(data, /*warn_if_not_writeable=*/!copy_numpy);
     return tensor.to(...);
  }

  auto device = device_opt.has_value() ? *device_opt : options.device();
  auto sizes = compute_sizes(data, scalar_type);
  ScalarType inferred_scalar_type = type_inference ? infer_scalar_type(data) : scalar_type;

  Tensor tensor;
  {
    {
      if (isStorage(data)) {
        Storage storage = createStorageGetType(data, storage_scalar_type, is_typed_storage);
        tensor = at::empty( sizes,
            at::initialTensorOptions().dtype( is_typed_storage ? storage_scalar_type : inferred_scalar_type)
                .pinned_memory(pin_memory)
                .device(storage.device()));
        tensor.set_(storage);

      } else {
        TensorOptions opts = at::initialTensorOptions().dtype(inferred_scalar_type);
        tensor = at::empty(sizes, opts.pinned_memory(pin_memory));
        recursive_store(
              (char*)tensor.data_ptr(),
              tensor.sizes(),
              tensor.strides(),
              0,
              inferred_scalar_type,
              tensor.dtype().itemsize(),
              data);
      }
    }
    maybe_initialize_cuda(device);
    tensor = tensor.to(device, inferred_scalar_type, /*non_blocking=*/false, /*copy=*/false);
  }

  return at::lift_fresh(tensor);
}
</code></pre>
<ul>
<li>at::empty() 创建 tensor</li>
<li>recursive_store() 初始化 tensor 数据</li>
</ul>
<p>其中 <code>detach_</code> 调用会调用 materialize_autograd_meta 初始化 autograd_meta_.</p>
<pre><code class="language-cpp">// torch/csrc/autograd/variable.cpp

AutogradMeta* materialize_autograd_meta(const at::TensorBase&amp; self) {
  auto p = self.unsafeGetTensorImpl();
  if (!p-&gt;autograd_meta()) {
    p-&gt;set_autograd_meta(std::make_unique&lt;AutogradMeta&gt;());
  }
  return get_autograd_meta(self);
}
</code></pre>
<h2 id="torchadd"><a class="header" href="#torchadd">torch.add</a></h2>
<blockquote>
<p>torch/csrc/autograd/generated/ 目录需要 build 生成</p>
</blockquote>
<pre><code class="language-cpp">// torch/csrc/autograd/generated/VariableType_2.cpp

at::Tensor add_Tensor(c10::DispatchKeySet ks, const at::Tensor &amp; self, const at::Tensor &amp; other, const at::Scalar &amp; alpha) {
  auto&amp; self_ = unpack(self, &quot;self&quot;, 0);
  auto&amp; other_ = unpack(other, &quot;other&quot;, 1);
  auto _any_requires_grad = compute_requires_grad( self, other );
  
  (void)_any_requires_grad;
  auto _any_has_forward_grad_result = (isFwGradDefined(self) || isFwGradDefined(other));
  (void)_any_has_forward_grad_result;
  std::shared_ptr&lt;AddBackward0&gt; grad_fn;
  if (_any_requires_grad) {
    grad_fn = std::shared_ptr&lt;AddBackward0&gt;(new AddBackward0(), deleteNode);
    grad_fn-&gt;set_next_edges(collect_next_edges( self, other ));
    grad_fn-&gt;other_scalar_type = other.scalar_type();
    grad_fn-&gt;alpha = alpha;
    grad_fn-&gt;self_scalar_type = self.scalar_type();
  }

  auto _tmp = ([&amp;]() {
    at::AutoDispatchBelowADInplaceOrView guard;
    return at::redispatch::add(ks &amp; c10::after_autograd_keyset, self_, other_, alpha);
  })();
  auto result = std::move(_tmp);

  if (grad_fn) {
      set_history(flatten_tensor_args( result ), grad_fn);
  }
  return result;
}
</code></pre>
<ul>
<li>构建反向节点 AddBackward0</li>
<li>计算 at::redispatch::add，结果保存至 result</li>
<li>关联 AddBackward0 和 result</li>
</ul>
<p>AddBackward0</p>
<pre><code class="language-cpp">// torch/csrc/autograd/generated/Functions.h

struct TORCH_API AddBackward0 : public TraceableFunction {
  using TraceableFunction::TraceableFunction;
  variable_list apply(variable_list&amp;&amp; grads) override;
  std::string name() const override { return &quot;AddBackward0&quot;; }
  void release_variables() override { }

  at::ScalarType other_scalar_type;
  at::Scalar alpha;
  at::ScalarType self_scalar_type;
};
</code></pre>
<p>TraceableFunction </p>
<pre><code class="language-cpp">// torch/csrc/autograd/function.h

struct TraceableFunction : public Node {
  using Node::Node;
  bool is_traceable() final {
    return true;
  }
};

collect_next_edges 根据两个输入找到节点的 Edges

```cpp
// torch/csrc/autograd/function.h

/// Return the next edges of all the given variables, or tuples of variables.
template &lt;typename... Variables&gt;
edge_list collect_next_edges(Variables&amp;&amp;... variables) {
  detail::MakeNextFunctionList make;
  make.apply(std::forward&lt;Variables&gt;(variables)...);
  return std::move(make.next_edges);
}

struct MakeNextFunctionList : IterArgs&lt;MakeNextFunctionList&gt; {
  edge_list next_edges;
  using IterArgs&lt;MakeNextFunctionList&gt;::operator();
  void operator()(const Variable&amp; variable) {
    if (variable.defined()) {
      next_edges.push_back(impl::gradient_edge(variable));
    } else {
      next_edges.emplace_back();
    }
  }
  void operator()(const Variable* variable) { ... }
  void operator()(const c10::optional&lt;Variable&gt;&amp; variable) { ... }
};
</code></pre>
<p>gradient_edge 会返回一组 Edges</p>
<pre><code class="language-cpp">// torch/csrc/autograd/variable.cpp

Edge gradient_edge(const Variable&amp; self) {
  if (const auto&amp; gradient = self.grad_fn()) {
    return Edge(gradient, self.output_nr());
  } else {
    return Edge(grad_accumulator(self), 0);
  }
}
</code></pre>
<p>如果 self 是内部创建的（非叶子结点），即通过运算生成的，则返回 self 的 grad_fn 数据成员，否则（即用户创建的叶子结点）返回 AccumulateGrad 实例。</p>
<pre><code class="language-cpp">// torch/csrc/autograd/variable.cpp

std::shared_ptr&lt;Node&gt; grad_accumulator(const Variable&amp; self) {
  auto autograd_meta = get_autograd_meta(self);
  c10::raw::intrusive_ptr::incref(self.unsafeGetTensorImpl());
  auto intrusive_from_this =
      c10::intrusive_ptr&lt;at::TensorImpl&gt;::reclaim(self.unsafeGetTensorImpl());
  result = std::make_shared&lt;AccumulateGrad&gt;(
      Variable(std::move(intrusive_from_this)));
  autograd_meta-&gt;grad_accumulator_ = result;
  return result;
}
</code></pre>
<p>其中 AcculateGrad 中的 Variable 即 aten::Tensor 指向 self 的 TensorImpl 用于更新聚合梯度：</p>
<pre><code class="language-cpp">// torch/csrc/autograd/functions/accumulate_grad.h

struct TORCH_API AccumulateGrad : public Node {
  explicit AccumulateGrad(Variable variable_);
  variable_list apply(variable_list&amp;&amp; grads) override;
  Variable variable;
};
</code></pre>
<p>set_history</p>
<pre><code class="language-cpp">// torch/csrc/autograd/functions/utils.h

inline void set_history(
    at::Tensor&amp; variable,
    const std::shared_ptr&lt;Node&gt;&amp; grad_fn) {
  AT_ASSERT(grad_fn);
  if (variable.defined()) {
    auto output_nr = grad_fn-&gt;add_input_metadata(variable);
    impl::set_gradient_edge(variable, {grad_fn, output_nr});
  } else {
    grad_fn-&gt;add_input_metadata(Node::undefined_input());
  }
}

inline void set_history(
    std::vector&lt;Variable&gt;&amp;&amp; variables,
    const std::shared_ptr&lt;Node&gt;&amp; grad_fn) {
  for (auto&amp; variable : variables) {
    set_history(variable, grad_fn);
  }
}
</code></pre>
<p>set_gradient_edge 设置 Tensor 和 grad_fn_.</p>
<pre><code class="language-cpp">// torch/csrc/autograd/variable.cpp

void set_gradient_edge(const Variable&amp; self, Edge edge) {
  auto* meta = materialize_autograd_meta(self);
  meta-&gt;grad_fn_ = std::move(edge.function);
  meta-&gt;output_nr_ = edge.input_nr;
  auto diff_view_meta = get_view_autograd_meta(self);
  if (diff_view_meta &amp;&amp; diff_view_meta-&gt;has_bw_view()) {
    diff_view_meta-&gt;set_attr_version(self._version());
  }
}
</code></pre>
<h3 id="torchmul"><a class="header" href="#torchmul">torch.mul</a></h3>
<p>流程类似</p>
<pre><code class="language-cpp">// torch/csrc/autograd/generated/VariableType_0.cpp

at::Tensor mul_Tensor(c10::DispatchKeySet ks, const at::Tensor &amp; self, const at::Tensor &amp; other) {
  auto&amp; self_ = unpack(self, &quot;self&quot;, 0);
  auto&amp; other_ = unpack(other, &quot;other&quot;, 1);
  auto _any_requires_grad = compute_requires_grad( self, other );

  (void)_any_requires_grad;
  auto _any_has_forward_grad_result = (isFwGradDefined(self) || isFwGradDefined(other));
  (void)_any_has_forward_grad_result;
  std::shared_ptr&lt;MulBackward0&gt; grad_fn;
  if (_any_requires_grad) {
    grad_fn = std::shared_ptr&lt;MulBackward0&gt;(new MulBackward0(), deleteNode);
    grad_fn-&gt;set_next_edges(collect_next_edges( self, other ));
    if (grad_fn-&gt;should_compute_output(1)) {
      grad_fn-&gt;self_ = SavedVariable(self, false);
    }
    grad_fn-&gt;other_scalar_type = other.scalar_type();
    grad_fn-&gt;self_scalar_type = self.scalar_type();
    if (grad_fn-&gt;should_compute_output(0)) {
      grad_fn-&gt;other_ = SavedVariable(other, false);
    }
  }
  auto _tmp = ([&amp;]() {
    at::AutoDispatchBelowADInplaceOrView guard;
    return at::redispatch::mul(ks &amp; c10::after_autograd_keyset, self_, other_);
  })();
  auto result = std::move(_tmp);

  if (grad_fn) {
      set_history(flatten_tensor_args( result ), grad_fn);
  }

  if (result_new_fw_grad_opt.has_value() &amp;&amp; result_new_fw_grad_opt.value().defined() &amp;&amp; result.defined()) {
    // The hardcoded 0 here will need to be updated once we support multiple levels.
    result._set_fw_grad(result_new_fw_grad_opt.value(), /* level */ 0, /* is_inplace_op */ false);
  }
  return result;
}
</code></pre>
<p>不同是的是因为乘法的求导和输入有关，所以我们在构建 MulBackward0 的时候需要把输入保存下来，即代码中的 SavedVariable 用于保存实例.</p>
<pre><code class="language-cpp">// torch/csrc/autograd/generated/Functions.h 

struct TORCH_API MulBackward0 : public TraceableFunction {
  using TraceableFunction::TraceableFunction;
  variable_list apply(variable_list&amp;&amp; grads) override;
  std::string name() const override { return &quot;MulBackward0&quot;; }
  void release_variables() override {
    std::lock_guard&lt;std::mutex&gt; lock(mutex_);
    self_.reset_data();
    other_.reset_data();
  }

  SavedVariable self_;
  at::ScalarType other_scalar_type;
  at::ScalarType self_scalar_type;
  SavedVariable other_;

};
</code></pre>
<p>使用 SavedVariable 来保存前向 Var 的数据区而不影响其管理反向 Op 的生命周期：</p>
<pre><code class="language-cpp">// torch/csrc/autograd/saved_variable.h

class TORCH_API SavedVariable {
 public:
  /// Reconstructs the saved variable. Pass `saved_for` as the gradient
  /// function if constructing the `SavedVariable` with it would have caused a
  /// circular reference.
  Variable unpack(std::shared_ptr&lt;Node&gt; saved_for = nullptr) const;

 private:
  at::Tensor data_;

  std::shared_ptr&lt;ForwardGrad&gt; fw_grad_;

  std::weak_ptr&lt;Node&gt; weak_grad_fn_;
  c10::VariableVersion version_counter_;

  uint32_t saved_version_ = 0;
  uint32_t output_nr_ = 0;
  bool was_default_constructed_ = true;
  bool is_inplace_on_view_ = false;
  bool saved_original_ = false;
  bool is_leaf_ = false;
  bool is_output_ = false;

  std::unique_ptr&lt;SavedVariableHooks&gt; hooks_;
  std::shared_ptr&lt;Node&gt; grad_fn_;
  std::weak_ptr&lt;Node&gt; grad_accumulator_;
  bool requires_grad_ = false;
};
</code></pre>
<h2 id="lifecycle"><a class="header" href="#lifecycle">Lifecycle</a></h2>
<p><img src="pytorch/5.png" alt="1" /></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="pytorch-profiler"><a class="header" href="#pytorch-profiler">PyTorch Profiler</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<ul>
<li>PyTorch 功能相对齐全：
<ul>
<li>基础设计明确：profiler/benchmark/debug 信息分的很细，比如时间统计放 benchmark，前反向信息放 debug</li>
<li>profiler 数据设计层次明确：打点日志 events --&gt; 整理数据 key_averages --&gt; 数据展示 table</li>
<li>数据展示部分：
<ul>
<li>控制台打印依赖整理数据的表格，通过控制各项 api 参数控制列，如统计设备/内存/flops 等等</li>
<li>chrome tracing 使用保存的 json 文件，适用于 timeline 相关信息分析，同时支持元素详细信息展示，如tensor shape 等</li>
<li>数据展示能力的发挥在于利用了 tensorbord，提供多种视图，多种形式的数据展示形式</li>
</ul>
</li>
<li>目前关于 model/layer 的支持仅限 torchscript 模式，还不完善，由 with_modules 参数控制</li>
<li>Highlight: 信息展示中有根据 profiler 分析数据，给出优化建议</li>
</ul>
</li>
</ul>
<h2 id="demo"><a class="header" href="#demo">Demo</a></h2>
<p>体现基本流程的示例</p>
<pre><code class="language-python">import torch
import torchvision.models as models
from torch.profiler import profile, record_function, ProfilerActivity

# 创建模型，需要 profile 的对象
model = models.resnet18()
inputs = torch.randn(5, 3, 224, 224)

# 配置
prof = profile(activities=[ProfilerActivity.CPU], record_shapes=True)

prof.start()

model(inputs)

prof.stop()

# 结果分析和输出
print(prof.key_averages().table(sort_by=&quot;cpu_time_total&quot;, row_limit=10))

prof.export_chrome_trace(&quot;trace.json&quot;)
</code></pre>
<p>其中 <code>torch.profiler.profile</code> 可以使用 <code>with</code> 语法</p>
<pre><code class="language-python">with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:
    with record_function(&quot;model_inference&quot;):
        model(inputs)
</code></pre>
<p>输出</p>
<pre><code class="language-shell">---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------
                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls
---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------
                 model_inferencex         0.10%      15.353ms       100.00%       14.951s       14.951s             1
                 aten::batch_norm         0.00%     292.000us        43.14%        6.449s     322.464ms            20
     aten::_batch_norm_impl_index         0.00%     567.000us        43.13%        6.449s     322.450ms            20
          aten::native_batch_norm        32.92%        4.921s        43.13%        6.448s     322.419ms            20
                     aten::conv2d         0.00%     310.000us        42.00%        6.279s     313.938ms            20
                aten::convolution         0.00%     350.000us        41.99%        6.278s     313.923ms            20
               aten::_convolution         0.00%     601.000us        41.99%        6.278s     313.905ms            20
         aten::mkldnn_convolution        41.98%        6.276s        41.99%        6.278s     313.875ms            20
                       aten::mean         0.01%       1.209ms        10.54%        1.576s      75.043ms            21
                        aten::sum        10.45%        1.562s        10.45%        1.562s      74.386ms            21
---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------
Self CPU time total: 14.951s
</code></pre>
<h3 id="api"><a class="header" href="#api">API</a></h3>
<p><code>torch.profiler.profile</code></p>
<p>参数说明</p>
<ul>
<li><code>activities</code> list 类型，profile 的内容，支持 <code>torch.profiler.ProfilerActivity.CPU</code> 和 <code>torch.profiler.ProfilerActivity.CUDA</code>，这里的设置需要和模型使用的 device 一致</li>
<li><code>schedule</code> 默认会持续记录所有事件，使用 scheduler() 作为帮助函数生成 schedule 函数，自定义记录逻辑</li>
<li><code>on_trace_ready</code> 配合 <code>schedule</code> 使用，在它返回 <code>ProfilerAction.RECORD_AND_SAVE</code> 后被调用</li>
<li><code>record_shapes</code> 是否记录 input shapes</li>
<li><code>profile_memory</code> 是否记录 内存/显存, 和 <code>activities</code> 对应</li>
<li><code>with_stack</code> 是否开启调用文件信息源的记录，包括代码文件和行号</li>
<li><code>with_flops</code> 预估FLOPs，主要针对 matrix multiplication and 2D convolution</li>
<li><code>with_modules</code> 层级记录，暂时只针对 TorchScript</li>
</ul>
<p><code>ProfilerAction</code> 用于状态的记录和转换</p>
<pre><code class="language-python">class ProfilerAction(Enum):
    NONE = 0
    WARMUP = 1
    RECORD = 2
    RECORD_AND_SAVE = 3
</code></pre>
<p><code>profile</code> 对象</p>
<pre><code class="language-python"># torch/profiler/profiler.py

# Profiler context manager
class profile(_KinetoProfile):

    def __init__(...):
        # 记录函数
        self.step_rec_fn: Optional[prof.record_function] = None

        # 状态转换时会触发一系列操作，action_map 记录里任意两个状态转换时执行的动作
        self.action_map: Dict[Tuple[ProfilerAction, Optional[ProfilerAction]], List[Any]] = {
            (ProfilerAction.NONE, ProfilerAction.WARMUP): [self.prepare_trace],
            (ProfilerAction.NONE, ProfilerAction.RECORD): [self.prepare_trace, self.start_trace],
            ...
        }

    def start(self):
        self._transit_action(ProfilerAction.NONE, self.current_action)
        if self.record_steps:
            self.step_rec_fn = prof.record_function(&quot;ProfilerStep#&quot; + str(self.step_num))
            self.step_rec_fn.__enter__()

    def stop(self):
        if self.record_steps and self.step_rec_fn:
            self.step_rec_fn.__exit__(None, None, None)
        self._transit_action(self.current_action, None)

    def step(self):
        self.step_num += 1
        # schedule 接受 step 数，返回当前 action
        self.current_action = self.schedule(self.step_num)

        # 转换状态，触发 map 中定义的动作
        self._transit_action(prev_action, self.current_action)

        if self.record_steps:
            self.step_rec_fn = prof.record_function(&quot;ProfilerStep#&quot; + str(cur_step))
            self.step_rec_fn.__enter__()
</code></pre>
<p><code>schedule</code></p>
<pre><code class="language-python">def schedule(*, wait: int, warmup: int, active: int, repeat: int = 0, skip_first: int = 0) -&gt; Callable:
    # skip_fist + ( wait + warmup + active ) * repeat
    # NONE                 WARMUP   RECORD RECORD_AND_SAVE
    def schedule_fn(step: int) -&gt; ProfilerAction:
        # 根据 step 返回 当前的状态
    return schedule_fn
</code></pre>
<p><code>record_function</code></p>
<pre><code class="language-python"># torch/autograd/profiler.py

class record_function(ContextDecorator):
    def __init__(self, name: str, args: Optional[str] = None):
        self.record = torch.jit.annotate(Optional[&quot;torch.classes.profiler._RecordFunction&quot;], None)

    def __enter__(self):
        self.record = torch.ops.profiler._record_function_enter_new(self.name, self.args)

    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any):
        torch.ops.profiler._record_function_exit(self.record)
</code></pre>
<h2 id="reference-1"><a class="header" href="#reference-1">Reference</a></h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/profiler.html">profiler</a></li>
<li><a href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html">profiler_recipe</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html">tensorboard_profiler_tutorial</a></li>
<li><a href="https://pytorch.org/tutorials/recipes/recipes/benchmark.html">benchmark</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="hook"><a class="header" href="#hook">Hook</a></h1>
<h3 id="summary-1"><a class="header" href="#summary-1">Summary</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Hook</th><th>触发时机</th><th>API</th></tr></thead><tbody>
<tr><td>反向 hook</td><td>反向梯度计算完成后</td><td>register_hook(hook)</td></tr>
<tr><td>前向 after hook</td><td>forward() 调用之后</td><td>register_forward_hook(hook)</td></tr>
<tr><td>前向 before hook</td><td>forward() 调用之前</td><td>register_forward_pre_hook(hook)</td></tr>
<tr><td>module hook</td><td>module inputs 反向梯度计算完成后</td><td>register_full_backward_hook(hook)</td></tr>
<tr><td>节点 hook</td><td>autograd hook, 节点计算后</td><td>register_hook(hook)</td></tr>
<tr><td>通信 hook</td><td>hook 参数 dist.GradBucket ready</td><td>register_comm_hook(state, hook)</td></tr>
</tbody></table>
</div>
<blockquote>
<p>torch.nn.parallel.DistributedDataParallel.register_comm_hook
Tensor.register_hook(hook)
torch.nn.Module.register_forward_hook(hook)
torch.nn.Module.register_forward_pre_hook(hook)
torch.nn.Module.register_full_backward_hook(hook)
Node.register_hook(hook)
torch.nn.parallel.DistributedDataParallel.register_comm_hook(state, hook)</p>
</blockquote>
<h3 id="反向-hook"><a class="header" href="#反向-hook">反向 hook</a></h3>
<p>反向 hook 最为常用的 hook，但反向梯度生成后加入逻辑。</p>
<pre><code class="language-python"># hook signature
hook(grad) -&gt; Tensor or None

def hook(grad):
    return grad * 2

v = torch.tensor([0., 0., 0.], requires_grad=True)
h = v.register_hook(hook)  # double the gradient
v.backward(torch.tensor([1., 2., 3.]))
v.grad # 2 4 6
h.remove()  # removes the hook
</code></pre>
<h3 id="module-hook"><a class="header" href="#module-hook">Module hook</a></h3>
<pre><code class="language-python">register_forward_hook(hook)
hook(module, input, output) -&gt; None or modified output
register_forward_pre_hook(hook)
hook(module, input) -&gt; None or modified input
register_full_backward_hook(hook)
hook(module, grad_input, grad_output) -&gt; tuple(Tensor) or None
# 不允许修改参数 tensor，但是可以返回 tensor 用于后续梯度计算
</code></pre>
<h3 id="autograd-hook"><a class="header" href="#autograd-hook">Autograd Hook</a></h3>
<p>autograd hook，node grad
经典用法来自 horovod optimizer</p>
<pre><code class="language-python">p_tmp = p.expand_as(p)
grad_acc = p_tmp.grad_fn.next_functions[0][0]
grad_acc.register_hook(self._make_hook(p))
# 示例
&gt;&gt;&gt; p = torch.tensor([1,2,3], dtype=float, requires_grad=True)
&gt;&gt;&gt; p
tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True)
&gt;&gt;&gt; pt = p.expand_as(p)
&gt;&gt;&gt; pt
tensor([1., 2., 3.], dtype=torch.float64, grad_fn=&lt;ExpandBackward0&gt;)
&gt;&gt;&gt; pg = pt.grad_fn.next_functions[0][0]
&gt;&gt;&gt; pg
&lt;AccumulateGrad object at 0x7fa7ade03710&gt;
</code></pre>
<h3 id="ddp-通信-hook"><a class="header" href="#ddp-通信-hook">DDP 通信 hook</a></h3>
<pre><code class="language-python">torch.nn.parallel.DistributedDataParallel.register_comm_hook(state, hook)
hook(state: object, bucket: dist.GradBucket) -&gt; torch.futures.Future[torch.Tensor]
</code></pre>
<p><strong>Example</strong></p>
<pre><code class="language-python">def encode_and_decode(state: object, bucket: dist.GradBucket): -&gt; torch.futures.Future[torch.Tensor]
    encoded_tensor = encode(bucket.buffer()) # encode gradients
    fut = torch.distributed.all_reduce(encoded_tensor).get_future()
    # Define the then callback to decode.
    def decode(fut):
        decoded_tensor = decode(fut.value()[0]) # decode gradients
        return decoded_tensor
    return fut.then(decode)
</code></pre>
<h3 id="reference-2"><a class="header" href="#reference-2">Reference</a></h3>
<ul>
<li>https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html</li>
<li>https://pytorch.org/docs/stable/ddp_comm_hooks.html</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="ealstic"><a class="header" href="#ealstic">Ealstic</a></h1>
<h2 id="launchrun"><a class="header" href="#launchrun">launch/run</a></h2>
<pre><code class="language-shell">python -m torch.distributed.run
</code></pre>
<p>模块实际调用 <code>elastic_launch</code> 函数启动</p>
<pre><code class="language-python"># torch/distributed/run.py

def run(args):
    config, cmd, cmd_args = config_from_args(args)
    elastic_launch(
        config=config,
        entrypoint=cmd,
    )(*cmd_args)


@record
def main(args=None):
    args = parse_args(args)
    run(args)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>elastic_launch 调用 launch_agent 方法</p>
<ul>
<li>创建 RendezvousParameters，只包含声明</li>
<li>创建 WorkerSpec, rdzv_handler 参数处理见 rendezvous 部分</li>
<li>创建 LocalElasticAgent</li>
<li>调用 agent.run()</li>
</ul>
<pre><code class="language-python"># torch/distributed/launcher/api.py

class elastic_launch:
    def __call__(self, *args):
        return launch_agent(self._config, self._entrypoint, list(args))

def launch_agent(...)
    run_id = str(uuid.uuid4().int)

    entrypoint_name = _get_entrypoint_name(entrypoint, args)

    rdzv_parameters = RendezvousParameters(...)

    # 这里的 master 只有在 rdzv_backend == static 时等于 rdzv, 否则都是 None，将会在后面创建
    master_addr, master_port = _get_addr_and_port(rdzv_parameters)

    spec = WorkerSpec(
        role=config.role,
        local_world_size=config.nproc_per_node,
        entrypoint=entrypoint,
        args=tuple(args),
        rdzv_handler=rdzv_registry.get_rendezvous_handler(rdzv_parameters),
        max_restarts=config.max_restarts,
        monitor_interval=config.monitor_interval,
        redirects=config.redirects,
        tee=config.tee,
        master_addr=master_addr,
        master_port=master_port,
    )

    agent = LocalElasticAgent(
        spec=spec, start_method=config.start_method, log_dir=config.log_dir
    )

    result = agent.run()
</code></pre>
<h2 id="rendezvous"><a class="header" href="#rendezvous">rendezvous</a></h2>
<p>rendezvous 模块在初始化时把默认支持的 handler 都进行了初始化，注册在 handler_registry 中。</p>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/__init__.py
from .registry import _register_default_handlers
_register_default_handlers()
</code></pre>
<p>即提供了对应关系，可以通过 handler key 获取到 create handler 方法。</p>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/registry.py

from .api import rendezvous_handler_registry as handler_registry
from .dynamic_rendezvous import create_handler

def _create_c10d_handler(params: RendezvousParameters) -&gt; RendezvousHandler:
    from .c10d_rendezvous_backend import create_backend

    backend, store = create_backend(params)
    return create_handler(store, backend, params)

def _register_default_handlers() -&gt; None:
    handler_registry.register(&quot;c10d&quot;, _create_c10d_handler)
    handler_registry.register(&quot;static&quot;, _create_static_handler)


def get_rendezvous_handler(params: RendezvousParameters) -&gt; RendezvousHandler:
    return handler_registry.create_handler(params)
</code></pre>
<blockquote>
<p>注意这里有两个 create_handler，一个从注册器中取出并调用，一个是 create backend 后的封装。</p>
</blockquote>
<p>启动时调用的 <code>rdzv_registry.get_rendezvous_handler(rdzv_parameters)</code> 即通过 prameter 获取对应 handler 并初始化。</p>
<pre><code class="language-python">import torch.distributed.elastic.rendezvous.registry as rdzv_registry
</code></pre>
<pre><code class="language-python">#  torch/distributed/elastic/rendezvous/api.py

rendezvous_handler_registry = RendezvousHandlerRegistry()

class RendezvousHandlerRegistry:

    _registry: Dict[str, RendezvousHandlerCreator]

    def register(self, backend: str, creator: RendezvousHandlerCreator) -&gt; None:
        self._registry[backend] = creator

    def create_handler(self, params: RendezvousParameters) -&gt; RendezvousHandler:
        creator = self._registry[params.backend]
        handler = creator(params)
        return handler
</code></pre>
<p>以 c10d 为例说明 create_backend，即真正启动服务的部分</p>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py

def _create_tcp_store(params: RendezvousParameters) -&gt; TCPStore:
    host, port = parse_rendezvous_endpoint(params.endpoint, default_port=29400)
    # 对于同一台机器多进程启动的 case，通过重试解决
    store = TCPStore(host, port, is_master=is_server, timeout=timedelta(seconds=read_timeout))

    return store

def create_backend(params: RendezvousParameters) -&gt; Tuple[C10dRendezvousBackend, Store]:
    store_type = params.get(&quot;store_type&quot;, &quot;tcp&quot;).strip().lower()
    store = _create_tcp_store(params)
    backend = C10dRendezvousBackend(store, params.run_id)

    return backend, store
</code></pre>
<pre><code class="language-python"># torch/distributed/elastic/rendezvous/dynamic_rendezvous.py

def create_handler(
    store: Store, backend: RendezvousBackend, params: RendezvousParameters
) -&gt; DynamicRendezvousHandler:
        return DynamicRendezvousHandler.from_backend(...)

class DynamicRendezvousHandler(RendezvousHandler):
    @classmethod
    def from_backend(
        cls,
        run_id: str,
        store: Store,
        backend: RendezvousBackend,
        min_nodes: int,
        max_nodes: int,
        timeout: Optional[RendezvousTimeout] = None,
    ):
        return cls(node, settings, backend.name, store, state_holder)

    def next_rendezvous(self) -&gt; Tuple[Store, int, int]:
        self._start_heartbeats()

        rank, world_size = self._get_world()
        store = self._get_store()

        return store, rank, world_size

    def _keep_alive(self) -&gt; None:
        ...

    def _start_heartbeats(self) -&gt; None:
        ...

</code></pre>
<p><code>_keep_alive</code>  是通过 <code>_PeriodicTimer</code> 启动线程依赖 backend 实现的。</p>
<p>链路逻辑，</p>
<ul>
<li><code>_keep_alive_weak</code> 调用 <code>_keep_alive</code>，<code>_DistributedRendezvousOpExecutor.run</code> 方法声明更新</li>
<li><code>_DistributedRendezvousOpExecutor</code> 初始化时需要传入 <code>_state_holder</code></li>
<li><code>state_holder: _RendezvousStateHolder</code> 在 DynamicRendezvousHandler` 初始化时传入</li>
<li>_BackendRendezvousStateHolder(backend, settings) 使用 <code>backend</code></li>
</ul>
<h2 id="worker"><a class="header" href="#worker">worker</a></h2>
<p><strong>TL;DR;</strong></p>
<p>提供 WorkerSpec/Worker/WorkerGroup/WorkerState/RunResult 抽象, 封装 process 管理。</p>
<p>调用如前所述，初始化后使用 <code>agent.run()</code> 调用，</p>
<ul>
<li>run 调用 invoke_run</li>
<li>invoke_run 调用 _initialize_workers 实际拉起 worker 进程，然后 while 循环监控状态</li>
</ul>
<p>_initialize_workers</p>
<ul>
<li>首先调用 _rendezvous: 0 号节点在 store 中写入 master 地址，所有节点从中取出 master 地址，并不使用，只为了做同步</li>
<li>调用 _start_workers 启动 worker</li>
</ul>
<blockquote>
<p>0 号节点写入的 master 地址在使用 c10d backend （非 static）时并不是 rendevous endpoint，默认情况会通过 socket bind 获取可用端口，然后写入 store，其余节点从 store 中获取。</p>
</blockquote>
<pre><code class="language-python"># torch/distributed/elastic/agent/server/api.py 

class SimpleElasticAgent(ElasticAgent):

    def run(self, role: str = DEFAULT_ROLE) -&gt; RunResult:
        result = self._invoke_run(role)
        return result

    def _invoke_run(self, role: str = DEFAULT_ROLE) -&gt; RunResult:
        self._initialize_workers(self._worker_group)
        rdzv_handler = spec.rdzv_handler

        while True:
            run_result = self._monitor_workers(self._worker_group)
            state = run_result.state
            if state == WorkerState.SUCCEEDED:
                self._exit_barrier()
                return run_result
            elif state in {WorkerState.UNHEALTHY, WorkerState.FAILED}:
                if self._remaining_restarts &gt; 0:
                    self._remaining_restarts -= 1
                    self._restart_workers(self._worker_group)
                else:
                    self._stop_workers(self._worker_group)
                    self._worker_group.state = WorkerState.FAILED
                    self._exit_barrier()
                    return run_result
            elif state == WorkerState.HEALTHY:
                num_nodes_waiting = rdzv_handler.num_nodes_waiting()
                if num_nodes_waiting &gt; 0:
                    self._restart_workers(self._worker_group)

    def _initialize_workers(self, worker_group: WorkerGroup) -&gt; None:
        self._rendezvous(worker_group)
        worker_ids = self._start_workers(worker_group)

    def _rendezvous(self, worker_group: WorkerGroup) -&gt; None:
        store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
        workers = self._assign_worker_ranks(store, group_rank, group_world_size, spec)

        if group_rank == 0:
            self._set_master_addr_port(store, spec.master_addr, spec.master_port)

        # 获取 master 地址，起到同步作用
        master_addr, master_port = self._get_master_addr_port(store)

    @staticmethod
    def _set_master_addr_port(
        store: Store, master_addr: Optional[str], master_port: Optional[int]
    ):
        if master_port is None:
            sock = _get_socket_with_port()
            with closing(sock):
                master_port = sock.getsockname()[1]

        if master_addr is None:
            master_addr = _get_fq_hostname()

        store.set(&quot;MASTER_ADDR&quot;, master_addr.encode(encoding=&quot;UTF-8&quot;))
        store.set(&quot;MASTER_PORT&quot;, str(master_port).encode(encoding=&quot;UTF-8&quot;))

    @staticmethod
    def _get_master_addr_port(store: Store) -&gt; Tuple[str, int]:
        master_addr = store.get(&quot;MASTER_ADDR&quot;).decode(encoding=&quot;UTF-8&quot;)
        master_port = int(store.get(&quot;MASTER_PORT&quot;).decode(encoding=&quot;UTF-8&quot;))
        return (master_addr, master_port)


def _get_socket_with_port() -&gt; socket.socket:
    s = socket.socket(family, type, proto)
    s.bind((&quot;localhost&quot;, 0))
    s.listen(0)
    return s

</code></pre>
<p>_start_workers 为真正启动进程的模块，</p>
<ul>
<li>首先获取 master 地址，这个地址在非 static backend 时是 0 号节点写入 store 的</li>
<li>为 process 准备多种配置，主要包括 env，args，然后调用进程封装模块启动进程返回进程 id</li>
</ul>
<pre><code class="language-python"># torch/distributed/elastic/agent/server/local_elastic_agent.py

class LocalElasticAgent(SimpleElasticAgent):

    def _start_workers(self, worker_group: WorkerGroup) -&gt; Dict[int, Any]:
        master_addr, master_port = super()._get_master_addr_port(store)
        for worker in worker_group.workers:
            local_rank = worker.local_rank
            worker_env = {
                &quot;LOCAL_RANK&quot;: str(local_rank),
                &quot;RANK&quot;: str(worker.global_rank),
                &quot;GROUP_RANK&quot;: str(worker_group.group_rank),
                &quot;ROLE_RANK&quot;: str(worker.role_rank),
                &quot;ROLE_NAME&quot;: spec.role,
                &quot;LOCAL_WORLD_SIZE&quot;: str(spec.local_world_size),
                &quot;WORLD_SIZE&quot;: str(worker.world_size),
                &quot;GROUP_WORLD_SIZE&quot;: str(worker_group.group_world_size),
                &quot;ROLE_WORLD_SIZE&quot;: str(worker.role_world_size),
                &quot;MASTER_ADDR&quot;: master_addr,
                &quot;MASTER_PORT&quot;: str(master_port),
                &quot;TORCHELASTIC_RESTART_COUNT&quot;: str(restart_count),
                &quot;TORCHELASTIC_MAX_RESTARTS&quot;: str(spec.max_restarts),
                &quot;TORCHELASTIC_RUN_ID&quot;: spec.rdzv_handler.get_run_id(),
                &quot;TORCHELASTIC_USE_AGENT_STORE&quot;: str(use_agent_store),
                &quot;NCCL_ASYNC_ERROR_HANDLING&quot;: os.getenv(
                    &quot;NCCL_ASYNC_ERROR_HANDLING&quot;, str(1)
                ),
            }
            if &quot;OMP_NUM_THREADS&quot; in os.environ:
                worker_env[&quot;OMP_NUM_THREADS&quot;] = os.environ[&quot;OMP_NUM_THREADS&quot;]

            envs[local_rank] = worker_env
            worker_args = list(spec.args)
            worker_args = macros.substitute(worker_args, str(local_rank))
            args[local_rank] = tuple(worker_args)

        self._pcontext = start_processes(
            name=spec.role,
            entrypoint=spec.entrypoint,
            args=args,
            envs=envs,
            log_dir=attempt_log_dir,
            start_method=self._start_method,
            redirects=spec.redirects,
            tee=spec.tee,
        )

        return self._pcontext.pids()

</code></pre>
<p>子进程启动的用户脚本例如 trainer.py，会获取这里配置的环境运行。</p>
<h2 id="process"><a class="header" href="#process">process</a></h2>
<p>对进程和线程的封装，主要是 process 和 multiprocessing 库的封装。</p>
<p>通过对 entrypoint 是否是 str 判断决定启动方式。</p>
<pre><code class="language-python"># torch/distributed/elastic/multiprocessing/__init__.py

def start_processes(
    name: str,
    entrypoint: Union[Callable, str],
) -&gt; PContext:
    context: PContext
    if isinstance(entrypoint, str):
        context = SubprocessContext(...)
    else:
        context = MultiprocessContext(...)

    try:
        context.start()
        return context
    except Exception:
        context.close()
        raise
</code></pre>
<pre><code class="language-python"># torch/distributed/elastic/multiprocessing/api.py

class SubprocessHandler:
    def __init__(...):
        self.proc: subprocess.Popen = self._popen(args_str, env_vars)

class SubprocessContext(PContext):
    def __init__(...):
        self._running_local_ranks: Set[int] = set(range(self.nprocs))
        self._failures: Dict[int, ProcessFailure] = {}
        self.subprocess_handlers: Dict[int, SubprocessHandler] = {}

    def _start(self):
        self.subprocess_handlers = { local_rank: SubprocessHandler(...) }

    def _poll(self) -&gt; Optional[RunProcsResult]:
        for local_rank in self._running_local_ranks:
            exitcode = handler.proc.poll()
            if exitcode is not None:
                done_local_ranks.add(local_rank)
        self._running_local_ranks.difference_update(done_local_ranks)

    def _close(self, death_sig: signal.Signals, timeout: int = 30) -&gt; None:
        for handler in self.subprocess_handlers.values():
            if handler.proc.poll() is None:
                handler.close(death_sig=death_sig)

class PContext(abc.ABC):
    def __init__(...):
        self.entrypoint = entrypoint

    def start(self) -&gt; None:
        self._start()

    def wait(self, timeout: float = -1, period: float = 1) -&gt; Optional[RunProcsResult]:
        expiry = time.time() + timeout
        while time.time() &lt; expiry:
            pr = self._poll()
            if pr: return pr

    def close(
        self, death_sig: Optional[signal.Signals] = None, timeout: int = 30
    ) -&gt; None:
        self._close(death_sig=death_sig, timeout=timeout)
</code></pre>
<pre><code class="language-python">import torch.multiprocessing as mp

class MultiprocessContext(PContext):
    def __init__(..., entrypoint: Callable, ...):
        self._ret_vals = {
            local_rank: mp.get_context(self.start_method).SimpleQueue()
            for local_rank in range(self.nprocs)
        }
        self._pc: Optional[mp.ProcessContext] = None

    def _start(self):
        self._pc = mp.start_processes(...)

    def _poll(self) -&gt; Optional[RunProcsResult]:
        self._pc.join(-1)

    def _close(self, death_sig: signal.Signals, timeout: int = 30) -&gt; None:
        for proc in self._pc.processes:
            if proc.is_alive():
                try:
                    os.kill(proc.pid, death_sig)
</code></pre>
<h2 id="demo-1"><a class="header" href="#demo-1">demo</a></h2>
<p>上面部分的内容都是 run 模块的部分，下面是用户侧代码比如 train.py 的部分。</p>
<pre><code class="language-python">import torch

torch.distributed.init_process_group(backend=&quot;nccl&quot;, init_method=&quot;env://&quot;)
print(torch.distributed.get_world_size())
</code></pre>
<p>init_process_group 提供两种初始化方式</p>
<ul>
<li>显式提供 store, rank, world_size 以初始化</li>
<li>指定 init_method, 默认为 env:// 使用环境变量，如 launch/run 模块已配置好了环境变量</li>
</ul>
<p>在没有 store 的时候会通过 rendevous 创建 store 并获取 rank 和 size 信息。</p>
<p>然后根据这些信息创建 process group,</p>
<ul>
<li>mpi 从 orte 中获取信息，不需要通过这里指定</li>
<li>gloo/nccl 通过 store, rank, size 初始化创建通信域</li>
</ul>
<pre><code class="language-python"># torch/distributed/distributed_c10d.py

from .rendezvous import rendezvous

def init_process_group(
    backend,
    init_method=None,
    timeout=default_pg_timeout,
    world_size=-1,
    rank=-1,
    store=None,
    group_name=&quot;&quot;,
    pg_options=None,
):
    backend = Backend(backend)

    if backend == Backend.MPI:
        default_pg = _new_process_group_helper(
            -1, -1, [], Backend.MPI, None, group_name=group_name, timeout=timeout
        )
        _update_default_pg(default_pg)
    else:
        if store is None:
            rendezvous_iterator = rendezvous(
                init_method, rank, world_size, timeout=timeout
            )
            store, rank, world_size = next(rendezvous_iterator)
            store = PrefixStore(&quot;default_pg&quot;, store)

        default_pg = _new_process_group_helper(...)
        _update_default_pg(default_pg)

    if backend == Backend.MPI:
        barrier()
    else:
        _store_based_barrier(rank, store, timeout)


def _new_process_group_helper(
    world_size,
    rank,
    group_ranks,
    backend,
    store,
    pg_options=None,
    group_name=None,
    timeout=default_pg_timeout,
):
    backend = Backend(backend)
    if backend == Backend.MPI:
        pg = ProcessGroupMPI.create(group_ranks)
        _pg_map[pg] = (Backend.MPI, None)
        _pg_names[pg] = group_name
    else:
        prefix_store = PrefixStore(group_name, store)

        if backend == Backend.GLOO:
            pg = ProcessGroupGloo(prefix_store, rank, world_size, timeout=timeout)
            _pg_map[pg] = (Backend.GLOO, store)
            _pg_names[pg] = group_name
        elif backend == Backend.NCCL:
            pg = ProcessGroupNCCL(prefix_store, rank, world_size, pg_options)
            _pg_map[pg] = (Backend.NCCL, store)
            _pg_names[pg] = group_name

    return pg

</code></pre>
<p>rendevous 会创建 store 并返回 rank, size 信息，创建 store 通过 <code>_create_c10d_store</code> 实现，
在调用c api 创建 TCPStore 时通过 start_daemon 指定是否在当前调用里创建服务。</p>
<pre><code class="language-python"># torch/distributed/rendezvous.py

_rendezvous_handlers = {}

def rendezvous(url: str, rank: int = -1, world_size: int = -1, **kwargs):
    return _rendezvous_handlers[result.scheme](url, **kwargs)

def register_rendezvous_handler(scheme, handler):
    _rendezvous_handlers[scheme] = handler

register_rendezvous_handler(&quot;tcp&quot;, _tcp_rendezvous_handler)
register_rendezvous_handler(&quot;env&quot;, _env_rendezvous_handler)
register_rendezvous_handler(&quot;file&quot;, _file_rendezvous_handler)

def _file_rendezvous_handler(url: str, **kwargs):
    result = urlparse(url)
    query_dict = _query_to_dict(result.query)
    rank = int(query_dict[&quot;rank&quot;])
    world_size = int(query_dict[&quot;world_size&quot;])
    store = FileStore(path, world_size)
    yield (store, rank, world_size)


def _create_c10d_store(hostname, port, rank, world_size, timeout) -&gt; Store:
    if _torchelastic_use_agent_store():
        tcp_store = TCPStore(hostname, port, world_size, False, timeout)
        return PrefixStore(f&quot;/worker/attempt_{attempt}&quot;, tcp_store)
    else:
        start_daemon = rank == 0
        return TCPStore(
            hostname, port, world_size, start_daemon, timeout, multi_tenant=True
        )


def _tcp_rendezvous_handler(
    url: str, timeout: timedelta = default_pg_timeout, **kwargs
):
    result = urlparse(url)
    query_dict = _query_to_dict(result.query)
    rank = int(query_dict[&quot;rank&quot;])
    world_size = int(query_dict[&quot;world_size&quot;])

    store = _create_c10d_store(result.hostname, result.port, rank, world_size, timeout)

    yield (store, rank, world_size)


def _env_rendezvous_handler(
    url: str, timeout: timedelta = default_pg_timeout, **kwargs
):
    result = urlparse(url)
    query_dict: Dict[str, Union[int, str]] = _query_to_dict(result.query)

    if &quot;rank&quot; in query_dict:
        rank = int(query_dict[&quot;rank&quot;])
    else:
        rank = int(_get_env_or_raise(&quot;RANK&quot;))

    if &quot;world_size&quot; in query_dict:
        world_size = int(query_dict[&quot;world_size&quot;])
    else:
        world_size = int(_get_env_or_raise(&quot;WORLD_SIZE&quot;))

    master_addr = _get_env_or_raise(&quot;MASTER_ADDR&quot;)
    master_port = int(_get_env_or_raise(&quot;MASTER_PORT&quot;))

    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)

    yield (store, rank, world_size)

</code></pre>
<p>rendezvous_handler 的实现使用了 iterator 可以避免被多次调用，同时有 lazy init 的效果。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="pytorch-patch"><a class="header" href="#pytorch-patch">PyTorch Patch</a></h1>
<h2 id="summary-2"><a class="header" href="#summary-2">summary</a></h2>
<p>这个库提供了一种对 pytorch 进行 patch/hack 的方式，在很多场景可以借鉴，例如容错弹性。</p>
<pre><code class="language-python">patch_apex()
patch_torch_classes() # [torch, torch.Tensor, torch.nn.functional, torch.distributed]
patch_torch_nn_forward_functions() # [torch.nn.RNN, torch.nn.RNNCell, torch.nn.LSTM, torch.nn.LSTMCell, torch.nn.GRU, torch.nn.GRUCell]
</code></pre>
<pre><code class="language-python">patch_apex --&gt; patch_apex_c + patch_apex_pyt
    patch_apex_c --&gt; patchClass --&gt; add_wrapper
    patch_apex_pyt --&gt; patch_apex_module --&gt; patch_apex_class --&gt; add_wrapper

patch_torch_classes --&gt; patchClass --&gt; add_wrapper
patch_torch_nn_forward_functions --&gt; add_wrapper
</code></pre>
<h3 id="patch_apex"><a class="header" href="#patch_apex">patch_apex</a></h3>
<pre><code class="language-python">def patch_apex():
    patch_apex_c()
    patch_apex_pyt()

def patch_apex_c():
    if importlib.util.find_spec(&quot;amp_C&quot;) is not None:
        import amp_C
        patchClass(amp_C)
    # fused_adam_cuda
    # fused_lamb_cuda
    # fused_layer_norm_cuda
    # distributed_lamb_cuda
    # xentropy_cuda
    # mlp_cuda

def patch_apex_pyt():
    if importlib.util.find_spec(&quot;apex&quot;) is not None:
        patch_apex_module(&quot;apex.amp&quot;)
        patch_apex_module(&quot;apex.contrib.groupbn&quot;)
        patch_apex_module(&quot;apex.contrib.multihead_attn&quot;)
        patch_apex_module(&quot;apex.contrib.optimizers&quot;)
        patch_apex_module(&quot;apex.contrib.sparsity&quot;)
        patch_apex_module(&quot;apex.contrib.xentropy&quot;)
        patch_apex_module(&quot;apex.fp16_utils&quot;)
        patch_apex_module(&quot;apex.mlp&quot;)
        patch_apex_module(&quot;apex.multi_tensor_apply&quot;)
        patch_apex_module(&quot;apex.optimizers&quot;)
        patch_apex_module(&quot;apex.parallel&quot;)

def patch_apex_module(modstr):
    &quot;&quot;&quot; 
    Patch all forward/backward/step functions in classes in the given apex module.
    &quot;&quot;&quot;
    if importlib.util.find_spec(modstr) is not None:
        mod = importlib.import_module(modstr)

        for _, v in ins.getmembers(mod):
            # This makes sure we don't patch random other modules that are imported by the target module
            if is_same_module_or_submodule(mod, ins.getmodule(v)):
                if (ins.isclass(v)):
                    patch_apex_class(v)

def patch_apex_class(cls):
    &quot;&quot;&quot;
    Patch all forward/backward/step functions in the given apex class
    &quot;&quot;&quot;
    for f in cls.__dict__:
        if (ins.isfunction(cls.__dict__[f])):
            if f in [&quot;forward&quot;, &quot;backward&quot;, &quot;step&quot;]:
                add_wrapper(cls, f)
</code></pre>
<h3 id="patch_torch_classes"><a class="header" href="#patch_torch_classes">patch_torch_classes</a></h3>
<pre><code class="language-python">def patchClass(cls):
    for f in dir(cls):
        if isfunc(cls, f):
            add_wrapper(cls, f)


def patch_torch_classes():
    &quot;&quot;&quot;Monkey-patch all classes in torch&quot;&quot;&quot;
    for cls in [torch, torch.Tensor, torch.nn.functional, torch.distributed]:
        patchClass(cls)
</code></pre>
<h3 id="patch_torch_nn_forward_functions"><a class="header" href="#patch_torch_nn_forward_functions">patch_torch_nn_forward_functions</a></h3>
<pre><code class="language-python">def patch_torch_nn_forward_functions():
    &quot;&quot;&quot;Monkey-patch all forward functions in torch.nn libraries&quot;&quot;&quot;
    for cls in [torch.nn.RNN, torch.nn.RNNCell, torch.nn.LSTM, torch.nn.LSTMCell, torch.nn.GRU, torch.nn.GRUCell]:
        if isfunc(cls, 'forward'):
            add_wrapper(cls, 'forward')
</code></pre>
<h3 id="add_wrapper"><a class="header" href="#add_wrapper">add_wrapper</a></h3>
<pre><code class="language-python">def add_wrapper(mod, fn_name):

    # Get a pointer to the original function
    func = getattr(mod, fn_name)

    # Check if the mod has a string representation
    # and is not a Script or Traced module (used by JIT)
    # yapf: disable
    s = hasattr(mod, &quot;extra_repr&quot;) and (type(mod) is not torch.jit.ScriptModule
                                       ) and (type(mod) is not torch.jit.TopLevelTracedModule)
    # yapf: enable

    def wrapper_func(*args, **kwargs):

        # Extract the stacktrace
        stack = traceback.extract_stack()

        # Push trace marker
        nvtx.range_push(traceMarker(stack))

        # Push module marker
        if s:
            m = modMarker(mod, fn_name, args)
            nvtx.range_push(m)

        # Create and push argument marker
        cadena = argMarker(mod, fn_name, args, kwargs)
        nvtx.range_push(cadena)

        # Call the original function
        result = func(*args, **kwargs)

        # Pop argumet marker
        nvtx.range_pop()

        # Pop module marker
        if s:
            nvtx.range_pop()

        # Pop trace marker
        nvtx.range_pop()

        return result

    setattr(mod, fn_name, wrapper_func)
</code></pre>
<h2 id="reference-3"><a class="header" href="#reference-3">Reference</a></h2>
<ul>
<li>https://github.com/NVIDIA/PyProf.git</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="paddle"><a class="header" href="#paddle">paddle</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="paddle-ps-代码分析"><a class="header" href="#paddle-ps-代码分析">paddle ps 代码分析</a></h1>
<h2 id="python-前端"><a class="header" href="#python-前端">python 前端</a></h2>
<h3 id="api-1"><a class="header" href="#api-1">API</a></h3>
<pre><code class="language-python">import paddle.distributed.fleet as fleet

fleet.init()

if fleet.is_server():
    fleet.init_server()
    fleet.run_server()
elif fleet.is_worker():
    run_worker()
    fleet.stop_worker()

def run_worker():
    # paddle.static.Executor(place)
    exe.run(paddle.static.default_startup_program())
    fleet.init_worker()
    exe.train_from_dataset(...)

# Fin, fleet is optimizer
</code></pre>
<h3 id="fleet-initoptimizer"><a class="header" href="#fleet-initoptimizer">fleet init/optimizer</a></h3>
<pre><code class="language-python"># python/paddle/distributed/fleet/base/fleet_base.py

def init(self, role_maker=None, is_collective=False, strategy=None):
    # 配置之集大成者，就是各种配置，细到训练参数，粗到训练模式，开关
    strategy = DistributedStrategy()
    # role maker 包含分布式信息，基本上对接 launch 信息
    # 也负责初始化如 gloo 之类的工具
    self._role_maker._generate_role()

def minimize(...)
    def _minimize_impl(...)
        # runtime handle 做映射 init_server/_init_server, run_server/_run_server
        self._runtime_handle = RuntimeFactory()._create_runtime(context)
</code></pre>
<h3 id="runtime"><a class="header" href="#runtime">runtime</a></h3>
<pre><code class="language-python"># 使用实例
# python/paddle/distributed/ps/the_one_ps.py
class TheOnePSRuntime(RuntimeBase):
    def __init__(self):
        super(TheOnePSRuntime, self).__init__()
        self._communicator = None
        self._server = None
        self._worker = fluid.core.DistFleetWrapper()
        self._server_sub_program = []
        self._heter_client = None
        self._send_ctx = None
</code></pre>
<h3 id="pybind"><a class="header" href="#pybind">pybind</a></h3>
<pre><code class="language-cpp">void BindDistFleetWrapper(py::module* m) {
  py::class_&lt;FleetWrapper, std::shared_ptr&lt;FleetWrapper&gt;&gt;(*m,
                                                          &quot;DistFleetWrapper&quot;)
      .def(py::init([]() { return FleetWrapper::GetInstance(); }))
      .def(&quot;load_sparse&quot;, &amp;FleetWrapper::LoadSparseOnServer)
      .def(&quot;load_model&quot;, &amp;FleetWrapper::LoadModel)
      .def(&quot;load_one_table&quot;, &amp;FleetWrapper::LoadModelOneTable)
      .def(&quot;init_server&quot;, &amp;FleetWrapper::InitServer)
      .def(&quot;run_server&quot;,
           (uint64_t (FleetWrapper::*)(void)) &amp; FleetWrapper::RunServer)
      .def(&quot;run_server&quot;, (uint64_t (FleetWrapper::*)(          // NOLINT
                             const std::string&amp;, uint32_t)) &amp;  // NOLINT
                             FleetWrapper::RunServer)
      .def(&quot;init_worker&quot;, &amp;FleetWrapper::InitWorker)
      .def(&quot;push_dense_params&quot;, &amp;FleetWrapper::PushDenseParamSync)
      .def(&quot;pull_dense_params&quot;, &amp;FleetWrapper::PullDenseVarsSync)
      .def(&quot;save_all_model&quot;, &amp;FleetWrapper::SaveModel)
      .def(&quot;save_one_model&quot;, &amp;FleetWrapper::SaveModelOneTable)
      .def(&quot;recv_and_save_model&quot;, &amp;FleetWrapper::RecvAndSaveTable)
      .def(&quot;sparse_table_stat&quot;, &amp;FleetWrapper::PrintTableStat)
      .def(&quot;stop_server&quot;, &amp;FleetWrapper::StopServer)
      .def(&quot;stop_worker&quot;, &amp;FleetWrapper::FinalizeWorker)
      .def(&quot;barrier&quot;, &amp;FleetWrapper::BarrierWithTable)
      .def(&quot;shrink_sparse_table&quot;, &amp;FleetWrapper::ShrinkSparseTable)
      .def(&quot;set_clients&quot;, &amp;FleetWrapper::SetClients)
      .def(&quot;get_client_info&quot;, &amp;FleetWrapper::GetClientsInfo)
      .def(&quot;create_client2client_connection&quot;,
           &amp;FleetWrapper::CreateClient2ClientConnection);
}
</code></pre>
<h2 id="fleet-run_server"><a class="header" href="#fleet-run_server">fleet run_server</a></h2>
<pre><code class="language-python"># runtime 层初始化
class TheOnePSRuntime(RuntimeBase):
    def _init_server(self, dirname=None, var_names=None, **kwargs):
        # cpp instance
        self._server = fluid.core.DistFleetWrapper()
        self._server.init_server(server_desc, self.string_hosts, role_id,
                                 trainers, self._server_sub_program)
        # load_sparse 
        for var_name in load_varnames:
            table_id = sparse_table_maps[var_name]
            self._server.load_sparse(dirname, &quot;0&quot;, table_id)

    def _run_server(self):
        self._server.run_server(host, int(port))
</code></pre>
<h3 id="fleetwrapper"><a class="header" href="#fleetwrapper">FleetWrapper</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/wrapper/fleet.cc
// FleetWrapper 层
void FleetWrapper::InitServer(...){
    pserver_ptr_ = std::shared_ptr&lt;paddle::distributed::PSCore&gt;(
        new paddle::distributed::PSCore());
    pserver_ptr_-&gt;init_server(...)
}

uint64_t FleetWrapper::RunServer(...){
    auto ret = pserver_ptr_-&gt;run_server(ip, port);
}

void FleetWrapper::LoadSparseOnServer(...){
    // _server_ptr is PSServer
    pserver_ptr_-&gt;_server_ptr-&gt;table(table_id)-&gt;load(path, meta);
}
</code></pre>
<h3 id="pscore"><a class="header" href="#pscore">PSCore</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/ps_service/service.cc
// PSCore layer

int PSCore::init_server(...){
  _ps_env = paddle::distributed::PaddlePSEnvironment();
  _ps_env.set_ps_servers(host_sign_list, node_num);
  _ps_env.set_trainers(trainers); // 没啥用
  _server_ptr = std::shared_ptr&lt;paddle::distributed::PSServer&gt;(
      paddle::distributed::PSServerFactory::create(_ps_param));
  ret = _server_ptr-&gt;configure(_ps_param, _ps_env, index, server_sub_program);
}

uint64_t PSCore::run_server(const std::string&amp; ip, uint32_t port) {
  return _server_ptr-&gt;start(ip, port);
}
</code></pre>
<h3 id="psserver"><a class="header" href="#psserver">PSServer</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/server.cc
// PSServer layer

PSServer *PSServerFactory::create(const PSParameter &amp;ps_config) {
    PSServer *server =
      CREATE_PSCORE_CLASS(PSServer, service_param.server_class());
    TableManager::instance().initialize();
}

int32_t PSServer::configure(...){
    // for i in downpour_param.downpour_table_param_size()
    auto *table = CREATE_PSCORE_CLASS(
        Table, downpour_param.downpour_table_param(i).table_class());
    table-&gt;set_program_env(scope_.get(), place_, &amp;server_sub_program);
    table-&gt;set_shard(_rank, shard_num);
    table-&gt;initialize(downpour_param.downpour_table_param(i),
                      config.fs_client_param());
    _table_map[downpour_param.downpour_table_param(i).table_id()].reset(table);

    return initialize();
}
</code></pre>
<h3 id="brpcpsserver"><a class="header" href="#brpcpsserver">BrpcPsServer</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/brpc_ps_server.h
class BrpcPsServer : public PSServer {
    brpc::Server _server;
}

// paddle/fluid/distributed/ps/service/brpc_ps_server.cc
int32_t BrpcPsServer::initialize() {
    auto *service =
      CREATE_PSCORE_CLASS(PsBaseService, service_config.service_class());
    _server.AddService(service, brpc::SERVER_DOESNT_OWN_SERVICE)
}
uint64_t BrpcPsServer::start(const std::string &amp;ip, uint32_t port) {
    auto trainers = _environment-&gt;get_trainers(); // 可以去掉
    _server.Start(ip_port.c_str(), &amp;options)
    _environment-&gt;registe_ps_server(ip, port, _rank);
}
</code></pre>
<h3 id="brpcpsservice"><a class="header" href="#brpcpsservice">BrpcPsService</a></h3>
<pre><code class="language-cpp">class BrpcPsService : public PsBaseService {
  int32_t initialize_shard_info(...)
  int32_t pull_dense(...)
  int32_t push_dense(...)
  int32_t push_dense_param(...)
  int32_t push_sparse_param(...)
  int32_t pull_sparse(...)
  int32_t pull_geo_param(...)
  int32_t barrier(...)
  int32_t push_sparse(...)
  int32_t load_one_table(...)
  int32_t load_all_table(...)
  int32_t save_one_table(...)
  int32_t save_all_table(...)
  int32_t shrink_table(...)
  int32_t clear_one_table(...)
  int32_t clear_all_table(...)
  int32_t stop_server(...)
  int32_t start_profiler(...)
  int32_t stop_profiler(...)
  int32_t print_table_stat(...)
  int32_t push_global_step(...)
}
</code></pre>
<h2 id="fleet-run_worker"><a class="header" href="#fleet-run_worker">fleet run_worker</a></h2>
<h3 id="runtime-1"><a class="header" href="#runtime-1">runtime</a></h3>
<pre><code class="language-python"># runtime 层初始化
class TheOnePSRuntime(RuntimeBase):
    def _init_worker(self, scopes=None):
        # in init
        # self._worker = fluid.core.DistFleetWrapper()
        self._worker.init_worker(proto_txt, self.string_hosts, role_id)
        # GEO mode
        self._communicator = Communicator(...)
        self._communicator.init_with_ctx(...)
        # 
        info = self._worker.get_client_info()
        self._worker.set_clients(all_info) # _all_gather info is all_info
        self._worker.create_client2client_connection()
        #
        self._pull_all_dense(scopes, send_ctx, dense_map)
        # GEO mode
        self._communicator.start()    

    def _pull_all_dense(self, scopes, send_ctx, recv_map):
        for name, ctx in send_ctx.items():
            self._worker.pull_dense_params(scope, table_id, var_names)
</code></pre>
<h3 id="init-worker"><a class="header" href="#init-worker">init worker</a></h3>
<h3 id="fleetwrapper-1"><a class="header" href="#fleetwrapper-1">FleetWrapper</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/wrapper/fleet.cc
void FleetWrapper::InitWorker(...){
    ps_env_.set_ps_servers(&amp;host_sign_list, servers);
    worker_ptr_ = std::shared_ptr&lt;paddle::distributed::PSClient&gt;(
          paddle::distributed::PSClientFactory::create(ps_param));
    worker_ptr_-&gt;configure(ps_param, dense_pull_regions, ps_env_, index);
}

void FleetWrapper::PullDenseVarsSync(...){
    auto status = worker_ptr_-&gt;pull_dense(regions.data(), regions.size(), tid);
    status.wait();
}

int FleetWrapper::SetClients(std::vector&lt;uint64_t&gt;&amp; host_sign_list) {
    return ps_env_.set_ps_clients(host_sign_list.data(), node);
}
void FleetWrapper::CreateClient2ClientConnection() {
    worker_ptr_-&gt;create_client2client_connection(...)
}
</code></pre>
<h3 id="psclient"><a class="header" href="#psclient">PSClient</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/ps_client.cc

PSClient *PSClientFactory::create(const PSParameter &amp;ps_config) {
    PSClient *client = CREATE_PSCORE_CLASS(PSClient, service_param.client_class());
    TableManager::instance().initialize();
}

int32_t PSClient::configure(...){
    // for i in work_param.downpour_table_param_size()
    auto *accessor = CREATE_PSCORE_CLASS(
        ValueAccessor,
        work_param.downpour_table_param(i).accessor().accessor_class());
    accessor-&gt;configure(work_param.downpour_table_param(i).accessor());
    accessor-&gt;initialize();
    _table_accessors[work_param.downpour_table_param(i).table_id()].reset(accessor);
    return initialize();
}
</code></pre>
<h3 id="brpcpsclient"><a class="header" href="#brpcpsclient">BrpcPsClient</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/brpc_ps_client.cc
class BrpcPsClient : public PSClient {
    brpc::Server _server;
    DownpourPsClientService _service;
}

int32_t BrpcPsClient::initialize() {
    // for i in server_list.size()
    _server_channels[i][j].reset(new brpc::Channel());
    _server_channels[i][j]-&gt;Init(server_ip_port.c_str(), &quot;&quot;, &amp;options)
    // 启动client探听接口, 并相互建立连接
    start_client_service();
    // 异步push 请求队列初始化
    _push_dense_task_queue_map[table_id] = paddle::framework::MakeChannel&lt;DenseAsyncTask *&gt;();
    _push_sparse_task_queue_map[table_id] = paddle::framework::MakeChannel&lt;SparseAsyncTask *&gt;();
    // 启动异步push线程
    _async_push_sparse_thread = std::thread(std::bind(&amp;BrpcPsClient::push_sparse_task_consume, this));
    // _async_push_sparse_thread.detach();
    _async_push_dense_thread = std::thread(std::bind(&amp;BrpcPsClient::push_dense_task_consume, this));
}

// 启动client端RpcService 用于数据互发等操作
int32_t BrpcPsClient::start_client_service() {
    _service.configure(this, _client_id)
    _server.AddService(&amp;_service, brpc::SERVER_DOESNT_OWN_SERVICE);
    _server.Start(butil::my_ip_cstr(), brpc::PortRange(start_port, max_port), &amp;options)
    _env-&gt;registe_ps_client(...)
}

// how 弹性？？？
int32_t BrpcPsClient::create_client2client_connection(...){
    // for i in client_list.size()
    _client_channels[i].reset(new brpc::Channel());
    _client_channels[i]-&gt;Init(server_ip_port.c_str(), &quot;&quot;, &amp;options)
}
</code></pre>
<h3 id="downpourpsclientservice"><a class="header" href="#downpourpsclientservice">DownpourPsClientService</a></h3>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/brpc_ps_client.cc

class DownpourPsClientService : public PsService {
    PSClient *_client;
    void service(...)
}
</code></pre>
<h2 id="communicator"><a class="header" href="#communicator">communicator</a></h2>
<pre><code class="language-python"># python/paddle/fluid/communicator.py

class Communicator(object):
    def init_with_ctx(self,...):
        self.communicator_ = core.DistCommunicator(self.mode,...)
    def start(self):
        # Start communicator. Should call before training process.
        self.communicator_.start()
</code></pre>
<h3 id="bind"><a class="header" href="#bind">bind</a></h3>
<pre><code class="language-cpp">// paddle/fluid/pybind/communicator_py.cc
void BindCommunicator(py::module* m) {
  // Communicator is already used by nccl, change to DistCommunicator
  py::class_&lt;Communicator, std::shared_ptr&lt;Communicator&gt;&gt;(*m, &quot;DistCommunicator&quot;)
  .def(py::init([](...){Communicator::InitInstance&lt;GeoCommunicator&gt;(...)}
  .def(&quot;start&quot;, &amp;Communicator::Start)
// paddle/fluid/distributed/ps/service/communicator/communicator.h
static Communicator *InitInstance(...){
    std::call_once(init_flag_, &amp;Communicator::InitWithRpcCtx&lt;T&gt;,...);
}
static void InitWithRpcCtx(...){
    communicator_.reset(new T(std::ref(envs)));
    communicator_-&gt;InitEnvs();
    communicator_-&gt;InitBrpcClient(dist_desc, host_sign_list);
    communicator_-&gt;InitImpl(send_ctx, recv_ctx, recv_scope);
}
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/distributed/ps/service/communicator/communicator.cc
void Communicator::InitBrpcClient(...){
    auto fleet = paddle::distributed::FleetWrapper::GetInstance();
    _worker_ptr = fleet-&gt;worker_ptr_;
}
void AsyncCommunicator::InitImpl(...){
    // for varnames
    send_varname_to_queue_[var_name] = std::make_shared&lt;BlockingQueue&lt;std::shared_ptr&lt;Variable&gt;&gt;&gt;(send_queue_size_);
    send_threadpool_.reset(new ::ThreadPool(thread_pool_size_));
    }

void AsyncCommunicator::Start() {
    main_thread_.reset(new std::thread(std::bind(&amp;AsyncCommunicator::MainThread, this))); // MainThread/RecvThread
}

void AsyncCommunicator::MainThread() {
    while (running_) {
        SendByCommunicator();
        RpcProfilerControl();
    }
}
void AsyncCommunicator::RecvThread() {
    while (running_) {
        RecvByCommunicator();
    }
}
</code></pre>
<h2 id="train_from_dataset"><a class="header" href="#train_from_dataset">train_from_dataset</a></h2>
<pre><code class="language-python"># dataset
dataset = paddle.distributed.InMemoryDataset() # &quot;MultiSlotInMemoryDataFeed&quot;
dataset.load_into_memory()
dataset.init(...)
dataset.set_filelist(train_files_list)

# InMemoryDataset -- MultiSlotInMemoryDataFeed  -- InMemoryDataFeed -- DataFeed
# QueueDataset -- MultiSlotDataFeed -- PrivateQueueDataFeed -- DataFeed
# python/paddle/fluid/executor.py
</code></pre>
<pre><code class="language-python"># class Executor(object):
def train_from_dataset(self,...):
    return self._run_from_dataset(...)

def _run_from_dataset(self,...):
    # dataset
    dataset = paddle.fluid.DatasetFactory().create_dataset(...)
    dataset.set_xxx(...)
    dataset._prepare_to_run()
    # trainer
    scope, trainer = self._prepare_trainer(...)
    trainer._gen_trainer_desc()
    # self._default_executor = core.Executor(p)
    trainer_instance = self._default_executor.init_for_dataset(
                    program.desc, trainer._desc(), scope, dataset.dataset)
    # run
    self._default_executor.run_from_dataset(trainer_instance)

def _prepare_trainer(self,...):
    trainer = TrainerFactory()._create_trainer(program.program._fleet_opt)
    # trainer._set_thread(thread)
</code></pre>
<h3 id="excutor"><a class="header" href="#excutor">excutor</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/executor.cc

std::shared_ptr&lt;TrainerBase&gt; Executor::InitForDataset(...){
  // MultiTrainer
  std::shared_ptr&lt;TrainerBase&gt; trainer;
  trainer = TrainerFactory::CreateTrainer(trainer_desc.class_name());
  // initialize trainer
  trainer-&gt;Initialize(trainer_desc, dataset);
  trainer-&gt;SetScope(scope);
  // prepare training environment and helper environment
  trainer-&gt;InitTrainerEnv(main_program, place_);
  // Try to init other environment
  trainer-&gt;InitOtherEnv(main_program);
}

void Executor::RunFromDataset(std::shared_ptr&lt;TrainerBase&gt; trainer) {
    trainer-&gt;Run();
}
</code></pre>
<h3 id="multitrainer"><a class="header" href="#multitrainer">MultiTrainer</a></h3>
<pre><code class="language-cpp">//paddle/fluid/framework/trainer.h
class MultiTrainer : public TrainerBase {
    std::vector&lt;DataFeed*&gt; readers_;
    std::vector&lt;std::shared_ptr&lt;DeviceWorker&gt;&gt; workers_;
}

// paddle/fluid/framework/multi_trainer.cc
void MultiTrainer::Initialize(const TrainerDesc&amp; trainer_desc, Dataset* dataset) {
    // Dataset -&gt; DataFeed
    const std::vector&lt;paddle::framework::DataFeed*&gt; readers = dataset-&gt;GetReaders();
    thread_num_ = readers.size(); // !!! thread num
    workers_.resize(thread_num_); 
    // for i in thread_num_
    workers_[i] = DeviceWorkerFactory::CreateDeviceWorker(...)
    workers_[i]-&gt;Setxxx()
    workers_[i]-&gt;Initialize(trainer_desc);
    workers_[i]-&gt;SetDataFeed(readers[i]);
}

void MultiTrainer::Run() {
    // for i in thread_num_
    threads_.push_back(std::thread(&amp;DeviceWorker::TrainFiles, workers_[thidx].get()));
    // for th in threads_
    th.join();
}
</code></pre>
<h3 id="hogwildworker"><a class="header" href="#hogwildworker">HogwildWorker</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/device_worker.cc
void DeviceWorker::SetDataFeed(DataFeed* data_feed) {
  device_reader_ = data_feed;
}

// paddle/fluid/framework/hogwild_worker.cc
void HogwildWorker::Initialize(const TrainerDesc &amp;desc) {
}

void HogwildWorker::TrainFiles() {
    device_reader_-&gt;Start();
    while ((cur_batch = device_reader_-&gt;Next()) &gt; 0) {
        // for op in ops_
        op-&gt;Run(*thread_scope_, place_);
    }
}
</code></pre>
<h3 id="multislotinmemorydatafeed"><a class="header" href="#multislotinmemorydatafeed">MultiSlotInMemoryDataFeed</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/data_feed.cc

class InMemoryDataFeed : public DataFeed {
    // 下面的 channel 赋值在 DatasetImpl&lt;T&gt;::CreateReaders()
    // input 为全局，output 和 consume 独立
    paddle::framework::ChannelObject&lt;T&gt;* input_channel_;
    paddle::framework::ChannelObject&lt;T&gt;* output_channel_;
    paddle::framework::ChannelObject&lt;T&gt;* consume_channel_;
}

bool InMemoryDataFeed&lt;T&gt;::Start() {
    //  input
    channel
    global channel
    input_channel_-&gt;Read(data); 
    output_channel_-&gt;Write(std::move(data));
}

int InMemoryDataFeed&lt;T&gt;::Next() {
    while (index &lt; this-&gt;default_batch_size_) {
        output_channel_-&gt;Get(instance);
        ins_vec.push_back(instance);
        ++index;
        consume_channel_-&gt;Put(std::move(instance));
    }
    PutToFeedVec(ins_vec);
}

class MultiSlotInMemoryDataFeed : public InMemoryDataFeed&lt;Record&gt; {
}
</code></pre>
<h3 id="multislotdatafeed"><a class="header" href="#multislotdatafeed">MultiSlotDataFeed</a></h3>
<pre><code class="language-cpp">// paddle/fluid/framework/data_feed.cc

class PrivateQueueDataFeed : public DataFeed {
    std::shared_ptr&lt;paddle::framework::ChannelObject&lt;T&gt;&gt; queue_;
}

bool PrivateQueueDataFeed&lt;T&gt;::Start() {
    read_thread_ = std::thread(&amp;PrivateQueueDataFeed::ReadThread, this);
}
void PrivateQueueDataFeed&lt;T&gt;::ReadThread() {
    while (PickOneFile(&amp;filename)) {
        fp_ = fs_open_read(filename, &amp;err_no, pipe_command_);
        while (ParseOneInstanceFromPipe(&amp;instance)) {
            queue_-&gt;Put(instance);
        }
    }
}
int PrivateQueueDataFeed&lt;T&gt;::Next() {
    while (index &lt; default_batch_size_) {
        queue_-&gt;Get(instance)
        AddInstanceToInsVec(&amp;ins_vec, instance, index++);
    }
    PutToFeedVec(ins_vec);
}

class MultiSlotDataFeed : public PrivateQueueDataFeed&lt;std::vector&lt;MultiSlotType&gt;&gt; {
}
</code></pre>
<h4 id="misc"><a class="header" href="#misc">Misc</a></h4>
<ol>
<li>InMemoryDataset 流程分析</li>
</ol>
<ul>
<li>
<p>LoadIntoMemory 把文件读取进 input_channel_，注意 input_channel_ 是全局共享，由 GetReaders() 返回时设定；</p>
</li>
<li>
<p>Start() 从 input_channel_ 读取一份数据进 output_channel_</p>
</li>
<li>
<p>Next() 从 output_channel_ 取数据进 consume_channel_</p>
</li>
</ul>
<ol start="2">
<li>input_channel_ 在哪里初始化？
data_set.cc 中 DatasetImpl<T>::CreateChannel()，它是全局的，最终调用在 dataset.py 中 self.dataset.create_channel()，所以 InMemoryDataset 有调用，QueueDataset 没有调用</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="framework"><a class="header" href="#framework">Framework</a></h1>
<h2 id="program"><a class="header" href="#program">Program</a></h2>
<p>Python Program 定义</p>
<pre><code># python/paddle/fluid/framework.py
class Program(object):
</code></pre>
<p>CPP 定义</p>
<pre><code>core.ProgramDesc()
# paddle/fluid/framework/program_desc.h
class ProgramDesc {}
</code></pre>
<p>对应 proto 定义</p>
<pre><code># paddle/fluid/framework/framework.proto
</code></pre>
<p>全局 default program</p>
<pre><code>paddle.static.default_startup_program()
# _main_program_ = Program()
paddle.static.default_main_program()
# _startup_program_ = Program()
</code></pre>
<ul>
<li>startup_program: 模型参数初始化、优化器参数初始化、reader初始化</li>
<li>main_program: 前向计算、反向计算、模型参数更新、优化器参数更新</li>
</ul>
<p>CompiledProgram 即 Graph</p>
<pre><code># python/paddle/fluid/compiler.py
class CompiledProgram(object):
</code></pre>
<p>Program to Graph </p>
<pre><code>core.Graph(program.desc)
</code></pre>
<p>Graph to Program</p>
<pre><code>compiled_program._compile(...)
compiled_graph = compiled_program._graph
fluid.framework.IrGraph(compiled_graph).to_program()
</code></pre>
<h2 id="demo-2"><a class="header" href="#demo-2">Demo</a></h2>
<p>静态图demo</p>
<pre><code class="language-python">import paddle
import numpy as np

paddle.enable_static()

inputs = paddle.static.data(name='input', shape=[None, 100], dtype='float32')
outputs = paddle.static.data(name='output', shape=[None, 10], dtype='float32')

out = paddle.static.nn.fc(x=inputs, size=10, activation='relu')

cost = paddle.nn.functional.square_error_cost(input=out, label=outputs)
loss = paddle.mean(cost)
adam = paddle.optimizer.Adam(learning_rate=1e-3)
adam.minimize(loss)

startup_program = paddle.static.default_startup_program()
main_program = paddle.static.default_main_program()

op_types = [op.type for op in startup_program.global_block().ops]
print(op_types)

op_types = [op.type for op in main_program.global_block().ops]
print(op_types)

executor = paddle.static.Executor()
executor.run(startup_program)

compiled_program = paddle.static.CompiledProgram(main_program)

BATCH_NUM = 20
BATCH_SIZE = 32

for batch_id in range(BATCH_NUM):
    input_data = np.random.random([BATCH_SIZE, 100]).astype('float32')
    output_data = np.random.random([BATCH_SIZE, 10]).astype('float32')
    loss_numpy, = executor.run(main_program, feed={'input': input_data, 'output': output_data}, fetch_list=[loss])
    print(&quot;Batch {}, loss = {}&quot;.format(batch_id, loss_numpy))
</code></pre>
<p>startup_program 的 op</p>
<pre><code>['uniform_random', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant', 'fill_constant']
</code></pre>
<p>main_program 的 op</p>
<pre><code>['mul', 'elementwise_add', 'relu', 'elementwise_sub', 'square', 'reduce_mean', 'fill_constant', 'reduce_mean_grad', 'square_grad', 'elementwise_sub_grad', 'relu_grad', 'elementwise_add_grad', 'mul_grad', 'adam', 'adam']
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="cinn"><a class="header" href="#cinn">CINN</a></h1>
<h2 id="summary-3"><a class="header" href="#summary-3">Summary</a></h2>
<p><strong>PassManger</strong></p>
<pre><code class="language-python">core.ProgramDesc(main_program.desc)
core.apply_pass(tmp_main_program, ...)
main_program._rebuild_from_desc(tmp_main_program)

# apply_pass
framework::ir::Pass::ApplyPassesToProgram(main_program, ...)
Graph graph(*main_program)
pass-&gt;Apply(&amp;graph);
ConvertToPrograms(&amp;graph, main_program, ...);
</code></pre>
<p><strong>Excutor build</strong></p>
<pre><code class="language-cpp">graph = core.Graph(program.desc)
graph = pass-&gt;Apply(graph)
ir_graph = fluid.framework.IrGraph(graph)
ir_graph.to_program()
</code></pre>
<h2 id="passmanager"><a class="header" href="#passmanager">PassManager</a></h2>
<p>Usage</p>
<pre><code class="language-python">from paddle.distributed.passes import new_pass, PassManager
pass_manager = PassManager([
    new_pass(&quot;build_cinn&quot;),
    new_pass(&quot;fuse_elewise_add_act&quot;),
])
pass_manager.apply([main_prog], [startup_prog])
op_types = [op.type for op in main_prog.global_block().ops]
self.assertTrue('cinn_launch' in op_types)
</code></pre>
<pre><code class="language-python"># python/paddle/fluid/framework.py

from paddle.fluid.framework import core, _apply_pass

def _apply_pass(main_program,
                startup_program,
                pass_name,
                pass_attrs={},
                pass_attr_types={}):
    assert isinstance(pass_attrs, dict), &quot;pass_attrs must be dict&quot;
    assert isinstance(pass_attr_types, dict), &quot;pass_attr_types must be dict&quot;
    tmp_main_program = core.ProgramDesc(main_program.desc)
    tmp_startup_program = core.ProgramDesc(startup_program.desc)
    attrs = core.apply_pass(tmp_main_program, tmp_startup_program, pass_name,
                            pass_attrs, pass_attr_types)
    main_program._rebuild_from_desc(tmp_main_program)
    startup_program._rebuild_from_desc(tmp_startup_program)
    return attrs
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/pybind/ir.cc

m-&gt;def(&quot;apply_pass&quot;,
         [](framework::ProgramDesc *main_program,
            framework::ProgramDesc *startup_program,
            const py::object &amp;py_pass_names,
            const std::unordered_map&lt;std::string, py::object&gt; &amp;pass_attrs,
            std::unordered_map&lt;std::string, std::string&gt; pass_attr_types) {
           auto pass_names = GetPassNames(py_pass_names);
           std::vector&lt;std::unique_ptr&lt;framework::ir::Pass&gt;&gt; passes;
           std::vector&lt;const framework::ir::Pass *&gt; passes_not_owned;
           passes.reserve(pass_names.size());
           passes_not_owned.reserve(pass_names.size());
           for (const auto &amp;name : pass_names) {
             auto pass = framework::ir::PassRegistry::Instance().Get(name);
             SetAttrsToPass(pass_attrs, &amp;pass_attr_types, pass.get());
             passes.push_back(std::move(pass));
             passes_not_owned.push_back(passes.back().get());
           }

           framework::ir::Pass::ApplyPassesToProgram(
               passes_not_owned, main_program, startup_program);
           std::unordered_map&lt;std::string, py::object&gt; result_attrs;
           for (const auto &amp;pass : passes) {
             for (const auto &amp;name_and_value : pass_attrs) {
               const auto &amp;attr_name = name_and_value.first;
               const auto &amp;attr_type = pass_attr_types.at(attr_name);
               result_attrs[attr_name] =
                   PassAttrGetterSetterRegistry::Instance().Get(
                       *pass, attr_name, attr_type);
             }
           }
           return result_attrs;
         });
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/framework/ir/pass.cc

void Pass::ApplyPassesToProgram(const std::vector&lt;const Pass *&gt; &amp;passes,
                                ProgramDesc *main_program,
                                ProgramDesc *startup_program) {
 if (passes.size() == 1 &amp;&amp; !passes[0]-&gt;SupportApplyProgramViaGraph()) {
    // apply pass to program
    passes[0]-&gt;ApplyImpl(main_program, startup_program);
    FillNotSpecifiedOpRole(*main_program);
    return;
  }

  Graph graph(*main_program);
  for (auto *p : passes) {
    p-&gt;Apply(&amp;graph);
  }
  ConvertToPrograms(&amp;graph, main_program, startup_program);
  FillNotSpecifiedOpRole(*main_program);
}

Graph *Pass::Apply(Graph *graph) const {
    ApplyImpl(graph);
    return graph;
}
</code></pre>
<h2 id="excutor-apply"><a class="header" href="#excutor-apply">Excutor Apply</a></h2>
<pre><code class="language-python">def _compile(program, loss_name=None):
    build_strategy = paddle.static.BuildStrategy()
    exec_strategy = paddle.static.ExecutionStrategy()

    exec_strategy.num_threads = 1

    compiled_program = paddle.static.CompiledProgram(
        program).with_data_parallel(
            loss_name=loss_name,
            build_strategy=build_strategy,
            exec_strategy=exec_strategy)

    return compiled_program

executor = paddle.static.Executor()

compiled_program = _compile(program_with_fetch_op, loss_name)

compiled_program._compile(scope, paddle.framework._current_expected_place())
compiled_graph = compiled_program._graph
ir_graph = fluid.framework.IrGraph(compiled_graph, for_test=True)
ir_program = ir_graph.to_program()
</code></pre>
<pre><code class="language-python"># python/paddle/fluid/compiler.py

BuildStrategy = core.ParallelExecutor.BuildStrategy

class CompiledProgram(object):
    # Static Graph
    def __init__(self, program_or_graph, build_strategy=None):
        self._graph = core.Graph(program_or_graph.desc)
        self._program = program_or_graph
    def _compile(self, scope, place):
        self._executor = self._compile_data_parallel(...)
    def _compile_data_parallel(self, places, use_device, scope=None):
        self._build_strategy = BuildStrategy()
        core.ParallelExecutor(...)

</code></pre>
<pre><code class="language-cpp">// paddle/fluid/pybind/parallel_executor.cc

py::class_&lt;ParallelExecutor&gt; pe(m, &quot;ParallelExecutor&quot;);
py::class_&lt;BuildStrategy&gt; build_strategy(pe, &quot;BuildStrategy&quot;, R&quot;DOC(
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/framework/parallel_executor.cc

ParallelExecutor::ParallelExecutor(const std::vector&lt;platform::Place&gt; &amp;places,
                                   const std::vector&lt;std::string&gt; &amp;bcast_vars,
                                   const std::string &amp;loss_var_name,
                                   Scope *scope,
                                   const std::vector&lt;Scope *&gt; &amp;local_scopes,
                                   const ExecutionStrategy &amp;exec_strategy,
                                   const BuildStrategy &amp;build_strategy,
                                   ir::Graph *graph){
    // ParallelExecutorPrivate *member_;
    std::vector&lt;ir::Graph *&gt; async_graphs = CompileGraphWithBuildStrategy(graph, &amp;graphs, loss_var_name);
    graph = member_-&gt;ApplyMemoryOptimizePass(graph);
    std::vector&lt;ir::Graph *&gt; final_graphs = CreateSSAGraphExecutor(exec_strategy, &amp;async_graphs, graph);
    if (!member_-&gt;build_strategy_.async_mode_) {
      member_-&gt;executor_.reset(new details::ScopeBufferedSSAGraphExecutor(
        exec_strategy,
        member_-&gt;local_scopes_,
        member_-&gt;local_exec_scopes_,
        std::move(var_infos),
        member_-&gt;places_,
        std::move(member_-&gt;executor_)));
  }
}

std::vector&lt;ir::Graph *&gt; ParallelExecutor::CompileGraphWithBuildStrategy(
    ir::Graph *graph,
    std::vector&lt;ir::Graph *&gt; *device_graphs,
    const std::string &amp;loss_var_name) {
    graph = member_-&gt;build_strategy_.Apply(graph, ...);
}
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/framework/details/build_strategy.cc

ir::Graph *BuildStrategy::Apply(ir::Graph *graph, ...){
    // 这里使用 ParallelExecutorPassBuilder 添加 pass
    CreatePassesFromStrategy(false);
    for (std::shared_ptr&lt;ir::Pass&gt; &amp;pass : pass_builder_-&gt;AllPasses()) {
        if (FLAGS_convert_all_blocks) {
          for (size_t i = 0; i &lt; graph-&gt;SubGraphsSize(); ++i) {
            pass-&gt;Apply(graph-&gt;GetSubGraph(i));
          }
        } else {
          graph = pass-&gt;Apply(graph);
        }
    }
}

std::shared_ptr&lt;ir::PassBuilder&gt; BuildStrategy::CreatePassesFromStrategy(bool finalize_strategy) const {
    pass_builder_.reset(new ParallelExecutorPassBuilder(*this));
    return pass_builder_;
}

class ParallelExecutorPassBuilder : public ir::PassBuilder {
    ...
    AppendPass(&quot;build_cinn_pass&quot;);
}
</code></pre>
<h2 id="build-cinn-pass"><a class="header" href="#build-cinn-pass">Build CINN Pass</a></h2>
<p>cinn pass 通过转成 Graph 然后 apply</p>
<pre><code class="language-cpp">// paddle/fluid/framework/paddle2cinn/build_cinn_pass.cc

void BuildCinnPass::ApplyImpl(Graph* graph) const { SearchAllSubgraphs(graph); }

void SearchAllSubgraphs(Graph* graph) {
    std::vector&lt;GraphNodeVec&gt; clusters = framework::ir::SubgraphDetector(graph, teller)();
    for (const auto&amp; node_vec : clusters) {
        cinn_compiler-&gt;AddGraph(CreateNewSubGraph(...)
        ReplaceSubGraphWithCinnOpNode(...)
    }
}

void ReplaceSubGraphWithCinnOpNode(...){
    // Add the cinn op node whose name is &quot;kCinnLaunchOp&quot; into graph
    AddCinnOpToGraph(...);
    // Remove the cinn subgraph from graph
    RemoveSubGraphFromGraph(cluster, cluster_internals, graph);
}
</code></pre>
<pre><code class="language-cpp">// paddle/fluid/framework/ir/subgraph_detector.cc

std::vector&lt;std::vector&lt;Node *&gt;&gt; SubgraphDetector::operator()() {
  MarkNodesInsideSubGraph();
  return ExtractSubGraphs();
}

void SubgraphDetector::MarkNodesInsideSubGraph() {
  for (auto &amp;node : framework::ir::GraphTraits::DFS(*graph_)) {
    if (node_inside_subgraph_teller_(&amp;node)) {
      Agent(&amp;node).set_marked(true);
      if (node.IsOp()) {
        // If a function is inside the sub-graph, mark all the output variables
        // to be inside too, so that two marked functions will be inside a same
        // sub-graph, lets take a example:  A_function-&gt;var-&gt;B_function, if
        // A_function is marked, var should also be marked, so that B_function
        // will be in the same sub-graph with A_function if B_function is
        // marked.
        MarkOutLinksInSubGraph(&amp;node);
      }
    }
  }
}

std::vector&lt;std::vector&lt;Node *&gt;&gt; SubgraphDetector::ExtractSubGraphs() {
}
</code></pre>
<h2 id="prim-op"><a class="header" href="#prim-op">Prim op</a></h2>
<p>通过以下API操作全局变量使用</p>
<pre><code>paddle.incubate.autograd.enable_prim()
paddle.incubate.autograd.disable_prim()
paddle.incubate.autograd.prim_enabled()
</code></pre>
<p>具体影响由使用 AD API 时体现</p>
<pre><code># python/paddle/incubate/autograd/primapi.py
paddle.incubate.autograd.grad()
# 调用 primx.orig2prim(block)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="horovod"><a class="header" href="#horovod">Horovod</a></h1>
<p>Horovod core principles are based on MPI concepts such as size, rank, local rank, allreduce, allgather, broadcast, and alltoall</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="run"><a class="header" href="#run">Run</a></h1>
<h3 id="启动"><a class="header" href="#启动">启动</a></h3>
<pre><code class="language-python">setup(name='horovod',
      entry_points={
          'console_scripts': [
              'horovodrun = horovod.runner.launch:run_commandline'
          ]
      })
</code></pre>
<pre><code class="language-python"># horovod/runner/launch.py

def run_commandline():
    args = parse_args()
    _run(args)

def _run(args):
    # set args.hosts
    if _is_elastic(args):
        return _run_elastic(args)
    else:
        return _run_static(args)
</code></pre>
<h3 id="非弹性启动"><a class="header" href="#非弹性启动">非弹性启动</a></h3>
<pre><code class="language-python">def _run_static(args):
    settings = hvd_settings.Settings(...)
    nics = driver_service.get_common_interfaces(settings, all_host_names,
                                                remote_host_names, fn_cache)
    if args.run_func:
        executable = args.executable or sys.executable
        command = [executable, '-m', 'horovod.runner.run_task', str(driver_ip), str(run_func_server_port)]
    else:
        command = args.command
    _launch_job(args, settings, nics, command)

def _launch_job(args, settings, nics, command):
    def gloo_run_fn():
        driver_ip = network.get_driver_ip(nics)
        gloo_run(settings, nics, env, driver_ip, command)

    def mpi_run_fn():
        mpi_run(settings, nics, env, command)

    def js_run_fn():
        js_run(settings, nics, env, command)

    run_controller(args.use_gloo, gloo_run_fn,
                   args.use_mpi, mpi_run_fn,
                   args.use_jsrun, js_run_fn,
                   args.verbose)

def run_controller(use_gloo, gloo_run, use_mpi, mpi_run, use_jsrun, js_run, verbosity):
    if use_gloo:
        gloo_run()
    elif use_mpi:
        mpi_run()
    elif use_jsrun:
        js_run()

from horovod.runner.gloo_run import gloo_run, gloo_run_elastic
from horovod.runner.mpi_run import mpi_run
from horovod.runner.js_run import js_run, is_jsrun_installed
</code></pre>
<pre><code class="language-python"># horovod/runner/gloo_run.py

def gloo_run(settings, nics, env, server_ip, command):
    # 启动命令通过 ssh 分发，如果出错所有进程将被 kill
    # 先封装执行函数
    exec_command = _exec_command_fn(settings)
    # 再调用执行
    launch_gloo(command, exec_command, settings, nics, env, server_ip)

def _exec_command_fn(settings):
    def _exec_command(command, slot_info, events):
        # 如果是需要分发到 remote 的节点
        # from horovod.runner.util.remote import get_remote_command
        # get_remote_command 提供 ssh 封装
        if host_address not in local_addresses:
            command = get_remote_command(local_command,...)
        exit_code = safe_shell_exec.execute(command,...)
    return _exec_command

def launch_gloo(command, exec_command, settings, nics, env, server_ip):
    # exec_command 为执行的命令
    # args_list 是执行的参数，由每个节点所需参数组成的列表
    # 通过如下方法的调用实现多节点运行
    res = threads.execute_function_multithreaded(exec_command, args_list, block_until_all_done=True)
</code></pre>
<pre><code class="language-python"># horovod/runner/util/threads.py

def execute_function_multithreaded(fn, args_list, block_until_all_done=True, max_concurrent_executions=1000):
    worker_queue = queue.Queue()
    result_queue = queue.Queue() # 结果池，用于放置结果，后续忽略

    # 把任务放进任务池
    for i, arg in enumerate(args_list):
        worker_queue.put(arg)

    # 只要任务池里还有任务就取出来执行之
    def fn_execute():
        while True:
            arg = worker_queue.get(block=False)
            exec_index = arg[-1]
            res = fn(*arg[:-1])

    # 启动多线程分发命令，感觉必要性不大
    for _ in range(number_of_threads):
        thread = in_thread(target=fn_execute, daemon=not block_until_all_done)

def in_thread(target, args=(), name=None, daemon=True, silent=False):
    bg = threading.Thread(target=fn, args=args, name=name)
    bg.daemon = daemon
    bg.start()
</code></pre>
<pre><code class="language-python"># horovod/runner/common/util/safe_shell_exec.py

# 使用 multiprocessing.Process 启动进程
# 然后再使用 subprocess 启动进程执行

def execute(command, env=None, stdout=None, stderr=None, index=None, events=None,
            prefix_output_with_timestamp=False):
    ctx = multiprocessing.get_context('spawn')

    exit_event = _create_event(ctx)

    # 当 parent process 被 hard kill 时，这个 Pipe 会被关闭，然后 middleman 就会向子进程发送 SIGTERM，避免出现 orphaned process
    (r, w) = ctx.Pipe(duplex=False)

    middleman = ctx.Process(target=_exec_middleman, args=(command, env, exit_event, ..., (r, w)))
    middleman.start()

    middleman.join()
    return middleman.exitcode

def _exec_middleman(command, env, exit_event, stdout, stderr, rw):
    os.setsid()

    executor_shell = subprocess.Popen(command, shell=True, env=env,
                                      stdout=stdout_w, stderr=stderr_w)

</code></pre>
<pre><code class="language-python"># horovod/runner/mpi_run.py

def mpi_run(settings, nics, env, command, stdout=None, stderr=None):
    mpirun_command = (
        'mpirun {basic_args} '
        '-np {num_proc}{ppn_arg}{hosts_arg} '
        '{binding_args} '
        '{mpi_args} '
        '{mpi_ssh_args} '
        '{tcp_intf_arg} '
        '{nccl_socket_intf_arg} '
        '{output_filename_arg} '
        '{env} {extra_mpi_args} {command}'
    )

    if settings.run_func_mode:
        exit_code = safe_shell_exec.execute(mpirun_command, env=env, stdout=stdout, stderr=stderr)
    else:
        os.execve('/bin/sh', ['/bin/sh', '-c', mpirun_command], env)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="workflow-1"><a class="header" href="#workflow-1">Workflow</a></h1>
<p>本节关于 horovod 的主要工作流程，包含以下内容</p>
<ul>
<li>HorovodBasics 即 API 部分</li>
<li>Operation 基于上述 API 的调用和调用后主要流程</li>
</ul>
<h2 id="tldr"><a class="header" href="#tldr">TL;DR;</a></h2>
<p><code>hvd.init()</code> </p>
<ul>
<li>调用 c api <code>horovod_init</code>, 调用函数 <code>InitializeHorovodOnce</code> 创建 thread 运行 <code>BackgroundThreadLoop</code>, 完成初始化后函数返回。</li>
<li>后台线程执行 <code>BackgroundThreadLoop</code> 进行各种初始化操作，最后 while 循环 <code>RunLoopOnce(state)</code>.</li>
<li><code>RunLoopOnce</code> 从队列中取出 tensor 驱动分布式通信。</li>
</ul>
<p><code>allreduce_async_</code></p>
<ul>
<li>python api 是根据框架封装的，PyTorch 通过 pybind 调用 <code>EnqueueTensorAllreduces</code>，将 tensor 放如队列。</li>
</ul>
<h2 id="horovodbasics"><a class="header" href="#horovodbasics">HorovodBasics</a></h2>
<h3 id="python-api"><a class="header" href="#python-api">Python API</a></h3>
<ul>
<li>horovod 的基础 API，会被具体实现 (torch/tf) 使用</li>
<li>提供 C 接口的 py 封装，通过 ctypes 实现调用</li>
</ul>
<pre><code class="language-python"># horovod/common/basics.py

class HorovodBasics(object):
    def __init__(self, pkg_path, *args):
        # 加载 mpi lib 实现包
        self.MPI_LIB_CTYPES = ctypes.CDLL(full_path, mode=ctypes.RTLD_GLOBAL)

    def init(self, comm, process_sets):
        initialization_ok = self.MPI_LIB_CTYPES.horovod_init(...)
        # initialization_ok = self.MPI_LIB_CTYPES.horovod_init_multi_comm(...)

        _init_process_sets(process_sets)

    def shutdown(self):
    def is_initialized(self):
    def start_timeline(self, file_path, mark_cycles=False):
    def stop_timeline(self):
    def size(self):
    def local_size(self):
    def cross_size(self):
    def rank(self):
    def local_rank(self):
    def cross_rank(self):
    def is_homogeneous(self):
    def mpi_threads_supported(self):
    def mpi_enabled(self):
    def mpi_built(self):
    def gloo_enabled(self):
    def gloo_built(self):
    def nccl_built(self):
    def ddl_built(self):
    def ccl_built(self):
    def cuda_built(self):
    def rocm_built(self):
    def _add_process_set_impl(self, ranks: Sequence[int]) -&gt; Optional[int]:
    def _remove_process_set_impl(self, process_set_id: int) -&gt; Optional[int]:
    def _process_set_rank(self, process_set_id: int) -&gt; int:
    def _process_set_size(self, process_set_id: int) -&gt; int:
    def _get_process_set_ids_and_ranks(self) -&gt; Dict[int, List[int]]:
    def _comm_process_set_id(self, comm: MPI.Comm) -&gt; int:
</code></pre>
<h3 id="c-api"><a class="header" href="#c-api">C API</a></h3>
<p>这里的接口有两个部分</p>
<ul>
<li>系统相关的 C 接口，通过 py 的 ctypes 引用</li>
<li>通信相关的接口，直接被调用</li>
</ul>
<pre><code class="language-c">// horovod/common/operations.h

namespace horovod {
namespace common {

extern &quot;C&quot; {

bool horovod_init(const int* ranks, int nranks, const int* process_set_ranks,
                  const int* process_set_sizes, int num_process_sets);

#if HAVE_MPI
// 使用 MPI communicators 初始化
bool horovod_init_multi_comm(MPI_Comm* comm, int ncomms,
                             const int* process_set_ranks_via_ranks,
                             const int* process_set_sizes_via_ranks,
                             int num_process_sets_via_ranks);
#endif

void horovod_shutdown();

int horovod_rank();
int horovod_local_rank();

int horovod_size();
int horovod_local_size();

// bool horovod_xxx_enabled();
// bool horovod_xxx_built();

int horovod_reduce_op_average();
int horovod_reduce_op_sum();
int horovod_reduce_op_adasum();

int horovod_add_process_set(const int *ranks, int nranks);
int horovod_remove_process_set(int process_set_id);
int horovod_process_set_rank(int process_set_id);
int horovod_process_set_size(int process_set_id);
int horovod_process_set_included(int process_set_id);
int horovod_number_of_process_sets();
void horovod_process_set_ids(int* ids_prealloc);
int horovod_process_set_ranks(int id, int* ranks_prealloc);

} // C API 结束

Status EnqueueTensorAllreduce(std::shared_ptr&lt;OpContext&gt; context,
                              std::shared_ptr&lt;Tensor&gt; tensor,
                              std::shared_ptr&lt;Tensor&gt; output,
                              ReadyEventList ready_event_list,
                              std::string name, int device,
                              StatusCallback callback,
                              ReduceOp reduce_op = ReduceOp::SUM,
                              double prescale_factor = 1.0,
                              double postscale_factor = 1.0,
                              int32_t process_set_id = 0);

Status EnqueueTensorAllreduces(std::vector&lt;std::shared_ptr&lt;OpContext&gt;&gt;&amp; contexts,
                               std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt;&amp; tensors,
                               std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt;&amp; outputs,
                               std::vector&lt;ReadyEventList&gt;&amp; ready_event_lists,
                               std::vector&lt;std::string&gt;&amp; names,
                               int device,
                               std::vector&lt;StatusCallback&gt;&amp; callbacks,
                               ReduceOp reduce_op = ReduceOp::SUM,
                               double prescale_factor = 1.0,
                               double postscale_factor = 1.0,
                               int32_t process_set_id = 0);

Status EnqueueTensorAllgather(std::shared_ptr&lt;OpContext&gt; context,
                              std::shared_ptr&lt;Tensor&gt; tensor,
                              ReadyEventList ready_event_list,
                              const std::string&amp; name, int device,
                              StatusCallback callback,
                              int32_t process_set_id = 0);

Status EnqueueTensorBroadcast(std::shared_ptr&lt;OpContext&gt; context,
                              std::shared_ptr&lt;Tensor&gt; tensor,
                              std::shared_ptr&lt;Tensor&gt; output, int root_rank,
                              ReadyEventList ready_event_list,
                              const std::string&amp; name, int device,
                              StatusCallback callback,
                              int32_t process_set_id = 0);

Status EnqueueTensorAlltoall(std::shared_ptr&lt;OpContext&gt; context,
                             std::shared_ptr&lt;Tensor&gt; tensor,
                             std::shared_ptr&lt;Tensor&gt; splits,
                             ReadyEventList ready_event_list,
                             const std::string&amp; name, int device,
                             StatusCallback callback,
                             int32_t process_set_id = 0);

Status EnqueueTensorReducescatter(std::shared_ptr&lt;OpContext&gt; context,
                                  std::shared_ptr&lt;Tensor&gt; tensor,
                                  ReadyEventList ready_event_list,
                                  const std::string&amp; name, int device,
                                  StatusCallback callback,
                                  ReduceOp reduce_op = ReduceOp::SUM,
                                  int32_t process_set_id = 0);

Status EnqueueJoin(std::shared_ptr&lt;OpContext&gt; context,
                   std::shared_ptr&lt;Tensor&gt; output_last_joined_rank,
                   ReadyEventList ready_event_list,
                   const std::string&amp; name, int device,
                   StatusCallback callback,
                   int32_t process_set_id = 0);

Status EnqueueBarrier(StatusCallback callback,
                   int32_t process_set_id = 0);

} // namespace common
} // namespace horovod

#endif // HOROVOD_OPERATIONS_H
</code></pre>
<h2 id="operation"><a class="header" href="#operation">Operation</a></h2>
<p>Horovod 的主要流程都在 <code>horovod/common/operations.cc</code> 中，主线包含两个方面</p>
<ul>
<li>init 接口调用启动后台进程，不断从 tensor_queue 中取出需要通信的 tensor 进行通信并返回结果</li>
<li>用户前端接口调用间接调用 EnqueueTensorAllreduces 以及类似的 API 不断将需要进行通信的 tensor 放入 tensor_queue </li>
</ul>
<h3 id="初始化和出-queue"><a class="header" href="#初始化和出-queue">初始化和出 Queue</a></h3>
<p>初始化接口的具体实现，启动一个后台进程，不断出发执行通信操作</p>
<pre><code class="language-c">// horovod/common/operations.cc

extern &quot;C&quot; {

bool horovod_init(const int* ranks, int nranks, const int* process_set_ranks,
                  const int* process_set_sizes, int num_process_sets) {
  return InitializeHorovodOnce(...);
}

bool horovod_init_multi_comm(MPI_Comm* comm, int ncomms,
                             const int* process_set_ranks_via_ranks,
                             const int* process_set_sizes_via_ranks,
                             int num_process_sets_via_ranks) {
  return InitializeHorovodOnce(std::vector&lt;int&gt;(), process_set_ranks_vecs);
}

// 启动 horovod 后台进程，只执行一次
bool InitializeHorovodOnce(
    const std::vector&lt;int&gt;&amp; ranks,
    const std::vector&lt;std::vector&lt;int&gt;&gt;&amp; process_set_ranks) {

  EnrichProcessSetWithMPIController(global_process_set);

  if (!horovod_global.initialize_flag.test_and_set()) {
    horovod_global.initialization_done = false;
    horovod_global.background_thread =
        std::thread(BackgroundThreadLoop, std::ref(horovod_global));
  }

  while (!horovod_global.initialization_done &amp;&amp;
         !horovod_global.initialization_failed) {
    std::this_thread::sleep_for(std::chrono::milliseconds(1));
  }
}

// 初始化 controller，将 global 中的多个对象赋值给 controller 
void EnrichProcessSetWithMPIController(ProcessSet&amp; process_set) {
  process_set.controller.reset(new MPIController(
      process_set.response_cache, process_set.tensor_queue,
      horovod_global.timeline, horovod_global.parameter_manager,
      process_set.group_table, horovod_global.timeline_controller,
      process_set.mpi_context));
}

void BackgroundThreadLoop(HorovodGlobalState&amp; state) {
  auto mpi_ctx_manager = MPIContextManager();
  if (global_mpi_context.IsEnabled()) {
    global_mpi_context.Initialize(mpi_ctx_manager);
    if (state.control_operation == LibType::MPI) {
      // Initializes global controller
      state.process_set_table.Initialize(global_mpi_context);
    }
  }

  bool is_coordinator = state.global_controller-&gt;IsCoordinator();
  bool is_homogeneous = state.global_controller-&gt;IsHomogeneous();
  int size = state.global_controller-&gt;GetSize();
  int local_size = state.global_controller-&gt;GetLocalSize();
  int local_rank = state.global_controller-&gt;GetLocalRank();

  # 一堆配置
  state.parameter_manager.SetTensorFusionThresholdBytes(128 * 1024 * 1024);
  state.parameter_manager.SetTensorFusionThresholdBytes(threshold, true);
  state.parameter_manager.SetCycleTimeMs(1);
  state.parameter_manager.SetCacheEnabled(true);
  state.process_set_table.Get(0).response_cache.set_capacity(...)
  state.parameter_manager.SetHierarchicalAllgather(false);
  state.parameter_manager.SetHierarchicalAllreduce(false);

  while (RunLoopOnce(state));

  state.shut_down = true;

  horovod_global.process_set_table.Finalize(global_mpi_context,...)
}

bool RunLoopOnce(HorovodGlobalState&amp; state) {
  state.process_set_table.InitializeRegisteredAndRemoveMarkedIfReady(global_mpi_context);

  for (auto process_set_id : state.process_set_table.Ids()) {
    auto&amp; process_set = state.process_set_table.Get(process_set_id);
    auto response_list = process_set.IsCurrentProcessIncluded()
            ? process_set.controller-&gt;ComputeResponseList(this_process_requested_shutdown, state, process_set)
            : ResponseList();

    if (process_set.IsCurrentProcessIncluded()) {
      int global_rank = state.global_controller-&gt;GetRank();
      for (auto&amp; response : response_list.responses()) {
        PerformOperation(response, process_set);
      }
    }
  }
}
</code></pre>
<p>这里主要包含两个操作</p>
<ul>
<li>process_set.controller-&gt;ComputeResponseList 处理通信前的协同</li>
<li>PerformOperation 从 process_set 的 tensor_queue 中取出内容执行通信</li>
</ul>
<h3 id="performoperation"><a class="header" href="#performoperation">PerformOperation</a></h3>
<pre><code class="language-cpp">// 执行通信操作，获取 Response 
void PerformOperation(Response response, ProcessSet&amp; process_set) {
  std::vector&lt;TensorTableEntry&gt; entries;
  process_set.tensor_queue.GetTensorEntriesFromResponse(response, entries, process_set.joined);

  if (response.response_type() != Response::JOIN &amp;&amp;
      response.response_type() != Response::BARRIER) {
    if (entries.size() &gt; 1) {
      auto first_entry = entries[0];
      // 创建 buffer
      Status status = horovod_global.fusion_buffer.InitializeBuffer(
          process_set.controller-&gt;TensorFusionThresholdBytes(),
          first_entry.device, first_entry.context,
          horovod_global.current_nccl_stream,
          [&amp;]() { timeline.ActivityStartAll(entries, INIT_FUSION_BUFFER); },
          [&amp;]() { timeline.ActivityEndAll(entries); });
    }
  }

  // std::unique_ptr&lt;OperationManager&gt; op_manager;
  Status status = op_manager-&gt;ExecuteOperation(entries, response, process_set);
}
</code></pre>
<p><em>OperationManager-&gt;ExecuteOperation</em> 即调用对应 api 完成 op 的执行</p>
<h3 id="computeresponselist"><a class="header" href="#computeresponselist">ComputeResponseList</a></h3>
<p>这是 controller 里最重要的函数，它在 worker 间进行 allreduce/allgather 的协同，返回准备好通信的 tensor 列表，其中</p>
<ul>
<li>0 号 worker 作为 coordinator</li>
<li>每个 worker 都存有一份别的 worker 发送的准备好的 tensor 列表作为 cache</li>
</ul>
<p>具体流程如下</p>
<ul>
<li>worker 所有计划的通信操作都会先发送给 coordinator，Request 类型，包括 (tensor, reduce/gather, shape, type)</li>
<li>worker 发送 DONE 消息给 coordinator 当所有计划通信操作都已发送</li>
<li>coordinator 接受来自 worker 的计划通信请求，直到收集到所有节点的 DONE 消息</li>
<li>coordinator 为准备好的 tensor 构建并向 worker 发送 Response 消息，当发送完毕时发送 DONE 消息</li>
<li>worker 监听来自 coordinator 的消息，执行对应的 reduce/gather 操作，直到收到 DONE 消息</li>
</ul>
<pre><code class="language-cpp">// horovod/common/controller.cc

ResponseList Controller::ComputeResponseList(bool this_process_requested_shutdown,
                                             HorovodGlobalState&amp; state,
                                             ProcessSet&amp; process_set) {
  CacheCoordinator cache_coordinator(response_cache_.num_active_bits());

  // tensor_queue_ --&gt; message_queue_tmp
  std::deque&lt;Request&gt; message_queue_tmp;
  tensor_queue_.PopMessagesFromQueue(message_queue_tmp);

  // cache 机制
  // tensor_queue_.PushMessagesToQueue(messages_to_replace);

  ResponseList response_list;

  if (!need_communication) {
    std::deque&lt;Response&gt; responses;
    for (auto bit : cache_coordinator.cache_hits()) {
      responses.push_back(response_cache_.get_response(bit));
    }
    FuseResponses(responses, state, response_list);
  } else {
    std::vector&lt;std::string&gt; ready_to_reduce;

    if (is_coordinator_) { // 0 号 worker
      // message_queue_tmp --&gt; ready_to_reduce
      while (!message_queue_tmp.empty()) {
        Request message = message_queue_tmp.front();
        ready_to_reduce.push_back(message.tensor_name());
      }
      // Receive ready tensors from other ranks
      std::vector&lt;RequestList&gt; ready_list;
      RecvReadyTensors(ready_to_reduce, ready_list); // ready_to_reduce 未实际使用

      // ready_list +-&gt; ready_to_reduce 即把各 worker 收集到的和自己的合并
      for (int i = 1; i &lt; size_; ++i) {
        auto received_message_list = ready_list[i];
        for (auto&amp; received_message : received_message_list.requests()) {
          auto&amp; received_name = received_message.tensor_name();
          ready_to_reduce.push_back(received_name);
        }
      }

      // 到此准备通信的 tensor 准备完毕
      std::deque&lt;Response&gt; responses;

      for (auto&amp; tensor_name : ready_to_reduce) {
        Response response = ConstructResponse(tensor_name, process_set.joined_size);
        responses.push_back(std::move(response));
      }
      FuseResponses(responses, state, response_list);

      // Broadcast final results to other ranks.
      SendFinalTensors(response_list);

    } else { // 非 0 号 worker
      RequestList message_list;
      while (!message_queue_tmp.empty()) {
        message_list.add_request(message_queue_tmp.front());
      }

      // Send ready tensors to rank zero
      SendReadyTensors(message_list);

      // Receive final tensors to be processed from rank zero
      RecvFinalTensors(response_list);
    }
  }

  return response_list;
}
</code></pre>
<h3 id="调用和入-queue"><a class="header" href="#调用和入-queue">调用和入 Queue</a></h3>
<p>主要流程如下</p>
<ul>
<li>通过入参 process_set_id 从 global state 的 process_set_table 中取出 process_set 对象</li>
<li>使用入参 Tensor tensors 和 outputs 封装 Request 和 TensorTableEntry </li>
<li>把上述封装列表添加到 process_set 对象的 tensor_queue 中</li>
</ul>
<pre><code class="language-cpp">// horovod/common/operations.cc

Status
EnqueueTensorAllreduces(std::vector&lt;std::shared_ptr&lt;OpContext&gt;&gt;&amp; contexts,
                        std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt;&amp; tensors,
                        std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt;&amp; outputs,
                        std::vector&lt;ReadyEventList&gt;&amp; ready_event_lists,
                        std::vector&lt;std::string&gt;&amp; names, const int device,
                        std::vector&lt;StatusCallback&gt;&amp; callbacks,
                        ReduceOp reduce_op, double prescale_factor,
                        double postscale_factor, int32_t process_set_id) {

  auto&amp; process_set = horovod_global.process_set_table.Get(process_set_id);
  Status status;

  std::vector&lt;Request&gt; messages;
  std::vector&lt;TensorTableEntry&gt; entries;

  for (int n = 0; n &lt; (int)tensors.size(); ++n) {
    Request message;
    message.set_xxxx(...);
    messages.push_back(std::move(message));

    TensorTableEntry e;
    e.tensor = tensors[n];
    e.output = outputs[n];
    e.process_set_id = process_set_id;
    entries.push_back(std::move(e));
  }

  status = process_set.tensor_queue.AddToTensorQueueMulti(entries, messages);
  return status;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="object"><a class="header" href="#object">Object</a></h1>
<p>Object 列表</p>
<ul>
<li>OperationManager </li>
<li>HorovodGlobalState </li>
<li>ParameterManager </li>
<li>FusionBufferManager</li>
<li>ProcessSet &amp; ProcessSetTable</li>
<li>Controller</li>
<li>TensorQueue</li>
<li>GroupTable</li>
</ul>
<h3 id="horovodglobalstate"><a class="header" href="#horovodglobalstate">HorovodGlobalState</a></h3>
<p>全局状态类，用于保存全局信息，同时持有以下几个对象</p>
<pre><code class="language-cpp">// horovod/common/global_state.h

struct HorovodGlobalState {
  // Background thread running MPI communication.
  std::thread background_thread;

  bool elastic_enabled = false;

  ParameterManager parameter_manager;

  // handles resizing and auto-tuning of buffer size.
  FusionBufferManager fusion_buffer;

  ProcessSetTable process_set_table;

  std::shared_ptr&lt;Controller&gt; global_controller;
};
</code></pre>
<h3 id="parametermanager"><a class="header" href="#parametermanager">ParameterManager</a></h3>
<p><strong>WHAT</strong>
ParameterManager 会记录 tunable 的变量，包括时间和 fusion buffer size 等，然后以获得高吞吐为目标对其进程动态调整</p>
<p>Manager 类主要包含几个部分</p>
<ul>
<li>manager 自身的配置包括开关、warmup 信息等等</li>
<li>API 包括 update、tune 等</li>
<li>对可调整参数的封装，包括调整对象和调整方法</li>
<li>调整策略, 基于上述封装，实现怎样调整的策略</li>
</ul>
<pre><code class="language-cpp">// horovod/common/parameter_manager.h

class ParameterManager {
  // 根据 tensor 信息计算 score 和调用 Tune 调整参数
  // 返回值决定是否将更新后的参数广播出去
  bool Update(const std::vector&lt;std::string&gt;&amp; tensor_names, int64_t bytes);
  // 根据 score 调整参数
  bool Tune(double score);

  // Manager 的配置
  struct Params {
    bool hierarchical_allreduce;
    bool hierarchical_allgather;
    bool cache_enabled;
    double tensor_fusion_threshold;
    double cycle_time;
    bool active;
  };
  Params GetParams();

  // Interface used to represent a parameter (or group of parameters) being tuned.
  class ITunableParameter {
  public:
    virtual bool Tune(double score, double* best_score) = 0;
    virtual void UpdateBestValue(double score) = 0;
    virtual double BestScore() const = 0;
    virtual bool IsTunable() const = 0;
  };

  // Abstract base class used to implement hierarchical parameter tuning.
  template &lt;class T&gt;
  class TunableParameter : public ITunableParameter {
    TunableParameter(T initial_value);
    T initial_value_;
    T value_;
    T best_value_;
  };
  // 需要调整的参数对象
  std::vector&lt;ITunableParameter*&gt; parameter_chain_;

  // A parameter that optimizes over a finite set of discrete values to be tried sequentially.
  template &lt;class T&gt;
  class CategoricalParameter : public TunableParameter&lt;T&gt; {
    CategoricalParameter(std::vector&lt;T&gt; values);
    std::vector&lt;T&gt; values_;
  };

  enum BayesianVariable { fusion_buffer_threshold_mb, cycle_time_ms };

  struct BayesianVariableConfig {
    BayesianVariable variable;
    std::pair&lt;double, double&gt; bounds;
  };

  // A set of numerical parameters optimized jointly using Bayesian Optimization.
  class BayesianParameter : public TunableParameter&lt;Eigen::VectorXd&gt; {
    std::unique_ptr&lt;BayesianOptimization&gt; bayes_;
  };

  CategoricalParameter&lt;bool&gt; hierarchical_allreduce_;
  CategoricalParameter&lt;bool&gt; hierarchical_allgather_;
  CategoricalParameter&lt;bool&gt; cache_enabled_;
  BayesianParameter joint_params_;
};
</code></pre>
<h3 id="fusionbuffermanager"><a class="header" href="#fusionbuffermanager">FusionBufferManager</a></h3>
<p>这里的 Buffer 会伴随进程的整个生命周期</p>
<pre><code class="language-cpp">// horovod/common/fusion_buffer_manager.h

class FusionBufferManager {
public:
  Status InitializeBuffer(int64_t threshold,
                          int device, std::shared_ptr&lt;OpContext&gt; context,
                          int stream_id,
                          std::function&lt;void()&gt; on_start_init,
                          std::function&lt;void()&gt; on_end_init);
  // Status status = context-&gt;AllocatePersistent(threshold, &amp;buffer);

  std::shared_ptr&lt;PersistentBuffer&gt; GetBuffer(int device, Framework framework, int stream_id);

  // map key: device ID, framework, stream_id
  std::unordered_map&lt;std::tuple&lt;int, Framework, int&gt;,
      std::pair&lt;std::shared_ptr&lt;PersistentBuffer&gt;, int64_t&gt;&gt; tensor_fusion_buffers_;
};

</code></pre>
<h3 id="processset--processsettable"><a class="header" href="#processset--processsettable">ProcessSet &amp; ProcessSetTable</a></h3>
<p>ProcessSet 持有以下对象</p>
<ul>
<li>Controller controller</li>
<li>TensorQueue tensor_queue</li>
<li>GroupTable group_table</li>
</ul>
<p>基本调用流程</p>
<ul>
<li>HorovodGlobalState 中的 ProcessSetTable 对象</li>
<li>ProcessSetTable Ids() 方法获取 ProcessSet 的 id</li>
<li>ProcessSetTable Get() 方法从 id_to_process_set_ 变量中获取 ProcessSet 对象</li>
<li>ProcessSet 的 IsCurrentProcessIncluded() 方法判断可见性</li>
</ul>
<pre><code class="language-cpp">// horovod/common/process_set.h

struct ProcessSet {
  std::shared_ptr&lt;Controller&gt; controller;

  TensorQueue tensor_queue;

  // LRU cache of Responses
  ResponseCache response_cache;

  // Information on registered groups.
  GroupTable group_table;

  std::vector&lt;int&gt; registered_global_ranks;

  MPIContext mpi_context;

  bool Initialize(const MPIContext&amp; global_mpi_context);

  void Finalize(const Status&amp; status);

  bool IsCurrentProcessIncluded() const;

  explicit ProcessSet(std::vector&lt;int&gt; global_ranks = {});
};

class ProcessSetTable {
  ProcessSetTable();

  void Initialize(const MPIContext&amp; global_mpi_context);

  int32_t RegisterProcessSet(std::vector&lt;int&gt; global_ranks = {});

  std::vector&lt;int32_t&gt; Ids() const; // Returns copy to be threadsafe

  bool Contains(int32_t id) const;

  ProcessSet&amp; Get(int32_t id);

  // Returns -1 if no process set with these ranks has been registered.
  int32_t FindId(const std::vector&lt;int32_t&gt;&amp; ranks);

  void MarkProcessSetForRemoval(int32_t process_set_id);

  void DeregisterProcessSet(int32_t process_set_id);

  // ProcessSet 对象
  std::unordered_map&lt;int32_t, ProcessSet&gt; id_to_process_set_;
};
</code></pre>
<h3 id="controller"><a class="header" href="#controller">Controller</a></h3>
<p>Controller 持有以下对象需要在创建时传入，即外部依赖</p>
<ul>
<li>TensorQueue&amp; tensor_queue_</li>
<li>ResponseCache&amp; response_cache_</li>
<li>ParameterManager&amp; parameter_manager_</li>
<li>GroupTable&amp; group_table_</li>
</ul>
<pre><code class="language-cpp">class Controller : public std::enable_shared_from_this&lt;Controller&gt; {
  void Initialize();

  virtual int GetTypeSize(DataType dtype) = 0;

  virtual void CrossRankBitwiseAnd(std::vector&lt;long long&gt;&amp; bitvector, int count) = 0;

  virtual void CrossRankBitwiseOr(std::vector&lt;long long&gt;&amp; bitvector, int count) = 0;

  virtual void Bcast(void* buffer, size_t size, int root_rank, Communicator communicator) = 0;

  virtual void AlltoallGetRecvSplits(const std::vector&lt;int32_t&gt;&amp; splits, std::vector&lt;int32_t&gt;&amp; recvsplits) = 0;

  virtual void Barrier(Communicator communicator) = 0;

  virtual void Allgather2Ints(std::array&lt;int, 2&gt; values, std::vector&lt;int&gt;&amp; recv_values) = 0;

  void SynchronizeParameters();

  ResponseList ComputeResponseList(bool this_process_requested_shutdown, HorovodGlobalState&amp; state, ProcessSet&amp; process_set);

  virtual void DoInitialization() = 0;

  // For rank 0 to receive other ranks' ready tensors.
  virtual void RecvReadyTensors(std::vector&lt;std::string&gt;&amp; ready_to_reduce,
                                std::vector&lt;RequestList&gt;&amp; ready_list) = 0;

  // For other ranks to send their ready tensors to rank 0
  virtual void SendReadyTensors(RequestList&amp; message_list) = 0;

  // For rank 0 to send final tensors ready to be allreduced/allgathered to other ranks.
  virtual void SendFinalTensors(ResponseList&amp; response_list) = 0;

  // For other ranks to receive final ready tensors.
  virtual void RecvFinalTensors(ResponseList&amp; response_list) = 0;

  // Once a tensor is ready to be reduced, the coordinator sends a Response
  // instructing all ranks to start the reduction to all ranks. The Response
  // also contains error messages in case the submitted Requests were not
  // valid (for example, contained mismatched shapes or types).
  // Constructing the Response, thus, requires a whole lot of error checking.
  Response ConstructResponse(const std::string&amp; name, int joined_size = 0);

  // Routine to sync cache hit and invalid bit sets across workers.
  // Also determines global shutdown state and whether uncached requests
  // exist on any worker.
  void CoordinateCacheAndState(CacheCoordinator&amp; cache_coordinator);

  void FuseResponses(std::deque&lt;Response&gt;&amp; responses,
                     HorovodGlobalState&amp; state,
                     ResponseList&amp; response_list);

  // Return the total byte size of the final allgathered output tensor
  int64_t
  TotalByteSizeOfAllgatherOutput(const std::vector&lt;int64_t&gt;&amp; tensor_sizes,
                                 const TensorTableEntry&amp; entry);

  // Store the Request for a name, and return whether the total count of
  // Requests for that tensor is now equal to the HOROVOD size (and thus we are
  // ready to reduce the tensor).
  bool IncrementTensorCount(const Request&amp; msg, int joined_size = 0);

  bool is_initialized_ = false;

  int rank_ = 0;
  int local_rank_ = 0;
  int cross_rank_ = 0;
  int size_ = 1;
  int local_size_ = 1;
  int cross_size_ = 1;
  bool is_coordinator_ = false;
  bool is_homogeneous_ = false;

  // Global rank of each process in the set associated to this controller.
  std::vector&lt;int&gt; global_ranks_;

  // Map (global rank) -&gt; (process set controller rank) for each process in this
  // set.
  std::unordered_map&lt;int,int&gt; global_rank_to_controller_rank_;

  // Controller process set ranks of processes running on this node.
  std::vector&lt;int&gt; local_comm_ranks_;

  StallInspector stall_inspector_;

  // Only exists on the coordinator node (rank zero). Maintains a vector of
  // requests to allreduce every tensor (keyed by tensor name).
  MessageTable message_table_;

  // Outside dependencies
  TensorQueue&amp; tensor_queue_;

  ResponseCache&amp; response_cache_;

  ParameterManager&amp; parameter_manager_;

  GroupTable&amp; group_table_;
};
</code></pre>
<h3 id="tensorqueue"><a class="header" href="#tensorqueue">TensorQueue</a></h3>
<p>TensorQueue 被 Controller 持有，主要包含两个对象</p>
<ul>
<li>Request 的对象 message_queue_，在 controller 中被取出做准备工作</li>
<li>TensorTableEntry 对象 tensor_table_ 真正需要进行通信的 tensor</li>
</ul>
<pre><code class="language-cpp">// horovod/common/tensor_queue.h

class TensorQueue {
  TensorQueue() = default;
  Status AddToTensorQueue(TensorTableEntry&amp; e, Request&amp; message);
  Status AddToTensorQueueMulti(std::vector&lt;TensorTableEntry&gt;&amp; entries, std::vector&lt;Request&gt;&amp; messages);

  void FinalizeTensorQueue(const Status&amp; status);

  int64_t GetTensorDataForAutotuner(const ResponseList&amp; response_list,
                                    std::vector&lt;std::string&gt;&amp; tensor_names);

  void GetTensorEntriesFromResponse(const Response&amp; response,
                                    std::vector&lt;TensorTableEntry&gt;&amp; entries,
                                    bool joined = false);

  const TensorTableEntry&amp; GetTensorEntry(const std::string&amp; tensor_name) const;

  bool IsTensorPresentInTable (const std::string&amp; tensor_name) const;

  void PopMessagesFromQueue(std::deque&lt;Request&gt;&amp; message_queue_buffer);

  void PushMessageToQueue(Request&amp; message);

  void PushMessagesToQueue(std::deque&lt;Request&gt;&amp; messages);

  void RemoveJoinTensor();

  // Tensors waiting to be allreduced or allgathered.
  std::unordered_map&lt;std::string, TensorTableEntry&gt; tensor_table_;

  // Queue of MPI requests waiting to be sent to the coordinator node.
  std::queue&lt;Request&gt; message_queue_;
};
</code></pre>
<h3 id="grouptable"><a class="header" href="#grouptable">GroupTable</a></h3>
<p>在 ProcessSet 中持有，</p>
<ul>
<li>EnqueueTensorAllreduces 中调用 RegisterGroup</li>
<li>RunLoopOnce 中 PerformOperation 前会调用 DeregisterGroups</li>
</ul>
<pre><code class="language-cpp">// horovod/common/group_table.h

class GroupTable {
public:
  GroupTable() = default;

  int32_t GetGroupIDFromTensorName(const std::string&amp; tensor_name) const;
  const std::vector&lt;std::string&gt;&amp; GetGroupTensorNames(int32_t group_id) const;
  bool empty(void) const;

  int32_t RegisterGroup(std::vector&lt;std::string&gt;&amp;&amp; tensor_names);
  void DeregisterGroups(const std::vector&lt;std::string&gt;&amp; tensor_names);

  std::unordered_map&lt;std::string, int32_t&gt; tensor_name_to_id_;
  std::unordered_map&lt;int32_t, std::vector&lt;std::string&gt;&gt; id_to_tensor_names_;

  // Queue of ids that can be reused
  std::queue&lt;int32_t&gt; free_ids_;

  // Next available group id (increases each time a group is added)
  int32_t next_group_id_ = 0;
};
</code></pre>
<h3 id="operationmanager"><a class="header" href="#operationmanager">OperationManager</a></h3>
<p>对通信 op 的一个封装，基本上通过调用 op-&gt;Excute 实现，为 horovod/common/ops 目录中的各个 op 实现提供了接口。</p>
<pre><code class="language-cpp">// horovod/common/ops/operation_manager.h

class OperationManager {
  OperationManager(ParameterManager* param_manager,
                   std::vector&lt;std::shared_ptr&lt;AllreduceOp&gt;&gt; allreduce_ops,
                   std::vector&lt;std::shared_ptr&lt;AllgatherOp&gt;&gt; allgather_ops,
                   std::vector&lt;std::shared_ptr&lt;BroadcastOp&gt;&gt; broadcast_ops,
                   std::vector&lt;std::shared_ptr&lt;AlltoallOp&gt;&gt; alltoall_ops,
                   std::vector&lt;std::shared_ptr&lt;ReducescatterOp&gt;&gt; reducescatter_ops,
                   std::shared_ptr&lt;JoinOp&gt; join_op,
                   std::vector&lt;std::shared_ptr&lt;AllreduceOp&gt;&gt; adasum_ops,
                   std::shared_ptr&lt;BarrierOp&gt; barrier_op,
                   std::shared_ptr&lt;ErrorOp&gt; error_op);

  Status ExecuteAllreduce(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteAllgather(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteBroadcast(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteAlltoall(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteReducescatter(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteError(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteJoin(std::vector&lt;TensorTableEntry&gt;&amp; entries,
                     const Response&amp; response, ProcessSet&amp; process_set) const;

  Status ExecuteAdasum(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteBarrier(std::vector&lt;TensorTableEntry&gt;&amp; entries, const Response&amp; response) const;

  Status ExecuteOperation(std::vector&lt;TensorTableEntry&gt;&amp; entries,
                          const Response&amp; response,
                          ProcessSet&amp; process_set) const;

  ParameterManager* param_manager_;

  std::vector&lt;std::shared_ptr&lt;AllreduceOp&gt;&gt; allreduce_ops_;
  std::vector&lt;std::shared_ptr&lt;AllgatherOp&gt;&gt; allgather_ops_;
  std::vector&lt;std::shared_ptr&lt;BroadcastOp&gt;&gt; broadcast_ops_;
  std::vector&lt;std::shared_ptr&lt;AlltoallOp&gt;&gt; alltoall_ops_;
  std::vector&lt;std::shared_ptr&lt;ReducescatterOp&gt;&gt; reducescatter_ops_;
  std::shared_ptr&lt;JoinOp&gt; join_op_;
  std::vector&lt;std::shared_ptr&lt;AllreduceOp&gt;&gt; adasum_ops_;
  std::shared_ptr&lt;BarrierOp&gt; barrier_op_;
  std::shared_ptr&lt;ErrorOp&gt; error_op_;
};
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="develop"><a class="header" href="#develop">Develop</a></h1>
<p>这里列的 horovod 对象是用于二次开发的接口。</p>
<h2 id="horovod-对象"><a class="header" href="#horovod-对象">Horovod 对象</a></h2>
<pre><code class="language-cpp"># horovod/common/common.h

enum Framework { TENSORFLOW, PYTORCH, MXNET, XLA };
enum StatusType { OK, UNKNOWN_ERROR, PRECONDITION_ERROR, ABORTED, INVALID_ARGUMENT, IN_PROGRESS };
enum DeviceType { CPU, GPU };

// for gpu
struct Event {
  std::shared_ptr&lt;gpuEvent_t&gt; event;
  uint64_t event_idx;
  gpuStream_t stream = nullptr;
};

class Status {
public:
  Status();
  static Status OK();
  static Status UnknownError(const std::string&amp; message);
  static Status PreconditionError(const std::string&amp; message);
  static Status Aborted(const std::string&amp; message);
  static Status InvalidArgument(const std::string&amp; message);
  static Status InProgress();
  bool ok() const;
  bool in_progress() const;
  StatusType type() const;
  const std::string&amp; reason() const;
  Event event;

private:
  StatusType type_ = StatusType::OK;
  std::string reason_;
  Status(StatusType type, std::string reason);
};

class TensorShape {
public:
  TensorShape() : shape_() {}
  TensorShape(std::vector&lt;int64_t&gt; vec) : shape_(vec) {}
  void AddDim(int64_t dim);
  void AppendShape(TensorShape&amp; other);

  std::string DebugString() const;
  int dims() const;
  int64_t dim_size(int idx) const;
  int64_t num_elements() const;
  const std::vector&lt;int64_t&gt;&amp; to_vector() const;

  inline bool operator==(const TensorShape&amp; rhs) const {
    return shape_ == rhs.shape_;
  }

  inline bool operator!=(const TensorShape&amp; rhs) const {
    return shape_ != rhs.shape_;
  }

private:
  std::vector&lt;int64_t&gt; shape_;
};

class ReadyEvent {};
class ReadyEventList {};

class PersistentBuffer {
public:
  virtual const void* AccessData(std::shared_ptr&lt;OpContext&gt; context) const = 0;
  virtual ~PersistentBuffer() = default;
};

class Tensor {
public:
  virtual const DataType dtype() const = 0;
  virtual const TensorShape shape() const = 0;
  virtual const void* data() const = 0;
  virtual int64_t size() const = 0;
  virtual ~Tensor() = default;
};

class OpContext {
public:
  // These allocators are fully synchronous, unlike TensorFlow counterparts.
  virtual Status
  AllocatePersistent(int64_t size,
                     std::shared_ptr&lt;PersistentBuffer&gt;* tensor) = 0;
  virtual Status AllocateOutput(TensorShape shape,
                                std::shared_ptr&lt;Tensor&gt;* tensor,
                                std::shared_ptr&lt;ReadyEvent&gt;* event = nullptr) = 0;
  virtual Status AllocateOutput(int output_index, TensorShape shape,
                                std::shared_ptr&lt;Tensor&gt;* tensor,
                                std::shared_ptr&lt;ReadyEvent&gt;* event = nullptr) {
    if (output_index == 0) {
      return AllocateOutput(std::move(shape), tensor);
    } else {
      throw std::logic_error(&quot;output_index != 0 not supported&quot;);
    }
  }
  virtual Status AllocateZeros(int64_t num_elements, DataType dtype,
                                std::shared_ptr&lt;Tensor&gt;* tensor) = 0;
  virtual Framework framework() const = 0;
  virtual ~OpContext() = default;
};

// A callback to call after the communication completes. Since the
// allreduce and allgather ops are asynchronous, this callback is what resumes
// computation after the reduction is completed.
using StatusCallback = std::function&lt;void(const Status&amp;)&gt;;

// Table storing Tensors to be reduced, keyed by unique name.
// This table contains everything necessary to do the distributed operation.
struct TensorTableEntry {
  std::string tensor_name;
  std::shared_ptr&lt;OpContext&gt; context;
  std::shared_ptr&lt;Tensor&gt; tensor;
  std::shared_ptr&lt;Tensor&gt; output;
  // Identifier for the subset of Horovod processes partaking in this operation.
  int32_t process_set_id = 0;
  // Root rank for broadcast operation (relative to process set).
  int root_rank = 0;
  // List of events indicating that data is ready.
  ReadyEventList ready_event_list;
  // GPU to do reduction on, or CPU_DEVICE_ID in case of CPU.
  int device = CPU_DEVICE_ID;
  // A callback to call with the status.
  StatusCallback callback;
  // If we build with NVTX support: A range marking the start
  // and end of the distributed op for this tensor (may be
  // shared by multiple tensors).
  SharedNvtxOpRange nvtx_op_range;

  // Alltoall splits (if tensor is for an Alltoall operation)
  // Note: splits are stored in TensorTableEntry to avoid N^2
  // storage complexity of collecting all worker split arrays
  // on coordinator rank.
  std::vector&lt;int32_t&gt; splits;
  std::shared_ptr&lt;Tensor&gt; received_splits;

  void FinishWithCallback(const Status&amp; status);
};
</code></pre>
<h3 id="message"><a class="header" href="#message">Message</a></h3>
<h4 id="request"><a class="header" href="#request">Request</a></h4>
<pre><code class="language-cpp">// horovod/common/message.h

// Request 是非 0 worker 向 0 号 worker 即 coordinator 发送消息的消息体
class Request {
  enum RequestType {
    ALLREDUCE = 0,
    ALLGATHER = 1,
    BROADCAST = 2,
    JOIN = 3,
    ADASUM = 4,
    ALLTOALL = 5,
    BARRIER = 6,
    REDUCESCATTER = 7
  };

  static const std::string&amp; RequestType_Name(RequestType value);
  int32_t request_rank() const;
  void set_request_rank(int32_t value);
  RequestType request_type() const;
  void set_request_type(RequestType value);
  DataType tensor_type() const;
  void set_tensor_type(DataType value);
  const std::string&amp; tensor_name() const;
  void set_tensor_name(const std::string&amp; value);
  int32_t root_rank() const;
  void set_root_rank(int32_t value);
  int32_t device() const;
  void set_device(int32_t value);
  int32_t group_id() const;
  void set_group_id(int32_t value);
  const std::vector&lt;int64_t&gt;&amp; tensor_shape() const;
  void set_tensor_shape(const std::vector&lt;int64_t&gt;&amp; value);
  void add_tensor_shape(int64_t value);
  double prescale_factor() const;
  double postscale_factor() const;
  void set_prescale_factor(double prescale_factor);
  void set_postscale_factor(double postscale_factor);
  static void ParseFromBytes(Request&amp; request, const uint8_t* input);
  static void SerializeToString(const Request&amp; request, std::string&amp; output);

  int32_t request_rank_ = 0;
  RequestType request_type_ = RequestType::ALLREDUCE;
  DataType tensor_type_ = DataType::HOROVOD_UINT8;
  int32_t root_rank_ = 0;
  int32_t device_ = 0;
  int32_t group_id_ = NULL_GROUP_ID;
  std::string tensor_name_;
  std::vector&lt;int64_t&gt; tensor_shape_;
  double prescale_factor_ = 1.0;
  double postscale_factor_ = 1.0;
};

class RequestList {
  const std::vector&lt;Request&gt;&amp; requests() const;
  void set_requests(const std::vector&lt;Request&gt;&amp; value);
  void add_request(const Request&amp; value);
  void emplace_request(Request&amp;&amp; value);
  bool shutdown() const;
  void set_shutdown(bool value);
  static void ParseFromBytes(RequestList&amp; request_list, const uint8_t* input);
  static void SerializeToString(const RequestList&amp; request_list, std::string&amp; output);

  std::vector&lt;Request&gt; requests_;
  bool shutdown_ = false;
};
</code></pre>
<h4 id="response"><a class="header" href="#response">Response</a></h4>
<pre><code class="language-cpp">// Response 是 0 号 worker 即 coordinator 向非 0 worker 发送消息的消息体
class Response {
public:
  enum ResponseType {
    ALLREDUCE = 0,
    ALLGATHER = 1,
    BROADCAST = 2,
    JOIN = 3,
    ADASUM = 4,
    ALLTOALL = 5,
    BARRIER = 6,
    REDUCESCATTER = 7,
    ERROR = 8
  };

  static const std::string&amp; ResponseType_Name(ResponseType value);
  ResponseType response_type() const;
  void set_response_type(ResponseType value);
  const std::vector&lt;std::string&gt;&amp; tensor_names() const;
  DataType tensor_type() const;
  void set_tensor_type(DataType value);
  const std::string tensor_names_string() const;
  void set_tensor_names(const std::vector&lt;std::string&gt;&amp; value);
  void add_tensor_name(const std::string&amp; value);
  void add_tensor_name(std::string&amp;&amp; value);
  const std::string&amp; error_message() const;
  void set_error_message(const std::string&amp; value);
  const std::vector&lt;int32_t&gt;&amp; devices() const;
  void set_devices(const std::vector&lt;int32_t&gt;&amp; value);
  void add_device(int32_t value);
  const std::vector&lt;int64_t&gt;&amp; tensor_sizes() const;
  void set_tensor_sizes(const std::vector&lt;int64_t&gt;&amp; value);
  void add_tensor_size(int64_t value);
  void add_allgather_response(const Response&amp; response);
  double prescale_factor() const;
  double postscale_factor() const;
  void set_prescale_factor(double prescale_factor);
  void set_postscale_factor(double postscale_factor);
  int last_joined_rank() const;
  void set_last_joined_rank(int value);
  static void ParseFromBytes(Response&amp; response, const uint8_t* input);
  static void SerializeToString(const Response&amp; response, std::string&amp; output);

  ResponseType response_type_ = ResponseType::ALLREDUCE;
  std::vector&lt;std::string&gt; tensor_names_;
  DataType tensor_type_ = DataType::HOROVOD_UINT8;
  std::string error_message_;
  std::vector&lt;int32_t&gt; devices_;
  std::vector&lt;int64_t&gt; tensor_sizes_;
  double prescale_factor_ = 1.0;
  double postscale_factor_ = 1.0;
  int last_joined_rank_ = -1;
};

class ResponseList {
  const std::vector&lt;Response&gt;&amp; responses() const;
  void set_responses(const std::vector&lt;Response&gt;&amp; value);
  void add_response(const Response&amp; value);
  void add_response(Response&amp;&amp; value);
  void emplace_response(Response&amp;&amp; value);
  bool shutdown() const;
  void set_shutdown(bool value);
  static void ParseFromBytes(ResponseList&amp; response_list, const uint8_t* input);
  static void SerializeToString(const ResponseList&amp; response_list, std::string&amp; output);

  std::vector&lt;Response&gt; responses_;
  bool shutdown_ = false;
};
</code></pre>
<p>ResponseCache </p>
<pre><code class="language-cpp">// horovod/common/response_cache.h

struct TensorParams {
  DataType dtype;
  std::vector&lt;int64_t&gt; shape;
  int32_t device;
};

// LRU cache of Responses
class ResponseCache {
public:
  ResponseCache() = default;
  ResponseCache(const ResponseCache&amp;) = delete;

  enum CacheState { MISS = 0, HIT = 1, INVALID = 2 };

  void clear();

  void set_capacity(uint32_t capacity);

  uint32_t capacity() const;

  size_t num_active_bits() const;

  CacheState cached(const Request&amp; message) const;

  CacheState cached(const Response&amp; response, const TensorParams&amp; params,
                    bool joined = false) const;

  void put(const Response&amp; response, TensorQueue&amp; tensor_queue,
           bool joined = false);

  const Response&amp; get_response(uint32_t cache_bit);

  const Response&amp; peek_response(uint32_t cache_bit) const;

  uint32_t peek_cache_bit(const Request&amp; message) const;

  uint32_t peek_cache_bit(const std::string&amp; tensor_name) const;

  std::vector&lt;uint32_t&gt; list_all_bits() const;

  void erase_response(uint32_t cache_bit);

  void update_cache_bits();

private:
  void put_(const Response&amp; response, TensorParams&amp; params,
            bool joined = false);

  uint32_t capacity_ = 0;

  // List containing cached entries. Each entry in the cache is a pair
  // of a Response and a TensorParams struct.
  std::list&lt;std::pair&lt;Response, TensorParams&gt;&gt; cache_;

  // Vector of iterators to cache entries. Indexed by cache bit.
  std::vector&lt;std::list&lt;std::pair&lt;Response, TensorParams&gt;&gt;::iterator&gt;
      cache_iters_;

  // Lookup table mapping tensor names to assigned cache bits.
  std::unordered_map&lt;std::string, uint32_t&gt; tensor_name_to_bit_;

  bool bits_outdated_ = false;

  bool print_warning_ = true;
};

// Helper class to coordinate cache and state information
// across workers. Uses global controller operations on a bit vector
// for cheaper coordination.
class CacheCoordinator {
public:
  explicit CacheCoordinator(size_t num_active_bits_);

  void record_hit(uint32_t bit);

  void record_invalid_bit(uint32_t bit);

  void erase_hit(uint32_t bit);

  void set_should_shut_down(bool should_shut_down);

  void set_uncached_in_queue(bool uncached_in_queue);

  const std::set&lt;uint32_t&gt;&amp; cache_hits() const;

  const std::set&lt;uint32_t&gt;&amp; invalid_bits() const;

  const std::set&lt;uint32_t&gt;&amp; timeline_bits() const;

  bool should_shut_down() const;

  bool uncached_in_queue() const;

  // Method to sync state and bit sets across workers.
  void sync(std::shared_ptr&lt;Controller&gt; controller, bool timeline_enabled);

private:
  enum StatusBit {
    SHOULD_SHUT_DOWN = 0,
    UNCACHED_IN_QUEUE = 1,
    INVALID_IN_QUEUE = 2
  };

  // Number of active bits in the cache. Required to size the
  // bitvector identically across workers.
  size_t num_active_bits_;

  // Set of cache hit bits. After sync(), contains only common
  // cache hit bits across workers.
  std::set&lt;uint32_t&gt; cache_hits_;

  // Set of invalid bits. After sync(), contains only common
  // invalid bits across workers.
  std::set&lt;uint32_t&gt; invalid_bits_;

  // Set of bits for timeline handling. After sync(), contains bits
  // where at least one worker recorded a cache hit. This indicates
  // that the timeline negotion phase should be started/continued.
  std::set&lt;uint32_t&gt; timeline_bits_;

  // States used externally in cycle loop.
  bool should_shut_down_ = false;
  bool uncached_in_queue_ = false;

  // State used internally to trigger second bit vector communication
  // to sync invalid bits.
  bool invalid_in_queue_ = false;

  std::vector&lt;long long&gt; bitvector_;

  bool synced_ = false;
};
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="pytorch-1"><a class="header" href="#pytorch-1">PyTorch</a></h1>
<h2 id="api-2"><a class="header" href="#api-2">API</a></h2>
<p><code>horovod.torch</code> api</p>
<p>大部分 api 从 mpi_ops 中引入</p>
<pre><code class="language-python"># horovod/torch/__init__.py

from horovod.torch import elastic
from horovod.torch.compression import Compression
from horovod.torch.functions import allgather_object, broadcast_object, broadcast_optimizer_state, broadcast_parameters
from horovod.torch.mpi_ops import allreduce, allreduce_async, allreduce_, allreduce_async_
from horovod.torch.mpi_ops import grouped_allreduce, grouped_allreduce_async, grouped_allreduce_, grouped_allreduce_async_
from horovod.torch.mpi_ops import sparse_allreduce_async
from horovod.torch.mpi_ops import allgather, allgather_async
from horovod.torch.mpi_ops import broadcast, broadcast_async, broadcast_, broadcast_async_
from horovod.torch.mpi_ops import alltoall, alltoall_async
from horovod.torch.mpi_ops import reducescatter, reducescatter_async
from horovod.torch.mpi_ops import join
from horovod.torch.mpi_ops import barrier
from horovod.torch.mpi_ops import poll, synchronize
from horovod.torch.mpi_ops import init, shutdown
from horovod.torch.mpi_ops import is_initialized, start_timeline, stop_timeline
from horovod.torch.mpi_ops import size, local_size, cross_size, rank, local_rank, cross_rank
from horovod.torch.mpi_ops import mpi_threads_supported, mpi_enabled, mpi_built
from horovod.torch.mpi_ops import gloo_enabled, gloo_built
from horovod.torch.mpi_ops import nccl_built, ddl_built, ccl_built, cuda_built, rocm_built
from horovod.torch.mpi_ops import ProcessSet, global_process_set, add_process_set, remove_process_set
from horovod.torch.mpi_ops import Average, Sum, Adasum
from horovod.torch.optimizer import DistributedOptimizer
from horovod.torch.sync_batch_norm import SyncBatchNorm
</code></pre>
<p><code>mpi_ops</code></p>
<p>这里的 api 分为两部分</p>
<ul>
<li>一部分从 mpi_lib_v2 library 中通过 C api 暴露，然后通过 basic 引入</li>
<li>通信 api 通过 pybind 调用</li>
</ul>
<pre><code class="language-python"># horovod/torch/mpi_ops.py

# so library
from horovod.torch import mpi_lib_v2 as mpi_lib

_basics = _HorovodBasics(__file__, 'mpi_lib_v2')
# import basic methods
# mpi_ops 中会包含 basic 中的 api

# 重要
# handle 会被放在 map 中，避免被 gc
# 在 synchronize 之后被释放
_handle_map = {}

# inplace allreduce
# allreduce_ -&gt; allreduce_async_ + synchronize -&gt; _allreduce_async -&gt; mpi_lib.horovod_torch_allreduce_async_

# allreduce
# allreduce -&gt; HorovodAllreduce.apply -&gt; allreduce_async + synchronize -&gt; _allreduce_async -&gt; mpi_lib.horovod_torch_allreduce_async_

def _allreduce_function_factory(tensor):
    return 'horovod_torch_allreduce_async_' + tensor.type().replace('.', '_')


def _allreduce_async(tensor, output, name, op, prescale_factor, postscale_factor, process_set: ProcessSet):
    function = _check_function(_allreduce_function_factory, tensor)
    try:
        handle = getattr(mpi_lib, function)(tensor, output, divisor,
                                            name.encode() if name is not None else _NULL, op,
                                            prescale_factor, postscale_factor, process_set.process_set_id)
    except RuntimeError as e:
        raise HorovodInternalError(e)
    return handle


def allreduce_async(tensor, average=None, name=None, op=None,
                    prescale_factor=1.0, postscale_factor=1.0,
                    process_set=global_process_set):
    output = tensor.new(tensor.shape)
    return _allreduce_async(tensor, output, name, op, prescale_factor, postscale_factor, process_set)


class HorovodAllreduce(torch.autograd.Function):
    @staticmethod
    def forward(ctx, tensor, average, name, op, prescale_factor, postscale_factor, process_set):
        ctx.average = average
        ctx.op = op
        ctx.prescale_factor = prescale_factor
        ctx.postscale_factor = postscale_factor
        ctx.process_set = process_set
        handle = allreduce_async(tensor, average, name, op, prescale_factor, postscale_factor, process_set)
        return synchronize(handle)

    @staticmethod
    def backward(ctx, grad_output):
        return allreduce(grad_output, average=ctx.average, op=ctx.op,
                         prescale_factor=ctx.prescale_factor,
                         postscale_factor=ctx.postscale_factor,
                         process_set=ctx.process_set), None, None, None, None, None, None


def allreduce(tensor, average=None, name=None, compression=Compression.none, op=None,
              prescale_factor=1.0, postscale_factor=1.0, process_set=global_process_set):
    &quot;&quot;&quot;
    This acts as a thin wrapper around an autograd function.  If your input
    tensor requires gradients, then callings this function will allow gradients
    to be computed and backpropagated.
    &quot;&quot;&quot;
    tensor_compressed, ctx = compression.compress(tensor)
    summed_tensor_compressed = HorovodAllreduce.apply(tensor_compressed, average, name, op,
                                                      prescale_factor, postscale_factor,
                                                      process_set)
    return compression.decompress(summed_tensor_compressed, ctx)


def allreduce_async_(tensor, average=None, name=None, op=None,
                     prescale_factor=1.0, postscale_factor=1.0,
                     process_set=global_process_set):
    op = handle_average_backwards_compatibility(op, average)
    return _allreduce_async(tensor, tensor, name, op, prescale_factor, postscale_factor, process_set)


def allreduce_(tensor, average=None, name=None, op=None,
               prescale_factor=1.0, postscale_factor=1.0,
               process_set=global_process_set):
    handle = allreduce_async_(tensor, average, name, op, prescale_factor, postscale_factor, process_set)
    return synchronize(handle)

</code></pre>
<p>这里最终调用的例如 <code>mpi_lib.horovod_torch_allreduce_async_</code> api 来自 cpp api 的 pybind.</p>
<p>cpp api</p>
<pre><code class="language-cpp">// horovod/torch/mpi_ops_v2.cc

PYBIND11_MODULE(mpi_lib_v2, m) {
  m.def(&quot;horovod_torch_allreduce_async_torch_IntTensor&quot;, &amp;DoAllreduce);
  ...
}

int DoAllreduce(::torch::Tensor tensor, ::torch::Tensor output, int divisor,
                const std::string&amp; name, int reduce_op_int,
                double prescale_factor, double postscale_factor,
                int process_set_id) {
  auto handle = handle_manager.AllocateHandle();
  common::ReadyEventList ready_event_list;
  auto hvd_tensor = std::make_shared&lt;TorchTensor&gt;(tensor);
  auto hvd_context = std::make_shared&lt;TorchOpContext&gt;(device, output);
  auto hvd_output = std::make_shared&lt;TorchTensor&gt;(output);

  ReduceOp reduce_op = static_cast&lt;ReduceOp&gt;(reduce_op_int);
  auto enqueue_result = EnqueueTensorAllreduce(hvd_context, hvd_tensor, hvd_output, ready_event_list, ... handle);

  return handle;
}
</code></pre>
<p>这里主要包括两个内容</p>
<ul>
<li>torch tensor 到 horovod tensor 的转换</li>
<li>调用来自 horovod/common/operations.h 的 <code>EnqueueTensorAllreduce</code> 将计划通信的 tensor 加入队列</li>
</ul>
<h3 id="handlemanager"><a class="header" href="#handlemanager">HandleManager</a></h3>
<p>HandleManager 用于记录通信操作的返回结果 Status, 通过它可以知道操作完成情况和进行同步。</p>
<pre><code class="language-cpp">// horovod/torch/handle_manager.h

class HandleManager {
  std::unordered_map&lt;int, std::shared_ptr&lt;Status&gt;&gt; results_;
};
</code></pre>
<h3 id="torchtensor"><a class="header" href="#torchtensor">TorchTensor</a></h3>
<p>TorchTensor 是 horovod tensor 的子类，它实现了对应的接口，horovod 的通信中可以直接使用该对象.</p>
<pre><code class="language-cpp">// horovod/torch/adapter_v2.h

class TorchPersistentBuffer : public PersistentBuffer {
  AccessData(std::shared_ptr&lt;OpContext&gt; context) const override;
  ::torch::Tensor tensor_;
};

class TorchTensor : public Tensor {
  ::torch::Tensor tensor_;
};

class TorchOpContext : public OpContext {
  std::vector&lt;::torch::Tensor&gt; outputs_;
};
</code></pre>
<h2 id="develop-1"><a class="header" href="#develop-1">Develop</a></h2>
<p>总结 PyTorch 接入 Horovod 框架需要做的工作</p>
<ul>
<li>API 封装，暴露拓展的 API 给用户，可以使用 torch 的 tensor 作为参数传递等；在 <code>horovod/torch/mpi_ops.py</code> 中实现</li>
<li>API 对接，前端 API 调用 horovod API 以及绑定 py API；在 <code>horovod/torch/mpi_ops_v2.cc</code> 中实现</li>
<li>Tensor 适配，即 torch 的 tensor 能够在 horovord 框架中使用；在 <code>horovod/torch/adapter_v2.*</code> 中实现</li>
</ul>
<h2 id="distributedoptimizer"><a class="header" href="#distributedoptimizer">DistributedOptimizer</a></h2>
<h3 id="demo-3"><a class="header" href="#demo-3">Demo</a></h3>
<pre><code class="language-python">output = model(data)
loss = F.nll_loss(output, target)
loss.backward()
optimizer.synchronize()
torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)
with optimizer.skip_synchronize():
    optimizer.step()
</code></pre>
<pre><code class="language-python">class _DistributedOptimizer(torch.optim.Optimizer):
    def __init__(self, ...):
        self._register_hooks()

    def _register_hooks(self):
        for param_group in self.param_groups:
            for p in param_group['params']:
                if p.requires_grad:
                    self._requires_update.add(p)
                    # p_tmp 和 p 使用同样的 storage，不占用额外显存
                    p_tmp = p.expand_as(p)
                    grad_acc = p_tmp.grad_fn.next_functions[0][0]
                    grad_acc.register_hook(self._make_hook(p))
                    self._grad_accs.append(grad_acc)

    def _make_hook(self, p):
        def hook(*ignore):
            handle, ctx = None, None
            self._allreduce_delay[p] -= 1
            if self._allreduce_delay[p] == 0:
                handle, ctx = self._allreduce_grad_async(p)
            self._handles[p] = (handle, ctx)
        return hook

    def _allreduce_grad_async(self, p):
        name = self._parameter_names.get(p)
        tensor = p.grad

        if p.grad.is_sparse:
            if self.sparse_as_dense:
                tensor = tensor.to_dense()
            else:
                return self._sparse_allreduce_grad_async(p, name)

        tensor_compressed, ctx = self._compression.compress(tensor)

        handle = allreduce_async_(tensor_compressed, name=name, op=self.op,
                                  prescale_factor=prescale_factor,
                                  postscale_factor=postscale_factor,
                                  process_set=self.process_set)
        return handle, ctx

    def _sparse_allreduce_grad_async(self, p, name):
        handle = sparse_allreduce_async(p.grad, name=name, op=self.op,
                                        process_set=self.process_set)
        return handle, None

    def synchronize(self):
        if not self.process_set.included():
            self._synchronized = True
            return

        completed = set()
        for x in self._handles.keys():
          completed.update(x) if isinstance(x, tuple) else completed.add(x)
        missing_p = self._requires_update - completed

        # 处理 hook 注册不成功，或者说 hook 没有被调用
        # hook 被调用后会添加 self._handles
        for p in missing_p:
            handle, ctx = self._allreduce_grad_async(p)
            self._handles[p] = (handle, ctx)

        # handle 为 None 的 hook 跳过又不跳过了？
        # 需要注意 synchronize 函数每个 step 被调用，但不是每次 backward 都会被调用
        # 在之前的 train 中有每个 step 会多次 backward，所以 grad 的 hook 会被多次调用，次数匹配
        # 所以代码执行到这里 handle 应该是一次调用_allreduce_grad_async 如果不是就补上
        for p, (handle, ctx) in self._handles.items():
            if handle is None:
                handle, ctx = self._allreduce_grad_async(p)
                self._handles[p] = (handle, ctx)

        # for 循环处理异步通信的结果
        for p, (handle, ctx) in self._handles.items():
                # When handle is a callable function, it returns the aggregated tensor result
                output = synchronize(handle) if not callable(handle) else handle()
                self._allreduce_delay[p] = self.backward_passes_per_step
                if p.grad.is_sparse:
                    aggregated = self._compression.decompress(output, ctx)
                    if not aggregated.is_sparse:
                        aggregated = aggregated.to_sparse()

                    # Sparse grads do not support set_ for some reason, so we do this as an equivalent
                    p.grad.zero_().add_(aggregated)
                else:
                    p.grad.set_(self._compression.decompress(output, ctx))
        self._handles.clear()

        self._synchronized = True


def DistributedOptimizer(optimizer, named_parameters=None,
                         compression=Compression.none,
                         backward_passes_per_step=1,
                         op=Average,
                         gradient_predivide_factor=1.0,
                         num_groups=0, groups=None,
                         sparse_as_dense=False,
                         process_set=global_process_set):
    if op != Adasum or size() == 1:
        cls = type(optimizer.__class__.__name__, (optimizer.__class__,),
                   dict(_DistributedOptimizer.__dict__))
        return cls(optimizer.param_groups, named_parameters, compression, backward_passes_per_step, op,
                   gradient_predivide_factor, groups, sparse_as_dense, process_set)
    else:
        cls = type(optimizer.__class__.__name__, (optimizer.__class__,),
                   dict(_DistributedAdasumOptimizer.__dict__))
        return cls(optimizer.param_groups, named_parameters, compression, backward_passes_per_step)
</code></pre>
<p><a href="https://arxiv.org/abs/2006.02924">Adasum</a> 是 allreduce 时一种计算合并 gradient 的方法，可以让结果更加稳定。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="tensorflow"><a class="header" href="#tensorflow">Tensorflow</a></h1>
<h3 id="demo-4"><a class="header" href="#demo-4">Demo</a></h3>
<pre><code class="language-python">    import tensorflow as tf
    import horovod.tensorflow as hvd


    # Initialize Horovod
    hvd.init()

    # Pin GPU to be used to process local rank (one GPU per process)
    config = tf.ConfigProto()
    config.gpu_options.visible_device_list = str(hvd.local_rank())

    # Build model...
    loss = ...
    opt = tf.train.AdagradOptimizer(0.01 * hvd.size())

    # Add Horovod Distributed Optimizer
    opt = hvd.DistributedOptimizer(opt)

    # Add hook to broadcast variables from rank 0 to all other processes during
    # initialization.
    hooks = [hvd.BroadcastGlobalVariablesHook(0)]

    # Make training operation
    train_op = opt.minimize(loss)

    # Save checkpoints only on worker 0 to prevent other workers from corrupting them.
    checkpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None

    # The MonitoredTrainingSession takes care of session initialization,
    # restoring from a checkpoint, saving to a checkpoint, and closing when done
    # or an error occurs.
    with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,
                                           config=config,
                                           hooks=hooks) as mon_sess:
      while not mon_sess.should_stop():
        # Perform synchronous training.
        mon_sess.run(train_op)

</code></pre>
<pre><code class="language-python"># horovod/tensorflow/mpi_ops.py 

def init(*args, **kwargs):
    _basics.init(*args, **kwargs)
    _setup_process_sets(_basics)

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="elastic"><a class="header" href="#elastic">Elastic</a></h1>
<h2 id="弹性启动"><a class="header" href="#弹性启动">弹性启动</a></h2>
<p>前述接正常启动部分，弹性使用 gloo 启动</p>
<pre><code class="language-python">def _run_elastic(args):
    settings = elastic_settings.ElasticSettings(discovery=discover_hosts,...)
    return gloo_run_elastic(settings, env, args.run_func if args.run_func else args.command, executable)

from horovod.runner.gloo_run import gloo_run, gloo_run_elastic
</code></pre>
<pre><code class="language-python"># horovod/runner/gloo_run.py

def gloo_run_elastic(settings, env, command_or_func, executable) -&gt; Optional[Any]:
    rendezvous = RendezvousServer(settings.verbose)
    return launch_gloo_elastic(command_or_func, exec_command, settings, env, get_common_interfaces, rendezvous, executable)

def launch_gloo_elastic(command_or_func, exec_command, settings, env, get_common_interfaces, rendezvous, executable):
    driver = ElasticDriver(rendezvous, settings.discovery,
                           settings.min_num_proc, settings.max_num_proc,
                           timeout=settings.elastic_timeout,
                           reset_limit=settings.reset_limit,
                           cooldown_range=settings.cooldown_range,
                           verbose=settings.verbose)

    handler = create_rendezvous_handler(driver)
    global_rendezv_port = rendezvous.start(handler)
    driver.wait_for_available_slots(settings.num_proc)

    run_command = get_run_command(command, server_ip, nics, global_rendezv_port, elastic=True)
    create_worker = _create_elastic_worker_fn(exec_command, run_command, env, event)

    driver.start(settings.num_proc, create_worker)
    res = driver.get_results()
    driver.stop()

</code></pre>
<h3 id="driver"><a class="header" href="#driver">Driver</a></h3>
<p>ElasticDriver 中有两个线程</p>
<ul>
<li>一个线程 while 循环执行 <code>_discover_hosts</code> 监控、报告节点更新</li>
<li>一个线程执行 <code>run_worker</code> 启动 worker</li>
</ul>
<p>注意 driver 不会阻塞，启动 worker 后返回 launch 函数，等待获取 results, 具体地，<code>driver.get_results()</code> 是一个 while 循环会造成阻塞。</p>
<pre><code class="language-python"># horovod/runner/elastic/driver.py 

class ElasticDriver(object):
    def __init__(self, rendezvous, ...):
        self._worker_registry = WorkerStateRegistry(self, self._host_manager, reset_limit=reset_limit)
        self._results = ResultsRecorder()
        self._discovery_thread = threading.Thread(target=self._discover_hosts)

    def start(self, num_proc, create_worker_fn):
        self._activate_workers(num_proc)

    def get_results(self):
        return self._results.get_results()

    def register_worker_server(self, host, slot, addresses, secret_key):
        self._worker_clients[(host, slot)] = WorkerNotificationClient(
            addresses, secret_key, self._verbose)

    def _activate_workers(self, min_num_proc):
        current_hosts = self.wait_for_available_slots(min_num_proc)
        pending_slots = self._update_host_assignments(current_hosts)
        self._worker_registry.reset(self.world_size())
        self._start_worker_processes(pending_slots)

    def _discover_hosts(self):
        while not self._shutdown.is_set():
            self._wait_hosts_cond.acquire()
            try:
                update_res = self._host_manager.update_available_hosts()
                if update_res != HostUpdateResult.no_update:
                    self._notify_workers_host_changes(self._host_manager.current_hosts, update_res)
                    self._wait_hosts_cond.notify_all()
            finally:
                self._wait_hosts_cond.release()
            self._shutdown.wait(DISCOVER_HOSTS_FREQUENCY_SECS)

    def _notify_workers_host_changes(self, current_hosts, update_res):
        coordinator_client.notify_hosts_updated(timestamp, update_res)

    def _start_worker_processes(self, pending_slots):
        for slot_info in pending_slots:
            self._start_worker_process(slot_info)

    def _start_worker_process(self, slot_info):
        def run_worker():
            res = create_worker_fn(slot_info, [shutdown_event, host_event])
            exit_code, timestamp = res
            self._handle_worker_exit(slot_info, exit_code, timestamp)

        thread = threading.Thread(target=run_worker)
        thread.daemon = True
        thread.start()
        self._results.expect(thread)

</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<pre><code class="language-python">hvd.init()

torch.cuda.set_device(hvd.local_rank())

dataset = ...
model = ...

optimizer = optim.SGD(model.parameters(), lr * hvd.size())
optimizer = hvd.DistributedOptimizer(optimizer)

@hvd.elastic.run
def train(state):
    batch_offset = state.batch
    for state.epoch in range(state.epoch, epochs):
        for state.batch in range(state.batch, batches_per_epoch):
            data, target = get_random_batch()

            optimizer.zero_grad()
            output = model(data)
            loss = F.nll_loss(output, target)
            loss.backward()
            optimizer.step()

            if state.batch % batches_per_commit == 0:
                state.commit()
        state.batch = 0

def on_state_reset():
    # adjust learning rate on reset
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr * hvd.size()

state = hvd.elastic.TorchState(model, optimizer, batch=0, epoch=0)
state.register_reset_callbacks([on_state_reset])
train(state)
</code></pre>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>在训练的循环函数上会有装饰器，用于识别错误和自身的恢复，另外通过 <code>notification_manager</code> 别的节点也会感知到错误的发生。</p>
<pre><code class="language-python"># horovod/common/elastic.py

notification_manager = WorkerNotificationManager()

def run_fn(func, reset):
    @functools.wraps(func)
    def wrapper(state, *args, **kwargs):
        notification_manager.init()
        notification_manager.register_listener(state)

        try:
            while True:
                try:
                    if not skip_sync:
                        state.sync()

                    return func(state, *args, **kwargs)
                except HorovodInternalError:
                    state.restore()
                    skip_sync = False
                except HostsUpdatedInterrupt as e:
                    skip_sync = e.skip_sync

                reset()
                state.on_reset()
    return wrapper
</code></pre>
<pre><code class="language-python"># horovod/common/elastic.py

class State(object):
    def register_reset_callbacks(self, callbacks):
        pass

    def on_reset(self):
        self._host_messages = queue.Queue()
        self.reset()
        for callback in self._reset_callbacks:
            callback()

    def on_hosts_updated(self, timestamp, update_res):
        self._host_messages.put((timestamp, update_res))

    def commit(self):
        self.save()
        self.check_host_updates()

    def check_host_updates(self):
        raise HostsUpdatedInterrupt(all_update == HostUpdateResult.removed)

    def save(self):
        pass

    def restore(self):
        pass

    def sync(self):
        pass

    def reset(self):
        pass

class ObjectState(State):
    def restore(self):
        self._set_attrs()

    def sync(self):
        if self._saved_state:
            self._saved_state = self._bcast_object(self._saved_state)
            self._set_attrs()


# horovod/torch/elastic/state.py

class TorchState(ObjectState):
    def restore(self):
        for handler in self._handlers.values():
            handler.restore()
        super(TorchState, self).restore()
</code></pre>
<p>因为 <code>hvd.init()</code> 之后，一直会有后台进程在负责真正的通信过程，在有节点变化时，通信组需要重建，具体实现如下。</p>
<pre><code class="language-cpp">// horovod/common/operations.cc

bool RunLoopOnce(HorovodGlobalState&amp; state) {
  if (state.dynamic_process_sets) {
    // Initialize any newly added process set that has been registered by all
    // Horovod processes and remove a process set that has been marked for
    // removal by all Horovod processes.
    if (state.control_operation == LibType::GLOO) {
      state.process_set_table.InitializeRegisteredAndRemoveMarkedIfReady(
          global_gloo_context);
    }
  }

}
</code></pre>
<p>Reinitialize Horovod context performing a new round of rendezvous.</p>
<p>负责重建通信域</p>
<pre><code class="language-cpp">// horovod/common/process_set.cc

template &lt;class Context&gt;
int32_t ProcessSetTable::InitializeRegisteredAndRemoveMarkedIfReady_(
    const Context&amp; global_context, const Status&amp; removal_status) {

  if (registered_count_agreement) {
    for (auto id : Ids()) {
      bool newly_registered = Get(id).Initialize(global_context);
    }
  }

  if (id_to_be_removed_agreement) {
      id_to_process_set_[id_to_be_removed_].Finalize(removal_status);
      DeregisterProcessSet(id_to_be_removed_);
  }
}

ProcessSetTable::ProcessSetTable() {
  auto process_set_id = RegisterProcessSet();
}

int32_t ProcessSetTable::RegisterProcessSet(std::vector&lt;int&gt; global_ranks) {
  // ProcessSet
  ids_.push_back(id);
}

bool ProcessSet::Initialize(const GlooContext&amp; global_gloo_context) {
  gloo_context.InitializeForProcessSet(global_gloo_context,
                                       registered_global_ranks);
}
</code></pre>
<pre><code class="language-cpp">// horovod/common/gloo/gloo_context.cc

void GlooContext::InitializeForProcessSet(const GlooContext&amp; global_context,
                                          const std::vector&lt;int&gt;&amp; registered_ranks) {
  ctx = Rendezvous(HOROVOD_GLOO_GLOBAL_PREFIX + process_set_suffix,
                   rendezvous_addr_env, rendezvous_port, rank, size, dev,
                   timeout_);
}
</code></pre>
<p>接口的调用顺序 </p>
<pre><code class="language-python"># horovod/common/process_sets.py

def add_process_set(process_set: Union[ProcessSet, Sequence[int]]) -&gt; ProcessSet:
    process_set_id = _basics._add_process_set_impl(process_set.ranks)
</code></pre>
<pre><code class="language-python"># horovod/common/basics.py

class HorovodBasics(object):
    def _add_process_set_impl(self, ranks: Sequence[int]) -&gt; Optional[int]:
        result = int(self.MPI_LIB_CTYPES.horovod_add_process_set(
            (ctypes.c_int * nrank)(*ranks), ctypes.c_int(nrank)))
</code></pre>
<pre><code class="language-cpp">// horovod/common/operations.cc

int horovod_add_process_set(const int* ranks, int nrank) {
  ProcessSet* process_set = nullptr;
  {
    process_set = &amp;GetProcessSetOrAddUnitialized(
        ranks &amp;&amp; nrank &gt; 0 ? std::vector&lt;int&gt;(ranks, ranks + nrank) : std::vector&lt;int&gt;(),
        id);
  }
}

ProcessSet&amp; GetProcessSetOrAddUnitialized(std::vector&lt;int&gt; ranks, int&amp; id) {
  id = horovod_global.process_set_table.FindId(ranks);
  id = horovod_global.process_set_table.RegisterProcessSet(std::move(ranks));
  auto&amp; process_set = horovod_global.process_set_table.Get(id);
  EnrichProcessSetWithGlooController(process_set);
}

void EnrichProcessSetWithGlooController(ProcessSet&amp; process_set) {
  process_set.controller.reset(new GlooController(
      process_set.response_cache, process_set.tensor_queue,
      horovod_global.timeline, horovod_global.parameter_manager,
      process_set.group_table, horovod_global.timeline_controller,
      process_set.gloo_context));
}
</code></pre>
<h3 id="workflow-summary"><a class="header" href="#workflow-summary">Workflow Summary</a></h3>
<ul>
<li><code>hvd.elastic.run</code> decorator </li>
<li>process <code>HorovodInternalError</code> </li>
<li>reinitialize context, new rendezvous</li>
<li>restore state, broadcasting from new worker-0</li>
</ul>
<h3 id="reference-4"><a class="header" href="#reference-4">Reference</a></h3>
<ul>
<li>https://horovod.readthedocs.io/en/stable/elastic_include.html</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="ray"><a class="header" href="#ray">Ray</a></h1>
<h2 id="reference-5"><a class="header" href="#reference-5">Reference</a></h2>
<ul>
<li><a href="https://github.com/ray-project/ray">Ray Github</a></li>
<li><a href="https://docs.ray.io/en/latest/">Ray Documentation</a></li>
<li><a href="https://rise.cs.berkeley.edu/blog/ray-tips-for-first-time-users/">Ray Tips</a></li>
<li><a href="https://docs.google.com/document/d/1lAy0Owi-vPz2jEqBSaHNQcy2IBSDEHyXNOQZlGuj93c/preview#">Ray 1.x Architecture - Google 文档</a></li>
</ul>
<p>源代码和官方文档永远是最好的学习资料，总结和学习笔记能辅助快速理解，抓住重点，提高效率。</p>
<div class="table-wrapper"><table><thead><tr><th><strong>API</strong></th><th><strong>Description</strong></th><th><strong>Example</strong></th></tr></thead><tbody>
<tr><td>ray.init()</td><td>Initialize Ray context.</td><td></td></tr>
<tr><td>@ray.remote</td><td>Function or class decorator specifying that the function will be executed as a task or the class as an actor in a different process.</td><td>@ray.remote @ray.remote <br> def fun(x):           class Actor(object):<br> …                            def method(y)<br> …</td></tr>
<tr><td>.remote</td><td>Postfix to every remote function, remote class declaration, or invocation of a remote class method. Remote operations are <em>asynchronous</em>.</td><td>ret_id = fun.remote(x)<br>a = Actor.remote()<br>ret_id = a.method.remote(y)</td></tr>
<tr><td>ray.put()</td><td>Store object in object store, and return its ID. This ID can be used to pass object as an argument to any remote function or method call. This is a <em>synchronous</em> operation.</td><td>x_id = ray.put(x)</td></tr>
<tr><td>ray.get()</td><td>Return an object or list of objects from the object ID or list of object IDs. This is a <em>synchronous</em> (i.e., blocking) operation.</td><td>x = ray.get(x_id)<br>…<br>objects = ray.get(object_ids)</td></tr>
<tr><td>ray.wait()</td><td>From a list of object IDs returns (1) the list of IDs of the objects that are ready, and (2) the list of IDs of the objects that are not ready yet. By default it returns one ready object ID at a time.</td><td>ready_ids, not_ready_ids =  ray.wait(object_ids)</td></tr>
</tbody></table>
</div>
<p>特点</p>
<ul>
<li>分布式异步调用</li>
<li>内存调度</li>
<li>Pandas/Numpy 的分布式支持</li>
<li>支持 Python</li>
<li>整体性能出众</li>
</ul>
<p>Ray (pickle5 + cloudpickle)</p>
<p><a href="https://github.com/ray-project/plasma">GitHub - ray-project/plasma: A minimal shared memory object store design</a></p>
<p><a href="https://github.com/cloudpipe/cloudpickle">GitHub - cloudpipe/cloudpickle: Extended pickling support for Python objects</a></p>
<ul>
<li>Plasma is an in-memory object store that is being developed as part of Apache Arrow</li>
<li>Ray uses Plasma to efficiently transfer objects across different processes and <em>different nodes</em></li>
</ul>
<h4 id="actor"><a class="header" href="#actor">Actor</a></h4>
<ul>
<li>An actor is essentially a stateful worker(or a service)</li>
<li>A new actor is instantiated, a new worker is created</li>
<li>When an actor contains async methods, the actor will be converted to async actors. This means all the ray’s tasks will run as a coroutine.</li>
</ul>
<pre><code class="language-python">## 1
@ray.remote
class Counter(object):
    def __init__(self):
        self.value = 0
Counter = ray.remote(Counter)

## 1
class Counter(object):
    def __init__(self):
        self.value = 0

## then
counter_actor = Counter.remote()
</code></pre>
<h4 id="actor-vs-worker"><a class="header" href="#actor-vs-worker">Actor vs Worker</a></h4>
<p>Actor: a worker instantiated at runtime</p>
<p>Worker: python process, execute multiple tasks or actor (dedicated)</p>
<h4 id="fault-tolerance"><a class="header" href="#fault-tolerance">Fault Tolerance</a></h4>
<ul>
<li>task retry</li>
<li>actor retry</li>
<li>object retrieve or reconstruction</li>
</ul>
<h4 id="airflow"><a class="header" href="#airflow">Airflow</a></h4>
<p>Airflow can be act as job manager in Ray</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="overview-1"><a class="header" href="#overview-1">Overview</a></h1>
<h2 id="build"><a class="header" href="#build">BUILD</a></h2>
<p>Ray 的编译使用 bazel，其中大量的 proto 编译也依赖于此，
具体定义在 <code>src/ray/protobuf/BUILD</code> 文件中，参考 <a href="https://rules-proto-grpc.com/en/latest/example.html">文档</a>.</p>
<h2 id="启动部署"><a class="header" href="#启动部署">启动部署</a></h2>
<p>安装完成后，可以直接运行的相关命令如下</p>
<pre><code class="language-python"># python/setup.py

entry_points={
    &quot;console_scripts&quot;: [
        &quot;ray=ray.scripts.scripts:main&quot;,
        &quot;rllib=ray.rllib.scripts:cli [rllib]&quot;,
        &quot;tune=ray.tune.scripts:cli&quot;,
        &quot;ray-operator=ray.ray_operator.operator:main&quot;,
        &quot;serve=ray.serve.scripts:cli&quot;,
    ]
}
</code></pre>
<p>常驻模式启动 ray 集群</p>
<pre><code class="language-shell"># 启动 head 节点
ray start --head
# 启动 worker 节点
ray start --address=RAY_HEAD_IP:6379

ray start --head --redis-password=&quot;&quot; --port=6389
</code></pre>
<p>start 命令的解析如下</p>
<pre><code class="language-python"># python/ray/scripts/scripts.py

# args 解析用的是 click

@cli.command()
@click.option(&quot;--head&quot;,...)
def start(...,head,...):
    ray_params = ray._private.parameter.RayParams(...)
    if head:
        # 启动 head 节点
        ray_params.update_if_absent(...)
        node = ray.node.Node(ray_params, head=True,...)
    else:
        # 启动 worker 节点
        bootstrap_address = services.canonicalize_bootstrap_address(address)
        ray_params.gcs_address = bootstrap_address
        node = ray.node.Node(ray_params, head=False,...)

cli.add_command(start)
def main():
    return cli()
</code></pre>
<p>可以看出本质上都是初始化了节点 Node 对象，是否为 head 则通过参数指定。</p>
<h3 id="node-1"><a class="header" href="#node-1">Node</a></h3>
<p>Node 节点的初始化</p>
<pre><code class="language-python"># python/ray/node.py

class Node:
    def __init__(self, ray_params, head=False,...):
        self.head = head

        if not head:
            # GCS GRPC client, 确保 gcs 已启动
            self.get_gcs_client()

        # 初始化持久化存储
        storage._init_storage(ray_params.storage, is_head=head) 

        if head:
            self.validate_external_storage()

        if ...:
            # 启动 reaper 进程，负责在主进程意外退出后回收进程
            self.start_reaper_process()

        if head:
            self.start_head_processes()
            # 尝试写入 gcs
            self.get_gcs_client().internal_kv_put(...)

        if not connect_only:
            self.start_ray_processes()
            ray._private.services.wait_for_node(...)
</code></pre>
<p>Node 的初始化包括启动 start_head_processes 和 start_ray_processes 两部分。</p>
<pre><code class="language-python"># python/ray/node.py

class Node:
    def start_head_processes(self):
        # 如果使用外部 redis，需要配置
        # 这里的逻辑目前有点 confuse，external 和 local 不够明确
        if self._ray_params.external_addresses is not None:
            self.start_or_configure_redis()
            self.create_redis_client()

        # 启动 gcs，包含 redis 服务, 默认端口 6379
        self.start_gcs_server()

        self.start_ray_client_server()

    def start_or_configure_redis(self):
        # 如果 external 有配置，并不真正启动
        ray._private.services.start_redis(...)

    def start_gcs_server(self):
        process_info = ray._private.services.start_gcs_server(self.redis_address,...)
        # 等待启动
        self.get_gcs_client()

    def start_ray_client_server(self):
        process_info = ray._private.services.start_ray_client_server(self.address, self._node_ip_address, ...)

    def start_ray_processes(self):
        # 启动节点上所有的进程
        self.destroy_external_storage()
        # 启动 raylet
        self.start_raylet(plasma_directory, object_store_memory)

    def start_raylet(self, ...):
        process_info = ray._private.services.start_raylet(
            self.redis_address,
            self.gcs_address,
            self._node_ip_address,
            ...)

</code></pre>
<ul>
<li>Head 节点启动 gcs 服务和 ray_client 服务</li>
<li>Head 和 Worker 节点都启动 raylet 服务</li>
</ul>
<p>这些服务的具体启动都被封装在 services 里。</p>
<h3 id="services"><a class="header" href="#services">Services</a></h3>
<p>Services 提供多种服务启动的封装，包括 redis 服务启动。</p>
<blockquote>
<p>1.11 之前的版本 ray 通过启动 redis-server 二进制启动 redis，新版本中已经移除。</p>
</blockquote>
<pre><code class="language-python"># python/ray/_private/services.py

def start_gcs_server(redis_address, ...):
    # 调用 gcs 二进制启动服务，包含 redis 服务
    # GCS_SERVER_EXECUTABLE &quot;core/src/ray/gcs/gcs_server&quot;
    command = [GCS_SERVER_EXECUTABLE, &quot;--redis_xxxx=&quot;, ...]
    process_info = start_ray_process(command, ...)

def start_ray_client_server(address, ray_client_server_ip,...):
    command = [
        sys.executable,    # python
        setup_worker_path, # ray/workers/setup_worker.py
        &quot;-m&quot;,
        &quot;ray.util.client.server&quot;,
        ...]
    process_info = start_ray_process(command, ...)

def start_raylet(redis_address, gcs_address, ...):
    # 启动 raylet，包括 local scheduler 和 object manager
    # 支持 python、java 和 cpp
    # RAYLET_EXECUTABLE &quot;core/src/ray/raylet/raylet&quot;
    command = [
        RAYLET_EXECUTABLE,
        f&quot;--python_worker_command={subprocess.list2cmdline(start_worker_command)}&quot;,  # noqa
        f&quot;--java_worker_command={subprocess.list2cmdline(java_worker_command)}&quot;,  # noqa
        f&quot;--cpp_worker_command={subprocess.list2cmdline(cpp_worker_command)}&quot;,  # noqa
        ...]
    command.append(&quot;--agent_command={}&quot;.format(subprocess.list2cmdline(agent_command)))
    process_info = start_ray_process(command, ...)

def start_ray_process(command, ...):
    process = ConsolePopen(
        command,
        env=modified_env,
        cwd=cwd,
        stdout=stdout_file,
        stderr=stderr_file,
        stdin=subprocess.PIPE if pipe_stdin else None,
        preexec_fn=preexec_fn if sys.platform != &quot;win32&quot; else None,
        creationflags=CREATE_SUSPENDED if win32_fate_sharing else 0,
    )

class ConsolePopen(subprocess.Popen):
    pass

</code></pre>
<h3 id="setup-worker--runtime-env-context"><a class="header" href="#setup-worker--runtime-env-context">setup worker &amp; runtime env context</a></h3>
<p>setup worker 的作用是执行不同的程序，</p>
<pre><code class="language-python"># ray/workers/setup_worker.py

parser.add_argument(&quot;--serialized-runtime-env-context&quot;,...)
parser.add_argument(&quot;--language&quot;, ...)

if __name__ == &quot;__main__&quot;:
    args, remaining_args = parser.parse_known_args()
    runtime_env_context = RuntimeEnvContext.deserialize(
        args.serialized_runtime_env_context or &quot;{}&quot;
    )
    runtime_env_context.exec_worker(remaining_args, Language.Value(args.language))
</code></pre>
<pre><code class="language-python"># python/ray/_private/runtime_env/context.py

class RuntimeEnvContext:
    def exec_worker(self, passthrough_args: List[str], language: Language):
        os.environ.update(self.env_vars)

        # exec [python] passthrough_args
        command_str = &quot; &amp;&amp; &quot;.join(...)

        if sys.platform == &quot;win32&quot;:
            os.system(command_str)
        else:
            os.execvp(&quot;bash&quot;, args=[&quot;bash&quot;, &quot;-c&quot;, command_str])
</code></pre>
<h3 id="client-server"><a class="header" href="#client-server">client server</a></h3>
<pre><code class="language-bash">python -m ray.util.client.server --address=x.x.x.x:6379 --host=0.0.0.0 --port=10001 --mode=proxy --redis-password=
</code></pre>
<pre><code class="language-python"># python/ray/util/client/server/__main__.py
# -&gt; server.py main
# python/ray/util/client/server/server.py

def main():
    server = serve(hostport, ray_connect_handler)
    while True:
        ray.experimental.internal_kv._internal_kv_put(..., HEALTHCHECK)

def serve(connection_str, ray_connect_handler=None):
    server = grpc.server(
        futures.ThreadPoolExecutor(
            max_workers=CLIENT_SERVER_MAX_THREADS,
            thread_name_prefix=&quot;ray_client_server&quot;,
        ),
    )
    # mode proxy
    task_servicer = RayletServicerProxy(None, proxy_manager)
    data_servicer = DataServicerProxy(proxy_manager)
    logs_servicer = LogstreamServicerProxy(proxy_manager)
    # else
    task_servicer = RayletServicer(ray_connect_handler)
    data_servicer = DataServicer(task_servicer)
    logs_servicer = LogstreamServicer()
    ray_client_pb2_grpc.add_RayletDriverServicer_to_server(task_servicer, server)
    ray_client_pb2_grpc.add_RayletDataStreamerServicer_to_server(data_servicer, server)
    ray_client_pb2_grpc.add_RayletLogStreamerServicer_to_server(logs_servicer, server)
    server.start()
</code></pre>
<pre><code class="language-python"># python/ray/util/client/server/server.py

# class RayletServicerProxy(ray_client_pb2_grpc.RayletDriverServicer):
class RayletServicer(ray_client_pb2_grpc.RayletDriverServicer):
    def KVPut(self, request, context=None) -&gt; ray_client_pb2.KVPutResponse:
    def KVGet(self, request, context=None) -&gt; ray_client_pb2.KVGetResponse:
    def KVDel(self, request, context=None) -&gt; ray_client_pb2.KVDelResponse:
    def KVList(self, request, context=None) -&gt; ray_client_pb2.KVListResponse:
    def ListNamedActors(...):
    def ClusterInfo(self, request, context=None) -&gt; ray_client_pb2.ClusterInfoResponse:
    def release(self, client_id: str, id: bytes) -&gt; bool:
    def release_all(self, client_id):
    def Terminate(self, req, context=None):
    def GetObject(self, request: ray_client_pb2.GetRequest, context):
    def PutObject( self, request: ray_client_pb2.PutRequest, context=None) -&gt; ray_client_pb2.PutResponse:
    def WaitObject(self, request, context=None) -&gt; ray_client_pb2.WaitResponse:
    def Schedule( self, task: ray_client_pb2.ClientTask, context=None) -&gt; ray_client_pb2.ClientTaskTicket:
    def lookup_or_register_func( self, id: bytes, client_id: str, options: Optional[Dict]) -&gt; ray.remote_function.RemoteFunction:
    def lookup_or_register_actor( self, id: bytes, client_id: str, options: Optional[Dict]):
    def unify_and_track_outputs(self, output, client_id):
</code></pre>
<h3 id="总结-1"><a class="header" href="#总结-1">总结</a></h3>
<p><code>ray start [--head]</code>, 将启动以下进程</p>
<pre><code class="language-shell"># 以下进程只在 head 节点运行
# GCS_SERVER_EXECUTABLE 
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/gcs/gcs_server 
/usr/bin/python3.7 -m ray.util.client.server --host=0.0.0.0 --port=10001 --mode=proxy

# worker 进程
# RAYLET_EXECUTABLE
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/raylet/raylet
/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/dashboard/agent.py

/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/monitor.py
/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/dashboard/dashboard.py
/usr/bin/python3.7 -u /usr/local/lib/python3.7/dist-packages/ray/_private/log_monitor.py
</code></pre>
<pre><code class="language-shell"># 新版本中的以下进程已被移除
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/thirdparty/redis/src/redis-server *:6379
/usr/local/lib/python3.7/dist-packages/ray/core/src/ray/thirdparty/redis/src/redis-server *:64712
</code></pre>
<pre><code class="language-shell"># java worker command
python ray/workers/setup_worker.py java -Dx=x -cp xx RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker

#  cpp worker command
cpp/default_worker
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="gcs-server"><a class="header" href="#gcs-server">GCS Server</a></h1>
<p>服务由以下二进制启动</p>
<pre><code class="language-shell">&quot;core/src/ray/gcs/gcs_server&quot;
</code></pre>
<p>程序入口</p>
<pre><code class="language-cpp">// src/ray/gcs/gcs_server/gcs_server_main.cc

int main(int argc, char *argv[]) {
  // 初始化配置
  RayConfig::instance().initialize(config_list);
  // 启动 IO service
  // class instrumented_io_context : public boost::asio::io_context {...}
  instrumented_io_context main_service;
  boost::asio::io_service::work work(main_service);
  // 初始化状态模块
  ray::stats::Init(global_tags, metrics_agent_port);

  // 启动 grpc 服务
  ray::gcs::GcsServerConfig gcs_server_config;
  gcs_server_config.grpc_server_name = &quot;GcsServer&quot;;
  ray::gcs::GcsServer gcs_server(gcs_server_config, main_service);
  gcs_server.Start();

  main_service.run();
}
</code></pre>
<p>主服务</p>
<pre><code class="language-cpp">// src/ray/gcs/gcs_server/gcs_server.cc

// 服务初始化，根据配置使用外置 redis 存储或者内置存储
GcsServer::GcsServer(...) {
  if (storage_type_ == &quot;redis&quot;) {
    gcs_table_storage_ = std::make_shared&lt;gcs::RedisGcsTableStorage&gt;(GetOrConnectRedis());
  } else if (storage_type_ == &quot;memory&quot;) {
    gcs_table_storage_ = std::make_shared&lt;InMemoryGcsTableStorage&gt;(main_service_);
  }
}

void GcsServer::Start() {
  // 异步加载 gcs tables 数据
  auto gcs_init_data = std::make_shared&lt;GcsInitData&gt;(gcs_table_storage_);
  gcs_init_data-&gt;AsyncLoad([this, gcs_init_data] { DoStart(*gcs_init_data); });
}

void GcsServer::DoStart(const GcsInitData &amp;gcs_init_data) {
  // Init cluster resource scheduler.
  // Init gcs resource manager.
  // Init synchronization service
  // Init gcs node manager.
  // Init gcs heartbeat manager.
  // Init KV Manager
  // Init function manager
  // Init Pub/Sub handler
  // Init RuntimeENv manager
  // Init gcs job manager.
  // Init gcs placement group manager.
  // Init gcs actor manager.
  // Init gcs worker manager.
  // Init stats handler.
  // Install event listeners.

  // 启动 rpc 服务，依赖 tables 数据加载完成
  // rpc::GrpcServer rpc_server_;
  rpc_server_.Run();
  // 心跳服务
  gcs_heartbeat_manager_-&gt;Start();

  RecordMetrics();
}
</code></pre>
<p>Table storage</p>
<pre><code class="language-cpp">// src/ray/gcs/gcs_server/gcs_table_storage.h

class GcsTable {}

class GcsTableWithJobId : public GcsTable&lt;Key, Data&gt; {}

class GcsTableStorage {};

class RedisGcsTableStorage : public GcsTableStorage {};

class InMemoryGcsTableStorage : public GcsTableStorage {};
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="raylet"><a class="header" href="#raylet">Raylet</a></h1>
<p>服务由以下二进制启动</p>
<pre><code class="language-shell">core/src/ray/raylet/raylet
</code></pre>
<p>程序入口</p>
<pre><code class="language-cpp">// src/ray/raylet/main.cc

int main(int argc, char *argv[]) {

  // 启动 IO service
  // class instrumented_io_context : public boost::asio::io_context {...}
  instrumented_io_context main_service;
  boost::asio::io_service::work main_work(main_service);

  std::unique_ptr&lt;ray::raylet::Raylet&gt; raylet;
  ray::raylet::NodeManagerConfig node_manager_config;
  ray::ObjectManagerConfig object_manager_config;
  raylet = std::make_unique&lt;ray::raylet::Raylet&gt;(main_service,
                                                 raylet_socket_name,
                                                 node_ip_address,
                                                 node_manager_config,
                                                 object_manager_config,
                                                 gcs_client,
                                                 metrics_export_port);
  raylet-&gt;Start();
  main_service.run();
}

</code></pre>
<p>主服务类</p>
<pre><code class="language-cpp">// src/ray/raylet/raylet.cc

class Raylet {
  // 用于和 gcs 连接的客户端
  std::shared_ptr&lt;gcs::GcsClient&gt; gcs_client_;
  NodeManager node_manager_;
}

void Raylet::Start() {
  RAY_CHECK_OK(RegisterGcs());

  // Start listening for clients.
  DoAccept();
}

ray::Status Raylet::RegisterGcs() {
  node_manager_.RegisterGcs();

  gcs_client_-&gt;Nodes().RegisterSelf(self_node_info_, register_callback);
}

void Raylet::DoAccept() {
  acceptor_.async_accept(
      socket_,
      boost::bind(&amp;Raylet::HandleAccept, this, boost::asio::placeholders::error));
}

void Raylet::HandleAccept(const boost::system::error_code &amp;error) {
  // 建立本地连接并分发到 node manager 处理
  auto new_connection = ClientConnection::Create(
      client_handler, // node_manager_.ProcessNewClient(client);
      message_handler, // node_manager_.ProcessClientMessage(client, message_type, message.data());
      std::move(socket_),
      &quot;worker&quot;,
      node_manager_message_enum,
      static_cast&lt;int64_t&gt;(protocol::MessageType::DisconnectClient),
      message_data);
  // 处理连接
  DoAccept();
}
</code></pre>
<p>Node Manager</p>
<p>NodeManager 本身是一个 ServiceHandler，所以在初始化 node_manager_service_ 时，使用 this 作为 handler 传递。</p>
<pre><code class="language-cpp">// src/ray/raylet/node_manager.h

class NodeManager : public rpc::NodeManagerServiceHandler {
  std::shared_ptr&lt;gcs::GcsClient&gt; gcs_client_;
  std::unique_ptr&lt;HeartbeatSender&gt; heartbeat_sender_;
  WorkerPool worker_pool_;
  ObjectManager object_manager_;
  rpc::GrpcServer node_manager_server_;
  rpc::NodeManagerGrpcService node_manager_service_;

  std::unique_ptr&lt;rpc::AgentManagerServiceHandler&gt; agent_manager_service_handler_;
  rpc::AgentManagerGrpcService agent_manager_service_;

  std::shared_ptr&lt;ClusterResourceScheduler&gt; cluster_resource_scheduler_;
  std::shared_ptr&lt;LocalTaskManager&gt; local_task_manager_;

  std::shared_ptr&lt;PlacementGroupResourceManager&gt; placement_group_resource_manager_;
}

// src/ray/raylet/node_manager.cc

// Push
// Pull

NodeManager::NodeManager(...) {
  // 非常多的初始化配置
  node_manager_service_(io_service, *this),
  // 然后注册服务并启动
  node_manager_server_.RegisterService(node_manager_service_);
  node_manager_server_.RegisterService(agent_manager_service_);
  node_manager_server_.Run();
}
</code></pre>
<p>NodeManager 的 rpc 接口</p>
<pre><code class="language-cpp">// src/ray/rpc/node_manager/node_manager_server.h

// `NodeManagerService` 的接口, 对应 `src/ray/protobuf/node_manager.proto`.
class NodeManagerServiceHandler {}
// 目前有以下接口
// UpdateResourceUsage
// RequestResourceReport
// RequestWorkerLease
// ReportWorkerBacklog
// ReturnWorker
// ReleaseUnusedWorkers
// CancelWorkerLease
// PinObjectIDs
// GetNodeStats
// GlobalGC
// FormatGlobalMemoryInfo
// PrepareBundleResources
// CommitBundleResources
// CancelResourceReserve
// RequestObjectSpillage
// ReleaseUnusedBundles
// GetSystemConfig
// GetGcsServerAddress
// ShutdownRaylet

class NodeManagerGrpcService : public GrpcService {
  NodeManagerGrpcService(instrumented_io_context &amp;io_service,
                         NodeManagerServiceHandler &amp;service_handler)
}
</code></pre>
<blockquote>
<p>关于怎么增加新的接口可以参考: <code>src/ray/core_worker/core_worker.h</code>.</p>
</blockquote>
<p>ObjectManager </p>
<pre><code class="language-cpp">// src/ray/object_manager/object_manager.h

class ObjectManager : public ObjectManagerInterface, public rpc::ObjectManagerServiceHandler {
  instrumented_io_context rpc_service_;
  boost::asio::io_service::work rpc_work_;

  rpc::GrpcServer object_manager_server_;
  rpc::ObjectManagerGrpcService object_manager_service_;
}

// 主要接口
// Push
// Pull

// src/ray/object_manager/object_manager.cc

ObjectManager::ObjectManager(...){
  rpc_work_(rpc_service_),
  object_manager_server_(&quot;ObjectManager&quot;,...)
  object_manager_service_(rpc_service_, *this),
  StartRpcService();
}

void ObjectManager::StartRpcService() {
  // for i in config_.rpc_service_threads_number
  rpc_threads_[i] = std::thread(&amp;ObjectManager::RunRpcService, this, i);
  object_manager_server_.RegisterService(object_manager_service_);
  object_manager_server_.Run();
}

void ObjectManager::RunRpcService(int index) {
  rpc_service_.run();
}
</code></pre>
<pre><code class="language-cpp">// src/ray/rpc/object_manager/object_manager_server.h


class ObjectManagerGrpcService : public GrpcService {
  ObjectManagerGrpcService(instrumented_io_context &amp;io_service,
                           ObjectManagerServiceHandler &amp;service_handler)
      : GrpcService(io_service), service_handler_(service_handler){};
</code></pre>
<p>Worker Pool</p>
<pre><code class="language-cpp">// src/ray/raylet/worker_pool.cc
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="api-3"><a class="header" href="#api-3">API</a></h1>
<pre><code class="language-python">import ray
ray.init()
# ray.init(address='ray://localhost:10001')

@ray.remote
def f(x):
    return x * x

futures = [f.remote(i) for i in range(4)]
print(ray.get(futures))
</code></pre>
<pre><code class="language-python"># python/ray/__init__.py

from ray.worker import (  # noqa: E402,F401
    get,
    init,
    put,
    remote,
    wait,
)
</code></pre>
<p>API <code>ray.init</code>, <code>ray.remote</code>, <code>ray.get</code> 都来自 <code>ray.worker</code>.</p>
<pre><code class="language-python"># python/ray/worker.py

def init(address: Optional[str] = None, ...):
    # if address
    builder = ray.client(address, _deprecation_warn_enabled=False)
    builder._init_args(**passed_kwargs)
    return builder.connect()

    # if bootstrap_address is None:
    _global_node = ray.node.Node(head=True, shutdown_at_exit=False, spawn_reaper=True, ray_params=ray_params)
    # else
    _global_node = ray.node.Node(ray_params, head=False, shutdown_at_exit=False, spawn_reaper=False, connect_only=True)

    connect(...)
    return RayContext(...)

def connect(node, worker=global_worker, ...):
    worker.node = node
    worker.core_worker = ray._raylet.CoreWorker(...)
</code></pre>
<p>CoreWorker</p>
<pre><code class="language-cpp">// src/ray/core_worker/core_worker.h

class CoreWorker : public rpc::CoreWorkerServiceHandler {
  instrumented_io_context io_service_;
  boost::asio::io_service::work io_work_;

  rpc::CoreWorkerGrpcService grpc_service_;
  std::unique_ptr&lt;rpc::GrpcServer&gt; core_worker_server_;
  
  // std::unique_ptr&lt;ObjectRecoveryManager&gt; object_recovery_manager_;

  std::shared_ptr&lt;TaskManager&gt; task_manager_;
  std::unique_ptr&lt;ActorManager&gt; actor_manager_;

  /// Implements gRPC server handler.
  void HandleXxxx(const rpc::PushTaskRequest &amp;request,
                      rpc::PushTaskReply *reply,
                      rpc::SendReplyCallback send_reply_callback) override;
}


// src/ray/core_worker/core_worker.cc

CoreWorker::CoreWorker(...) {
  io_work_(io_service_),
  grpc_service_(io_service_, *this),

  core_worker_server_-&gt;RegisterService(grpc_service_);
  core_worker_server_-&gt;Run();
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="python"><a class="header" href="#python">python</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="concurrent-execution"><a class="header" href="#concurrent-execution">Concurrent Execution</a></h1>
<p><strong>TL;DR;</strong></p>
<ul>
<li>使用 python 作为引子/driver 启动其他独立进程，使用 exec. </li>
<li>使用 python 作为主进程管理，子进程是独立启动的进程，使用 subprocess.Popen.</li>
<li>子进程是 python 函数使用 multiprocessing。</li>
<li>把 python 函数当作线程启动时使用 threading。</li>
</ul>
<p><a href="https://docs.python.org/3/library/concurrency.html">https://docs.python.org/3/library/concurrency.html</a></p>
<h3 id="1-subprocess"><a class="header" href="#1-subprocess">1. subprocess</a></h3>
<ul>
<li>启动子进程，自定义 excutable</li>
</ul>
<pre><code class="language-python">import subprocess

proc = subprocess.Popen([&quot;/usr/bin/git&quot;, &quot;commit&quot;, &quot;-m&quot;, &quot;Fixes a bug.&quot;])
proc.poll()
proc.wait()
proc.communicate()
proc.terminate()
proc.kill()
</code></pre>
<p><a href="https://docs.python.org/3/library/subprocess.html">https://docs.python.org/3/library/subprocess.html</a></p>
<h3 id="2-threading"><a class="header" href="#2-threading">2. threading</a></h3>
<ul>
<li>启动线程</li>
<li>存在 GIL 问题，无法完全利用 CPU</li>
</ul>
<pre><code class="language-python">import threading

def serve():
    pass

thread = threading.Thread(target=serve, daemon=None)
thread.start()
thread.join()
</code></pre>
<p><a href="https://docs.python.org/3/library/threading.html">https://docs.python.org/3/library/threading.html</a></p>
<h4 id="pros"><a class="header" href="#pros">Pros</a></h4>
<ul>
<li>Lightweight - low memory footprint</li>
<li>Shared memory - makes access to state from another context easier</li>
<li>Allows you to easily make responsive UIs</li>
<li>cPython C extension modules that properly release the GIL will run in parallel</li>
<li>Great option for I/O-bound applications</li>
</ul>
<h4 id="cons"><a class="header" href="#cons">Cons</a></h4>
<ul>
<li>cPython - subject to the GIL</li>
<li>Not interruptible/killable</li>
<li>If not following a command queue/message pump model (using the Queue module), then manual use of synchronization primitives become a necessity (decisions are needed for the granularity of locking)</li>
<li>Code is usually harder to understand and to get right - the potential for race conditions increases dramatically</li>
</ul>
<h3 id="3-multiprocessing"><a class="header" href="#3-multiprocessing">3. multiprocessing</a></h3>
<ul>
<li>启动子进程，使用内置函数</li>
<li>使用进程，充分利用 CPU 资源</li>
</ul>
<pre><code class="language-python">from multiprocessing

proc = multiprocessing.Process(target=serve, daemon=None)
proc.start()
proc.join()
proc.close()

</code></pre>
<p><a href="https://docs.python.org/3/library/multiprocessing.html">https://docs.python.org/3/library/multiprocessing.html</a></p>
<h4 id="pros-1"><a class="header" href="#pros-1">Pros</a></h4>
<ul>
<li>Separate memory space</li>
<li>Code is usually straightforward</li>
<li>Takes advantage of multiple CPUs &amp; cores</li>
<li>Avoids GIL limitations for cPython</li>
<li>Eliminates most needs for synchronization primitives unless if you use shared memory (instead, it's more of a communication model for IPC)</li>
<li>Child processes are interruptible/killable</li>
<li>Python multiprocessing module includes useful abstractions with an interface much like threading.Thread</li>
<li>A must with cPython for CPU-bound processing</li>
</ul>
<h4 id="cons-1"><a class="header" href="#cons-1">Cons</a></h4>
<ul>
<li>IPC a little more complicated with more overhead (communication model vs. shared memory/objects)</li>
<li>Larger memory footprint</li>
</ul>
<h3 id="4-executor"><a class="header" href="#4-executor">4. Executor</a></h3>
<p><a href="https://docs.python.org/3/library/concurrent.futures.html">https://docs.python.org/3/library/concurrent.futures.html</a></p>
<ul>
<li>ProcessPoolExecutor 封装 multiprocessing module，提供进程池</li>
<li>ThreadPoolExecutor, 线程池</li>
</ul>
<p>API</p>
<pre><code>class concurrent.futures.Executor:
    submit(fn, /, *args, **kwargs)
    map(func, *iterables, timeout=None, chunksize=1)
    shutdown(wait=True, *, cancel_futures=False)
</code></pre>
<p>调用 submit 返回 <code>concurrent.futures.Future</code>, 使用 result(timeout=None) 获取结果。.</p>
<h3 id="exec"><a class="header" href="#exec">exec</a></h3>
<p>python 转 shell 执行</p>
<pre><code>os.execve('/bin/sh', 'echo', 'ok')
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="multiprocessing"><a class="header" href="#multiprocessing">multiprocessing</a></h1>
<p><a href="https://docs.python.org/3/library/multiprocessing.html">multiprocessing — Process-based parallelism — Python 3.10.1 documentation</a></p>
<p>Difference between <code>Pipe</code> and <code>Queue</code></p>
<ul>
<li>
<p>A <code>Pipe()</code> can have two endpoints</p>
</li>
<li>
<p>A <code>Queue()</code> can have multiple producers and consumers</p>
</li>
</ul>
<p>A <code>Pipe</code> has a better performance than <code>Queue</code> since <code>Queue</code> is built on top of <code>Pipe</code>.</p>
<h3 id="queue"><a class="header" href="#queue">Queue</a></h3>
<pre><code class="language-py">from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print(q.get())    # prints &quot;[42, None, 'hello']&quot;
    p.join()
</code></pre>
<h3 id="pipe"><a class="header" href="#pipe">Pipe</a></h3>
<pre><code class="language-py">from multiprocessing import Process, Pipe

def f(conn):
    conn.send([42, None, 'hello'])
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    p = Process(target=f, args=(child_conn,))
    p.start()
    print(parent_conn.recv())   # prints &quot;[42, None, 'hello']&quot;
    p.join()
</code></pre>
<h3 id="lock"><a class="header" href="#lock">Lock</a></h3>
<pre><code class="language-py">from multiprocessing import Process, Lock

def f(l, i):
    l.acquire()
    try:
        print('hello world', i)
    finally:
        l.release()

if __name__ == '__main__':
    lock = Lock()

    for num in range(10):
        Process(target=f, args=(lock, num)).start()s
</code></pre>
<h3 id="shared--memory"><a class="header" href="#shared--memory">Shared  memory</a></h3>
<p>Value and Array Only</p>
<pre><code class="language-py">from multiprocessing import Process, Value, Array

def f(n, a):
    n.value = 3.1415927
    for i in range(len(a)):
        a[i] = -a[i]

if __name__ == '__main__':
    num = Value('d', 0.0)
    arr = Array('i', range(10))

    p = Process(target=f, args=(num, arr))
    p.start()
    p.join()

    print(num.value)
    print(arr[:])
</code></pre>
<h3 id="server-process"><a class="header" href="#server-process">Server process</a></h3>
<pre><code class="language-python">from multiprocessing import Process, Manager

def f(d, l):
    d[1] = '1'
    d['2'] = 2
    d[0.25] = None
    l.reverse()

if __name__ == '__main__':
    with Manager() as manager:
        d = manager.dict()
        l = manager.list(range(10))

        p = Process(target=f, args=(d, l))
        p.start()
        p.join()

        print(d)
        print(l)
</code></pre>
<p><strong>remote manager</strong></p>
<p>start server</p>
<pre><code class="language-python">from multiprocessing.managers import BaseManager
from queue import Queue
queue = Queue()
class QueueManager(BaseManager): pass
QueueManager.register('get_queue', callable=lambda:queue)
m = QueueManager(address=('', 50000), authkey=b'abracadabra')
s = m.get_server()
s.serve_forever()
</code></pre>
<p>use in clients</p>
<pre><code class="language-python">from multiprocessing.managers import BaseManager
class QueueManager(BaseManager): pass
QueueManager.register('get_queue')
m = QueueManager(address=('foo.bar.org', 50000), authkey=b'abracadabra')
m.connect()
queue = m.get_queue()
queue.put('hello')
#queue.get('hello')
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="decorator"><a class="header" href="#decorator">decorator</a></h1>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<pre><code class="language-python">def decorator(f):
    print(0)
    return f

@decorator
def func(*args, **kwargs):
    print(2, *args, **kwargs)
    return 3

# func = decorator(func)

print(1)
print(func())
</code></pre>
<p>应用场景</p>
<ul>
<li>插件注册 Registering Plugins</li>
<li>Trace</li>
</ul>
<pre><code class="language-python">def decorator(f):
    print(0)
    def wrapper(*args, **kwargs):
        print(2)
        ret = f(*args, **kwargs)
        print(4)
        return ret
    return wrapper

@decorator
def f(*args, **kwargs):
    print(3)
    return 5

# f = decorator(f)

print(1)
print(f())
</code></pre>
<p>应用场景</p>
<ul>
<li>过滤/校验</li>
<li>重复调用</li>
<li>统计时间</li>
<li>Debug</li>
</ul>
<pre><code class="language-python">def decorator(arg):
    print(arg)
    def wrapper(f):
        print(1)
        return f
    return wrapper

@decorator(0)
def f(*args, **kwargs):
    print(3)
    return 4

# f = decorator(arg)(f)

print(2)
print(f())
</code></pre>
<pre><code class="language-python">import functools

def repeat(_func=None, *, num_times=2):
    def decorator_repeat(func):
        @functools.wraps(func)
        def wrapper_repeat(*args, **kwargs):
            for _ in range(num_times):
                value = func(*args, **kwargs)
            return value
        return wrapper_repeat

    if _func is None:
        return decorator_repeat
    else:
        return decorator_repeat(_func)

@repeat
def say_whee():
    print(&quot;Whee!&quot;)

@repeat(num_times=3)
def greet(name):
    print(f&quot;Hello {name}&quot;)

say_whee()
greet(&quot;kk&quot;)
</code></pre>
<pre><code class="language-python">import functools

def singleton(cls):
    &quot;&quot;&quot;Make a class a Singleton class (only one instance)&quot;&quot;&quot;
    @functools.wraps(cls)
    def wrapper_singleton(*args, **kwargs):
        if not wrapper_singleton.instance:
            wrapper_singleton.instance = cls(*args, **kwargs)
        return wrapper_singleton.instance
    wrapper_singleton.instance = None
    return wrapper_singleton

@singleton
class TheOne:
    pass
</code></pre>
<pre><code class="language-python">class Decorator:
    def __init__(self, arg):
        print(arg)
        self.arg = arg

    def __call__(self, f):
        print(1, self.arg)
        return f

@Decorator(0)
def func(arg):
    print(3)
    return arg

# func = Decorator(arg)(arg)

print(2)

print(func(4))
print(func(5))
</code></pre>
<pre><code class="language-python">class Decorator:
    def __init__(self, f):
        print(0)
        self.f = f

    def __call__(self, arg):
        print(2, self.f)
        return self.f(arg)

@Decorator
def func(arg):
    print(3)
    return arg

# func = Decorator(arg)(arg)

print(1)

print(func(4))
print(func(5))
</code></pre>
<h2 id="reference-6"><a class="header" href="#reference-6">Reference</a></h2>
<ul>
<li><a href="https://realpython.com/primer-on-python-decorators/">realpython</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="kubernetes"><a class="header" href="#kubernetes">kubernetes</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="scheduler"><a class="header" href="#scheduler">scheduler</a></h1>
<h2 id="summary-and-examples"><a class="header" href="#summary-and-examples">Summary and Examples</a></h2>
<p>比较简单的 demo，体现基本框架</p>
<p><a href="https://github.com/Huang-Wei/sample-scheduler-extender">GitHub - Huang-Wei/sample-scheduler-extender: a sample to showcase how to create a k8s scheduler extender</a></p>
<p>稍微复杂一些，完整实现，extender 部署</p>
<p><a href="https://github.com/everpeace/k8s-scheduler-extender-example">GitHub - everpeace/k8s-scheduler-extender-example: An example of kubernetes scheduler extender</a></p>
<p>aliyun  gpu，部署替换 kube-scheduler</p>
<p><a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender">GitHub - AliyunContainerService/gpushare-scheduler-extender: GPU Sharing Scheduler for Kubernetes Cluster</a></p>
<p>基于 kubernetes framework</p>
<p><a href="https://github.com/everpeace/kube-throttler">GitHub - everpeace/kube-throttler: throttling your pods in kubernetes cluster.</a></p>
<h2 id="reference-7"><a class="header" href="#reference-7">Reference</a></h2>
<ul>
<li>
<p><a href="https://github.com/kubernetes/design-proposals-archive/blob/main/scheduling/scheduler_extender.md">design-proposals-archive/scheduler_extender.md at main · kubernetes/design-proposals-archive · GitHub</a></p>
</li>
<li>
<p><a href="https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/">Scheduling Framework | Kubernetes</a></p>
</li>
<li>
<p><a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/624-scheduling-framework/README.md">enhancements/README.md at master · kubernetes/enhancements · GitHub</a></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="kubernetes-operator-开发"><a class="header" href="#kubernetes-operator-开发">Kubernetes Operator 开发</a></h1>
<p>Kubernetes 是 Google 开源贡献给云原生计算基金会 (CNCF)，用于自动部署、拓展和管理容器化程序的开源系统。Kubernetes 作为云原生的基础设施，已经成为容器化应用编排的事实标准，依赖其优秀的顶层设计和强大的可拓展能力，为整个生态的繁荣奠定了基础。</p>
<p>Kubernetes 内置了一系列的工作负载资源可以直接使用以完成基于容器化运行的特定任务，例如一个数据处理任务或者一个单节点的训练任务可以使用定义 Job 来实现。当内置的工作负载不能满足我们的业务场景需求时，可以通过拓展 Kubernetes 的方式添加功能，例如直接使用 Kubernetes 内置资源无法准确定义一个分布式机器学习任务所需要的角色分配和批量任务等功能。</p>
<p>Operator 是开发 Kubernetes 应用拓展的原生方式，它通过添加自定义资源（CRD）拓展出新的 API，并且依赖 Kubernetes API Server 面向用户提供服务，即用户通过原有服务即可操作新添加的资源对象。为了响应该资源对象的变动，维护资源对象的生命周期，开发者需要定义资源的更新逻辑，即需要开发部署控制器 (Controller) .</p>
<img src="kubernetes/./assets/operator-3.png" title="" alt="" data-align="center">
<p>如图所示，Operator 包括自定义资源类型（CRD）和控制器（Controller）两个部分，CRD  使得资源定义和 API 得以拓展，Controller 负责对应资源的变化的逻辑处理。</p>
<p>Operator 的应用场景非常广泛，而相比于普通部署于 Kubernetes 集群的应用相比，Operator 的设计模式主要针对能够对资源类进行抽象，通过管理实例化资源的方式完成特定任务。更多应用场景的说明可以在<a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/">这里</a> 找到。</p>
<p>本文分为三个部分：首先通过 Kubernetes 资源定义和对 Controller 逻辑进行解析介绍 Operator 的工作原理，最后介绍在实践中开发 Operator 的方法。</p>
<h2 id="kubernetes-资源定义"><a class="header" href="#kubernetes-资源定义">Kubernetes 资源定义</a></h2>
<p>Kubernetes 的资源管理和调度以 Pod 为单位，一个 Pod 中可以运行一个或多个容器 (Container) ，容器中运行特定的应用程序。Kubernetes 中的资源定义都提供了对外接口，即用户可以通过 Kubernetes API 直接操作 Pod，例如可以使用以下配置信息来描述/定义一个 Pod 实例：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
</code></pre>
<p>配置信息相当于<em>实例化</em>了一个 Pod 对象，表示一个名称为 <code>nginx</code>  的 Pod，运行镜像为 <code>nginx:1.14.2</code> ， 而 Pod 类的定义可以在<a href="https://github.com/Kubernetes/api/blob/master/core/v1/types.go#L3877-L3896">这里</a>找到，</p>
<pre><code class="language-go">type Pod struct {
    metav1.TypeMeta `json:&quot;,inline&quot;`

    metav1.ObjectMeta `json:&quot;metadata,omitempty&quot; protobuf:&quot;bytes,1,opt,name=metadata&quot;`

    Spec PodSpec `json:&quot;spec,omitempty&quot; protobuf:&quot;bytes,2,opt,name=spec&quot;`

    Status PodStatus `json:&quot;status,omitempty&quot; protobuf:&quot;bytes,3,opt,name=status&quot;`
}
</code></pre>
<p>这里的定义主要有四块内容，其中 <code>apiVersion</code> 和 <code>kind</code> 来自于 <code>TypeMeta</code> 指定类型的名称和版本信息，来自 <code>ObjectMeta</code> 的 <code>metadata</code> 主要指定具体的对象信息，最常见的包含资源名称 <code>name</code> 和资源所在的命名空间 <code>namespace</code>。在 Kubernetes 中，通过类型、命名空间和名称的组合（kind-namespace-name）即可唯一标识一个具体的资源对象。<code>TypeMeta</code>和<code>ObjectMeta</code>信息属于 Kubernetes API 体系的基础定义，类似于继承中的父类定义。而 <code>spec</code> 和 <code>status</code> 会根据资源类型的不同有不同的定义，如这里 Pod 的 <code>spec</code> 和 <code>status</code> 分别由 <code>PodSpec</code> 和 <code>PodStatus</code> 具体定义。一般地，<code>spec</code>表示资源对象的静态配置信息和期望的状态，即该资源通过 <code>spec</code>即可描述它应有的完整工作流程。相对地，<code>status</code>表示该资源对象当前所处的状态信息，在运行时会随时间被更新的部分。</p>
<p>通过调用 Kubernetes 对应的服务接口我们可以在集群中对对象进行 CRUD 操作即创建、查询、更新、删除对应的对象。</p>
<blockquote>
<p>定义资源的格式可以有多种，如 yaml，json 等等，取决于调用方法所支持的数据格式。调用 Kubernetes 接口的方式也有多种，如 http(s) 访问、kubectl 客户端访问、使用 SDK 开发 client 等， 本文不对此做详细讨论。</p>
</blockquote>
<p>基于 Pod 拓展的资源叫做工作负载资源，Kubernetes 内置了多种工作负载资源。</p>
<ul>
<li>
<p>Job 提供单次任务资源定义，Cronjob 提供时间规划运行任务定义；</p>
</li>
<li>
<p>StatefulSet 提供有状态负载集合的定义；</p>
</li>
<li>
<p>Deployment 和 ReplicaSet 提供无状态负载集合的定义；</p>
</li>
<li>
<p>DaemonSet 提供节点绑定的负载定义；</p>
</li>
</ul>
<p>工作负载资源定义都有类似上述 Pod 定义四个部分的结构，基于 Kubernetes 声明式的设计，期望状态在 <code>spec</code> 中被描述， <code>status</code> 中体现当前资源所处的实际状态，那么谁负责更新资源当前所处的状态和怎么做才能满足期望状态呢？这就是接下来讲的组件 controller。</p>
<h2 id="controller-原理和实现"><a class="header" href="#controller-原理和实现">Controller 原理和实现</a></h2>
<p>通过上面资源定义的介绍我们知道 Controller 是进行逻辑处理的部分，它的作用是更新资源状态同时尽可能采取行动使得资源满足期望状态。要理解 Controller 的工作原理需要首先理解 Kubernetes client-go 中的 informer 设计。首先，informer 和特定的资源绑定，如图所示，Informer 通过客户端实现对特定资源的 List 和 Watch 操作，即从服务端拉取所需要的资源信息，获取到的信息一方面存入自带索引的本地缓存 cache indexer，另一方面变动信息生成对应事件 event，预先注册的对应资源变动的 handler 相应逻辑会被触发执行。这里 event 信息中只有索引信息，在处理模块中需要使用资源完整信息时再通过 indexer 进行查询。</p>
<img src="kubernetes/./assets/controller-detail.png" title="" alt="" data-align="center">
<p>从以上设计中可以看出，本地缓存所需资源信息，极大减少了和 API Server 交互的压力，而且在具体实现中，采用了 shared informer 的机制，即同一资源被多次使用时可以共享 informer 再次降低了负载压力。</p>
<p>我们以 Job Controller 为例（完整源码可以在<a href="https://github.com/kubernetes/kubernetes/blob/v1.23.1/pkg/controller/job/job_controller.go">这里</a>找到），来看 Controller 如何利用 informer 完成控制逻辑的。Controller 定义主要包含以下部分（已省略部分内容），在 Job Controller 中关注两种资源 Job 和 Pod。</p>
<pre><code class="language-go">type Controller struct {
    // 用于连接集群的客户端
    kubeClient clientset.Interface
    // 用于获取 job 信息
    jobLister batchv1listers.JobLister
    // 用于获取 pod 信息
    podStore corelisters.PodLister
    // 需要处理的消息任务队列
    queue workqueue.RateLimitingInterface
}
</code></pre>
<p>当 Controller 被初始化时，两种资源 Job 和 Pod对应的 informer 已经提前被创建作为参数传入，这里主要将 Controller 中对应的函数和资源变动事件通过 AddEventHandler 函数进行注册绑定，这样对应资源变动时，函数将会被执行，可以看到当 job 被创建和删除时，只是简单将对象放入处理队列，而 job 更新和 pod 变动都有对应函数处理，pod 的变动触发函数主要处理一致性问题和触发 job 更新消息，下面我们主要关注 job 更新消息的处理。</p>
<pre><code class="language-go">func NewController(podInformer coreinformers.PodInformer, jobInformer batchinformers.JobInformer, kubeClient clientset.Interface) *Controller {
    // 初始化，创建消息队列
    jm := &amp;Controller{
        kubeClient: kubeClient,
        queue:      workqueue.NewNamedRateLimitingQueue(...),
    }
    // 向 job informer 注册处理 job 资源变更消息的 handler 函数
    jobInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
        AddFunc: func(obj interface{}) {
            jm.enqueueController(obj, true)
        },
        UpdateFunc: jm.updateJob,
        DeleteFunc: func(obj interface{}) {
            jm.enqueueController(obj, true)
        },
    })
    jm.jobLister = jobInformer.Lister()
    // 向 pod informer 注册处理 pod 资源变更消息的 handler 函数
    podInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
        AddFunc:    jm.addPod,
        UpdateFunc: jm.updatePod,
        DeleteFunc: jm.deletePod,
    })
    jm.podStore = podInformer.Lister()

    return jm
}
</code></pre>
<p>当 Controller 运行时，可以同时运行多个 worker 并发处理任务</p>
<pre><code class="language-go">func (jm *Controller) Run(workers int, stopCh &lt;-chan struct{}) {
    ...
    for i := 0; i &lt; workers; i++ {
        go wait.Until(jm.worker, time.Second, stopCh)
    }
    ...
}
</code></pre>
<p>每个 worker 不断地从消息队列中取出需要处理即有变更发生的资源，执行同步函数</p>
<pre><code class="language-go">func (jm *Controller) worker() {
    for jm.processNextWorkItem() {
    }
}

func (jm *Controller) processNextWorkItem() bool {
    key, quit := jm.queue.Get()
    ...
    // syncHandler 即 jm.syncJob
    forget, err := jm.syncHandler(key.(string))
    ...
}
</code></pre>
<p>同步 job 的具体流程如下，先通过消息中的索引信息获取对象，这里再次注意获取资源三要素：资源类型、命名空间和名字，job 是用来管理 pod 的（几乎所有的工作负载都是这样设计），底层资源还是 pod，所以这里还要获取与 job 关联的 pods。获得资源的状态信息后，经过一系列判断以对 job 进行不同的操作，比如失败且满足条件时会执行删除关联 pod 操作，有的还需进一步判断，比如在 manageJob 包含了对不同情形下需要执行删除和创建 pod，注意到，最后操作都会落到对 pod 的管理上，这也是 job 资源的意义。同步完成后，更新 job 的最新状态。</p>
<blockquote>
<p>注意这里获取资源对象都是从 informer，也即本地缓存中获取的。</p>
</blockquote>
<pre><code class="language-go">func (jm *Controller) syncJob(key string) (bool, error) {
    // 获取资源
    ns, name, err := cache.SplitMetaNamespaceKey(key)
    // 
    sharedJob, err := jm.jobLister.Jobs(ns).Get(name)
    // 通过 job 获取关联 pods
    pods, err := jm.getPodsForJob(&amp;job)

    if jobFailed {
        // 如果 job 失败，删除 pods
        jm.deleteJobPods(&amp;job, activePods, errCh)
    } else {
        // 进一步分析以确定操作
        if ...
        jm.manageJob(activePods, succeeded, &amp;job)
        ...
    }
    // 计算、修改 job status
    ...
    // 即 updateJobStatus 更新 job status 信息
    jm.updateHandler(&amp;job)
}
</code></pre>
<p>在 manageJob 包含了对 job spec 中任务运行数量控制的核心逻辑，可以看出，当一个常规 job 被创建时，它会进入这里的创建 pod 分支以启动工作流程。</p>
<pre><code class="language-go">func (jm *Controller) manageJob(activePods []*v1.Pod, succeeded int32, job *batch.Job) (int32, error) {
    parallelism := *job.Spec.Parallelism
    if active &gt; parallelism {
        ...
        // 删除 pod
        jm.podControl.DeletePod(job.Namespace, activePods[ix].Name, job)
    } else if active &lt; parallelism {
        ...
        // 创建 pod，同时关联 pod 和 job
        jm.podControl.CreatePodsWithControllerRef(job.Namespace, &amp;job.Spec.Template, job, metav1.NewControllerRef(job, controllerKind))    }
    }
}
</code></pre>
<p>关于对 pod 的控制逻辑都已完毕，我们最后来看 Controller 一个重要的任务是将资源当前的状态更新至 status 字段下，这里的逻辑比较简单，只需要将获取和计算好的当前状态更新到服务端，值得注意的是并不会也不能直接改动从 informer 中获取的对象（再次强调它是本地缓存），而是通过客户端（这里的 jobClient）直接向 API Server 提交请求更新状态。</p>
<pre><code class="language-go">func (jm *Controller) updateJobStatus(job *batch.Job) error {
    jobClient := jm.kubeClient.BatchV1().Jobs(job.Namespace)
    newJob, err = jobClient.Get(context.TODO(), job.Name, metav1.GetOptions{})
    newJob.Status = job.Status
    jobClient.UpdateStatus(context.TODO(), newJob, metav1.UpdateOptions{}); err == nil {
}
</code></pre>
<blockquote>
<p>在上述介绍中，限于篇幅省略了对 expectations 的讨论，它是一个缓存工具用于保证同步过程中的数据一致性问题。因为在缓存场景下，运行时从缓存中获取的信息可能和服务端存在不一致的情况，在实现时需要考虑。</p>
</blockquote>
<p>通过以 Job Controller 为例，我们介绍了 Controller 的原理和工作流程，简单地可以将 Controller 的工作原理总结为以下循环和图示。</p>
<pre><code class="language-bash">for {
  desired := getDesiredState()   // spec
  current := getCurrentState()   // status
  makeChanges(desired, current)
}
</code></pre>
<img src="kubernetes/./assets/controller.png" title="" alt="" data-align="center">
<h2 id="operator-开发实践"><a class="header" href="#operator-开发实践">Operator 开发实践</a></h2>
<p>当 Kubernetes 提供的工作负载无法满足需求场景时，我们可以考虑通过添加自定义资源和自定义控制器的方式来扩展 Kubernetes 功能，这里包含两层意思：</p>
<ul>
<li>
<p>通过自定义资源 （ CustomResourceDefinition 简称 CRD）来拓展 Kubernetes API</p>
</li>
<li>
<p>通过部署对应的自定义 Controller 执行自定义资源的定制化逻辑</p>
</li>
</ul>
<p>这种原生的拓展方式即 CRD 和 Controller 联合开发部署的方式被称为开发 Kubernetes 的 Operator.</p>
<p>开发自定义 Operator 时，可以使用一些开发工具来帮助我们自动构建开发 Operator 所需要的基础组件，比如 <a href="https://github.com/kubernetes-sigs/kubebuilder">kubebuilder</a> 是一个带有命令行工具和运行时库的构建工具，通过它可以快速构建一个生产部署 ready 的自定义 Operator，包括生成 RBAC 、yaml 配置等等。</p>
<p>下面以 CronJob 的 Operator 为例来介绍使用自定义 Operator 开发的流程和方法。</p>
<p>首先是通过 Golang struct 定义 CRD，前面介绍过，只需要关心 <code>spec</code> 和 <code>status</code>即可，</p>
<pre><code class="language-go">type CronJob struct {
    metav1.TypeMeta   `json:&quot;,inline&quot;`
    metav1.ObjectMeta `json:&quot;metadata,omitempty&quot;`

    Spec   CronJobSpec   `json:&quot;spec,omitempty&quot;`
    Status CronJobStatus `json:&quot;status,omitempty&quot;`
}
</code></pre>
<p>根据具体的设计需要在 spec 中添加字段，可以一般也必然地会使用 kubernetes 内置的资源，这里 CronJob 中定义了 job，使用 job 资源类型来管理工作负载。</p>
<pre><code class="language-go">type CronJobSpec struct {
    Schedule string `json:&quot;schedule&quot;`
    JobTemplate batchv1beta1.JobTemplateSpec `json:&quot;jobTemplate&quot;`
    ...
}
</code></pre>
<p>Controller 对应这里的 CronJobReconciler，它的逻辑被封装为接口函数 Reconcile，这个函数会在资源发生变动时被触发，所以只需在函数内部专注编写同步状态逻辑即可。而且 Reconciler 还提供了高层 API 如 get/list/create 等操作，这些 API 来自于 <a href="https://github.com/kubernetes-sigs/controller-runtime">controller-runtime</a> 库中的 client，当有更灵活的调用需求时可以直接使用该库中的 API 进行资源操作而不必受限于这里封装的 Reconcile 函数。</p>
<pre><code class="language-go">func (r *CronJobReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    // 获取对象，再次注意三要素
    var cronJob batch.CronJob
    if err := r.Get(ctx, req.NamespacedName, &amp;cronJob); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }
    var childJobs kbatch.JobList
    r.List(ctx, &amp;childJobs, client.InNamespace(req.Namespace), client.MatchingFields{jobOwnerKey: req.Name}); err != nil {

    // 计算当前的状态，给 cronJob.Status 负值
    cronJob.Status = getStatus()
    // 更新状态
    if err := r.Status().Update(ctx, &amp;cronJob); err != nil {
        // 更新不成功时，返回错误，将任务放入队列重新执行
        return ctrl.Result{}, err
    }

    // 创建 job 实例
    job, err := constructJobForCronJob(&amp;cronJob, missedRun)
    if err != nil {
        return scheduledResult, nil
    }
    // 向服务端请求创建 job
    if err := r.Create(ctx, job); err != nil {
        return ctrl.Result{}, err
    }
    return scheduledResult, nil
}
</code></pre>
<p>同样值得关注的是 Controlller 被创建的部分，原 informer 中的索引和缓存逻辑被封装到了这里，根据拓展资源的定义在这里添加资源依赖关系和创建索引，除了工作负载如果需要用到其他 Kubernetes 资源也需要在这里进行添加，如 Service 和 Configmap 等，当使用非 Kubernetes 内置资源时，会形成必要的强依赖。</p>
<pre><code class="language-go">func (r *CronJobReconciler) SetupWithManager(mgr ctrl.Manager) error {
    // 创建本地缓存和索引
    mgr.GetFieldIndexer().IndexField(context.Background(), &amp;kbatch.Job{}, jobOwnerKey, func(rawObj client.Object) []string {}

    // 构建资源依赖关系
    return ctrl.NewControllerManagedBy(mgr).
        For(&amp;batch.CronJob{}).
        Owns(&amp;kbatch.Job{}).
        Complete(r)
}
</code></pre>
<p>到这里使用 Operator 开发模式进行 Kubernetes 扩展的主要内容就介绍完了，更多的开发细节请参考 Kubernetes 和 kuberbuilder 的文档。</p>
<p>基于 kuberbuilder 开发的用于运行 <a href="https://github.com/PaddlePaddle/Paddle">paddlepaddle</a> 分布式任务的 paddle-Operator 已经开源，感兴趣的朋友可以在这里找到<a href="https://github.com/PaddleFlow/paddle-operator">源码</a>，相互学习交流。</p>
<h4 id="reference-8"><a class="header" href="#reference-8">Reference</a></h4>
<p>https://kubernetes.io/zh/docs/concepts/workloads/</p>
<p>https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/</p>
<p>https://github.com/kubernetes-sigs/kubebuilder</p>
<p>https://github.com/kubernetes/api</p>
<p>https://github.com/cncf/tag-app-delivery/blob/main/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="device-plugin"><a class="header" href="#device-plugin">device plugin</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="docker"><a class="header" href="#docker">Docker</a></h1>
<h2 id="expression"><a class="header" href="#expression">Expression</a></h2>
<ul>
<li><strong>containerd</strong></li>
<li><strong>runc</strong></li>
<li><strong>CRI</strong></li>
<li><strong>OCI</strong></li>
<li><strong>containerd-shim</strong></li>
<li><strong>dockershim</strong></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="tvm"><a class="header" href="#tvm">TVM</a></h1>
<h2 id="expression-1"><a class="header" href="#expression-1">Expression</a></h2>
<p><strong>TE</strong>
Tensor Expression, DSL (domain-specific language)</p>
<p><strong>Relay</strong> TVM’s high-level model language</p>
<p><strong>IR</strong> intermediate representation</p>
<p><strong>TIR</strong> Tensor Intermediate Representation, TVM’s low-level intermediate representation</p>
<p><strong>Schedule</strong> how to execute the computation</p>
<p><strong>Stage</strong> schedule for one operation</p>
<p><strong>TOPI</strong> TVM Operator Inventory, numpy-style generic operations and schedules </p>
<h2 id="demo-5"><a class="header" href="#demo-5">Demo</a></h2>
<pre><code class="language-python">from tvm.driver import tvmc

#Step 1: Load
model = tvmc.load('resnet50-v2-7.onnx', shape_dict={'data':[1, 3, 224, 224]}) 

#Step 1.5: Optional Tune
tuning_records = tvmc.tune(model, target=&quot;llvm&quot;) 

#Step 2: Compile
package = tvmc.compile(model, target=&quot;llvm&quot;, tuning_records = tuning_records) 

#Step 3: Run
result = tvmc.run(package, device=&quot;cpu&quot;) 

print(result)
</code></pre>
<ul>
<li>IRModule: relay.Function + tir.PrimFunc</li>
<li>tvmc.compile: relay::Function --&gt; tir::PrimFunc</li>
</ul>
<p><strong>Why TVM ?</strong></p>
<p><code>tvmc.tune</code> make model run more fast.</p>
<p><strong>How ?</strong></p>
<p>ALL, especially,</p>
<p>AutoTVM (template-based) or AutoScheduler (Ansor, template-free auto-tuning)</p>
<h2 id="tvm-optimizaing-compiler-workflow"><a class="header" href="#tvm-optimizaing-compiler-workflow">TVM optimizaing compiler workflow</a></h2>
<ol>
<li>TF/PyTroch/ONNX</li>
<li>Relay (High-level IR)</li>
<li>TE (Computation definition)</li>
<li>AutoTVM/AutoScheduler (Auto-tuining module)</li>
<li>TE + Schedule (Optimization specification)</li>
<li>TIR (Low-level IR)</li>
<li>Machine Code</li>
</ol>
<p>流程解析</p>
<ol>
<li>TVM 数据输入格式，prefer ONNX</li>
<li>TVM 高级 API 操作计算图</li>
<li>Relay 通过 fuseops pass 生成子图，同时有 schedule primitives 对 low-level loop 进行优化，Tensor Operator Inventory (TOPI) 处理常规 op, 生成 TE</li>
<li>通过 AutoTVM (template-based) 或 AutoScheduler (template-free auto-tuning) 寻找最佳 schedule</li>
<li>生成 json 格式 tuning records, 包含最佳 schedule</li>
<li>生成 TIR，支持主流 LLVM/NVCC</li>
<li>生成机器码</li>
</ol>
<p>low-level loop optimizations: tiling, vectorization, parallelization, unrolling, and fusion</p>
<h2 id="tvm-auto-scheduler-aka-ansor"><a class="header" href="#tvm-auto-scheduler-aka-ansor">TVM Auto-scheduler (a.k.a. Ansor)</a></h2>
<p>package <code>tvm.auto_scheduler</code></p>
<h2 id="schedule-primitives"><a class="header" href="#schedule-primitives">Schedule Primitives</a></h2>
<p>How to get good performance kernel ?</p>
<h2 id="te"><a class="header" href="#te">TE</a></h2>
<pre><code class="language-python">import tvm
from tvm import te

m = te.var('m')
n = te.var('n')

a = te.placeholder((m, n), name='A')
b = te.placeholder((m, n), name='B')

c = te.compute((m, n), lambda i, j: a[i, j]*b[i, j], name='C')

s = te.create_schedule([c.op])

tgt = tvm.target.Target(target=&quot;llvm&quot;, host=&quot;llvm&quot;)
mult = tvm.build(s, [a, b, c], target=tgt, name=&quot;mult&quot;)

print(mult.get_source())

print(tvm.lower(s, [a, b, c], simple_mode=True))
</code></pre>
<p><code>tvm.build</code> </p>
<p>tvm.te.schedule.Schedule, tvm.tir.PrimFunc, IRModule, Mapping[str, IRModule] --&gt; <code>tvm.runtime.Module</code></p>
<p>A module that combines both host and device code</p>
<p><code>tvm.lower</code> </p>
<p>tvm.te.schedule.Schedule, tvm.tir.PrimFunc, IRModule --&gt; <code>IRModule</code></p>
<p>Demo for IRModule transform</p>
<pre><code class="language-python">import tvm
from tvm.ir.module import IRModule
from tvm.script import tir as T
import numpy as np

from tvm import te

A = te.placeholder((8,), dtype=&quot;float32&quot;, name=&quot;A&quot;)
B = te.compute((8,), lambda *i: A(*i) + 1.0, name=&quot;B&quot;)
func = te.create_prim_func([A, B])
ir_module = IRModule({&quot;main&quot;: func})
print(ir_module.script())
&quot;&quot;&quot;
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer[8, &quot;float32&quot;], B: T.Buffer[8, &quot;float32&quot;]) -&gt; None:
        # function attr dict
        T.func_attr({&quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True})
        # body
        # with T.block(&quot;root&quot;)
        for i0 in T.serial(8):
            with T.block(&quot;B&quot;):
                i0_1 = T.axis.spatial(8, i0)
                T.reads(A[i0_1])
                T.writes(B[i0_1])
                B[i0_1] = A[i0_1] + T.float32(1)
&quot;&quot;&quot;
</code></pre>
<pre><code class="language-python"># &lt;class 'tvm.driver.build_module.OperatorModule'&gt;
mod = tvm.build(ir_module, target=&quot;llvm&quot;)  # The module for CPU backends.

# &lt;class 'tvm.tir.schedule.schedule.Schedule'&gt;
sch = tvm.tir.Schedule(ir_module)
block_b = sch.get_block(&quot;B&quot;)
(i,) = sch.get_loops(block_b)
</code></pre>
<pre><code class="language-python">i_0, i_1, i_2 = sch.split(i, factors=[2, 2, 2])
print(sch.mod.script())
&quot;&quot;&quot;
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer[8, &quot;float32&quot;], B: T.Buffer[8, &quot;float32&quot;]) -&gt; None:
        # function attr dict
        T.func_attr({&quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True})
        # body
        # with T.block(&quot;root&quot;)
        for i0_0, i0_1, i0_2 in T.grid(2, 2, 2):
            with T.block(&quot;B&quot;):
                i0 = T.axis.spatial(8, i0_0 * 4 + i0_1 * 2 + i0_2)
                T.reads(A[i0])
                T.writes(B[i0])
                B[i0] = A[i0] + T.float32(1)
&quot;&quot;&quot;
</code></pre>
<pre><code class="language-python">sch.reorder(i_0, i_2, i_1)
print(sch.mod.script())
&quot;&quot;&quot;
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer[8, &quot;float32&quot;], B: T.Buffer[8, &quot;float32&quot;]) -&gt; None:
        # function attr dict
        T.func_attr({&quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True})
        # body
        # with T.block(&quot;root&quot;)
        for i0_0, i0_2, i0_1 in T.grid(2, 2, 2):
            with T.block(&quot;B&quot;):
                i0 = T.axis.spatial(8, i0_0 * 4 + i0_1 * 2 + i0_2)
                T.reads(A[i0])
                T.writes(B[i0])
                B[i0] = A[i0] + T.float32(1)
&quot;&quot;&quot;
</code></pre>
<pre><code class="language-python">sch.bind(i_0, &quot;blockIdx.x&quot;)
sch.bind(i_2, &quot;threadIdx.x&quot;)
print(sch.mod.script())
&quot;&quot;&quot;
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer[8, &quot;float32&quot;], B: T.Buffer[8, &quot;float32&quot;]) -&gt; None:
        # function attr dict
        T.func_attr({&quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True})
        # body
        # with T.block(&quot;root&quot;)
        for i0_0 in T.thread_binding(2, thread=&quot;blockIdx.x&quot;):
            for i0_2 in T.thread_binding(2, thread=&quot;threadIdx.x&quot;):
                for i0_1 in T.serial(2):
                    with T.block(&quot;B&quot;):
                        i0 = T.axis.spatial(8, i0_0 * 4 + i0_1 * 2 + i0_2)
                        T.reads(A[i0])
                        T.writes(B[i0])
                        B[i0] = A[i0] + T.float32(1)
&quot;&quot;&quot;
</code></pre>
<h2 id="relay"><a class="header" href="#relay">Relay</a></h2>
<p><strong>relay.build()</strong></p>
<p>return</p>
<ul>
<li>execution graph in json format</li>
<li>TVM module library of compiled functions specifically for this graph on the target hardware</li>
<li>parameter blobs of the model</li>
</ul>
<p>During the compilation, </p>
<ul>
<li>Relay does the graph-level optimization,</li>
<li>TVM does the tensor-level optimization,</li>
</ul>
<p>resulting in an optimized runtime module for model serving.</p>
<h3 id="relay-vs-te"><a class="header" href="#relay-vs-te">Relay v.s. TE</a></h3>
<pre><code class="language-python">tvm.tir.sqrt(x: tvm.ir.PrimExpr) -&gt; tvm.ir.PrimExpr

# Alias of tvm.tir.sqrt()
tvm.te.sqrt(x: tvm.ir.PrimExpr) -&gt; tvm.ir.PrimExpr

tvm.relay.sqrt(data: tvm.ir.RelayExpr) -&gt; tvm.ir.RelayExpr)
</code></pre>
<p>For tvm.ir.BaseExpr,</p>
<ul>
<li>PrimExpr is class of all primitive expressions, used in the low-level code optimizations and integer analysis.</li>
<li>RelayExpr is class of all non-primitive expressions.</li>
</ul>
<h3 id="build-1"><a class="header" href="#build-1">Build</a></h3>
<p><code>tvm.build</code> v.s. <code>tvm.relay.build</code></p>
<pre><code class="language-python">tvm.relay.build(ir_mod: IRModule, target, target_host, executor=graph{}, runtime=cpp) 
    -&gt; tvm.relay.backend.executor_factory.ExecutorFactoryModule

tvm.build(inputs: Union[tvm.te.schedule.Schedule, tvm.tir.function.PrimFunc, tvm.ir.module.IRModule, Mapping[str, tvm.ir.module.IRModule]], args, target, target_host, runtime, binds) 
    -&gt; tvm.driver.build_module.OperatorModule
</code></pre>
<h2 id="optimization"><a class="header" href="#optimization">Optimization</a></h2>
<p><strong>Blocking</strong>, <strong>Cache</strong></p>
<p>通过分 Block, 让留在 cache 中的中间计算结果能够发挥作用，从而提升性能。</p>
<p><strong>Vectorization</strong>, <strong>Array Packing</strong></p>
<p>连续的内存访问会比较高效，通过 <code>vectorize</code> 达到这样的目的。对矩阵的 Array Packing 也是在做这样的优化。</p>
<p><strong>Parallelization</strong></p>
<p>非依赖的情况下可以使用并行策略提高整体性能。</p>
<h2 id="topi"><a class="header" href="#topi">TOPI</a></h2>
<pre><code class="language-python">n = te.var(&quot;n&quot;)
m = te.var(&quot;m&quot;)
A = te.placeholder((n, m), name=&quot;A&quot;)
</code></pre>
<p>origin</p>
<pre><code class="language-python">k = te.reduce_axis((0, m), &quot;k&quot;)
B = te.compute((n,), lambda i: te.sum(A[i, k], axis=k), name=&quot;B&quot;)
s = te.create_schedule(B.op)
# print(tvm.lower(s, [A], simple_mode=True))
</code></pre>
<p>TOPI </p>
<pre><code class="language-python">C = topi.sum(A, axis=1)
ts = te.create_schedule(C.op)
# print(tvm.lower(ts, [A], simple_mode=True))
</code></pre>
<h2 id="develop-2"><a class="header" href="#develop-2">Develop</a></h2>
<ul>
<li>write a pass with IR</li>
<li>glue to lowering</li>
</ul>
<p>每一个 phase 做的 transformation 如下，</p>
<ul>
<li>Phase 0 generates the raw IR and loop levels.</li>
<li>Phase 1 flattens the array storage.</li>
<li>Phase 2 transforms loops, like unroll, vectorization and thread-binding.</li>
<li>Phase 3 does some cleanup work.</li>
</ul>
<p>所以比如自定义的 vectorize 适合放在 phase 1 之后。</p>
<pre><code class="language-python">with tvm.transform.PassContext(config={&quot;tir.add_lower_pass&quot;: [(1, vectorize)]}):
    print(tvm.lower(sch, [a, b, c]))
</code></pre>
<h2 id="reference-9"><a class="header" href="#reference-9">Reference</a></h2>
<ul>
<li><a href="https://tvm.apache.org/docs/">https://tvm.apache.org/docs/</a></li>
<li><a href="https://tvm.apache.org/docs/how_to/work_with_schedules/schedule_primitives.html">schedule_primitives</a></li>
<li><a href="https://tvm.apache.org/docs/tutorial/tensor_expr_get_started.html">optimization TE</a></li>
<li><a href="https://tvm.apache.org/docs/how_to/extend_tvm/low_level_custom_pass.html">custom pass</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="gloo"><a class="header" href="#gloo">Gloo</a></h1>
<h2 id="tldr-1"><a class="header" href="#tldr-1">TL;DR;</a></h2>
<p>Gloo 是集合通信和算法库。运行逻辑如下，</p>
<ul>
<li>定义网络设备信息创建通信媒介 Device;</li>
<li>使用可以共同交换数据的 Store 实现 rendezvous;</li>
<li>节点通过 (rank, size) 创建 Context, 使用 connectFullMesh 方法建立通信域：
<ul>
<li>向 Store 注册自身节点信息；</li>
<li>从 Store 中获取全部节点信息；</li>
<li>启动 n-1 个服务分别与其余节点建立连接;</li>
</ul>
</li>
<li>通过 Context 使用集合通信功能。</li>
</ul>
<h2 id="concepts"><a class="header" href="#concepts">Concepts</a></h2>
<p><strong>Device</strong></p>
<p>Device 是通信设备的抽象。</p>
<p><strong>Context</strong></p>
<p>Context 负责建立管理通信域。</p>
<p><strong>Store</strong> </p>
<p>Store 是实现 rendezvous 的介质，是实现共识的媒介。</p>
<p><strong>Address</strong> </p>
<p><code>gloo::transport::tcp::Address</code> 是对网络地址的封装。</p>
<p><strong>attr</strong></p>
<p><code>gloo::transport::tcp::attr</code> 是对网络通信属性的结构体封装，ip、网卡等信息。</p>
<h2 id="gloo-vs-mpi"><a class="header" href="#gloo-vs-mpi">Gloo v.s. MPI</a></h2>
<h2 id="more"><a class="header" href="#more">More</a></h2>
<p>ibverbs 是使用 IB(InfiniBand) 的 API.</p>
<h2 id="workflow-2"><a class="header" href="#workflow-2">Workflow</a></h2>
<pre><code class="language-cpp">int main(void) {

  // Device
  gloo::transport::tcp::attr attr;
  auto dev = gloo::transport::tcp::CreateDevice(attr);
  // Store
  auto fileStore = gloo::rendezvous::FileStore(&quot;/tmp&quot;);
  auto prefixStore = gloo::rendezvous::PrefixStore(prefix, fileStore);
  // Context
  auto context = std::make_shared&lt;gloo::rendezvous::Context&gt;(rank, size);

  context-&gt;connectFullMesh(prefixStore, dev);
}
</code></pre>
<pre><code class="language-cpp">// gloo/rendezvous/context.cc

void Context::connectFullMesh(
    rendezvous::Store&amp; store,
    std::shared_ptr&lt;transport::Device&gt;&amp; dev) {

  // localKey = 'rank_0'
  // value = 'host-0'
  store.set(localKey, value);
  for (int i = 0; i &lt; size; i++) {
    // i != rank
    auto val = store.get(key);
  }

  auto transportContext = dev-&gt;createContext(rank, size);
  for (int i = 0; i &lt; size; i++) {
    // i != rank
    auto&amp; pair = transportContext-&gt;createPair(i);
  }

  // '0'
  // [host-0]:9000[host-1]:9001
  store.set(storeKey.str(), allBytes);

  for (int i = 0; i &lt; size; i++) {
    // i != rank
    store.wait({key.str()}, getTimeout());
    auto allAddrs = store.get(key.str());
    auto addr = extractAddress(allAddrs, i);
    transportContext-&gt;getPair(i)-&gt;connect(addr);
  }
}

</code></pre>
<pre><code class="language-cpp">std::unique_ptr&lt;transport::Pair&gt;&amp; Context::createPair(int rank) {
  pairs_[rank] = std::unique_ptr&lt;transport::Pair&gt;(
      new tcp::Pair(this, device_.get(), rank, getTimeout()));
  return pairs_[rank];
}
</code></pre>
<p>创建 Pair 对象会在本地启动 tcp socket 服务。</p>
<pre><code class="language-cpp">// gloo/transport/tcp/pair.cc

Pair::Pair(
    Context* context,
    Device* device,
    int rank,
    std::chrono::milliseconds timeout) {
  listen();
}

void Pair::listen() {
  std::lock_guard&lt;std::mutex&gt; lock(m_);
  int rv;

  const auto&amp; attr = device_-&gt;attr_;
  auto fd = socket(attr.ai_family, attr.ai_socktype, attr.ai_protocol);
  rv = bind(fd, (const sockaddr*)&amp;attr.ai_addr, attr.ai_addrlen);
  fd_ = fd;
  rv = ::listen(fd_, 1);
  self_ = Address::fromSockName(fd);

  device_-&gt;registerDescriptor(fd_, EPOLLIN, this);

  return;
}
</code></pre>
<h2 id="reference-10"><a class="header" href="#reference-10">Reference</a></h2>
<ul>
<li><a href="https://github.com/facebookincubator/gloo">gloo</a></li>
<li><a href="https://github.com/ray-project/pygloo">pygloo</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="nccl"><a class="header" href="#nccl">nccl</a></h1>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<p>one device per process/thread 为常用模式</p>
<ol>
<li>ncclGetUniqueId 生成 ID,</li>
</ol>
<p>NCCL 建立通信域需要依赖共同的 nccl ID, 通常在 0 号节点上调用 ncclGetUniqueId API 生成 ID，
然后 broadcast 到所有节点上，这里 broadcast 的媒介 NCCL 并未提供方法，也没有限制。
可以通过 mpi、gloo、tcp 等方式在节点间同步。</p>
<pre><code class="language-cpp">ncclUniqueId id;
if (myRank == 0) ncclGetUniqueId(&amp;id);
</code></pre>
<ol start="2">
<li>ncclCommInitRank 建立通信域 </li>
</ol>
<p>NCCL 使用 (id, rank, size) 三元组建立通信域。</p>
<pre><code class="language-cpp">ncclComm_t comm;
ncclCommInitRank(&amp;comm, nRanks, id, myRank);
</code></pre>
<ol start="3">
<li>ncclAllReduce 使用 NCCL 通信</li>
</ol>
<p>通过建立好的通信域，可以调用 NCCL 提供的 API 进行集合通信。</p>
<pre><code class="language-cpp">ncclAllReduce( ... , comm);
</code></pre>
<ol start="4">
<li>ncclCommDestroy 销毁通信域</li>
</ol>
<p>使用 ncclCommDestroy API 销毁通信域，释放资源，另 ncclCommAbort 可用于标记释放通信域，实现容错等流程。</p>
<pre><code class="language-cpp">ncclCommDestroy(comm);
</code></pre>
<h2 id="api-4"><a class="header" href="#api-4">API</a></h2>
<p>重点使用的 API, 可以说是使用 NCCL 的目的就是使用这些 API 进行通信交换数据。</p>
<ul>
<li>Collective Communication Functions
<ul>
<li>ncclAllReduce</li>
<li>ncclBroadcast</li>
<li>ncclReduce</li>
<li>ncclAllGather</li>
<li>ncclReduceScatter</li>
</ul>
</li>
</ul>
<p>为了实现上述操作需要建立基本的连接等等操作，重点围绕通信域概念。</p>
<ul>
<li>Communicator Creation and Management Functions
<ul>
<li>ncclGetVersion</li>
<li>ncclGetUniqueId</li>
<li>ncclCommInitRank</li>
<li>ncclCommInitAll</li>
<li>ncclCommInitRankConfig</li>
<li>ncclCommDestroy</li>
<li>ncclCommAbort</li>
<li>ncclCommGetAsyncError</li>
<li>ncclCommCount</li>
<li>ncclCommCuDevice</li>
<li>ncclCommUserRank</li>
</ul>
</li>
</ul>
<p>为了讲述，进行如下定义，才有前述的操作。</p>
<ul>
<li>Types
<ul>
<li>ncclComm_t</li>
<li>ncclResult_t</li>
<li>ncclDataType_t</li>
<li>ncclRedOp_t</li>
<li>ncclConfig_t</li>
</ul>
</li>
</ul>
<p>为了高效和优化引入逻辑上的组概念。</p>
<ul>
<li>Group Calls
<ul>
<li>ncclGroupStart</li>
<li>ncclGroupEnd</li>
</ul>
</li>
</ul>
<p>引入点对点通信，可以实现比如 all-to-all 操作。</p>
<ul>
<li>Point To Point Communication Functions
<ul>
<li>ncclSend</li>
<li>ncclRecv</li>
</ul>
</li>
</ul>
<h2 id="workflow-3"><a class="header" href="#workflow-3">Workflow</a></h2>
<h3 id="ncclgetuniqueid"><a class="header" href="#ncclgetuniqueid">ncclGetUniqueId</a></h3>
<p>创建 <code>ncclGetUniqueId</code> 时会首先调用初始化函数 <code>ncclInit</code> 确认网络已经初始化, 然后调用 <code>bootstrapGetUniqueId</code> 创建 <code>ncclUniqueId</code>。</p>
<pre><code class="language-cpp">// nccl/src/init.cc

ncclResult_t ncclGetUniqueId(ncclUniqueId* out) {
  NCCLCHECK(ncclInit());
  return bootstrapGetUniqueId(out);
}
</code></pre>
<p><code>ncclInit</code> 分为两部分</p>
<ul>
<li><code>bootstrapNetInit</code> 调用 <code>ncclFindInterfaces</code> 完成获取 Interface 信息，赋值 <code>ncclSocketAddress bootstrapNetIfAddr</code></li>
<li><code>ncclNetPluginInit</code> 加载 net plugin</li>
</ul>
<pre><code class="language-cpp">// nccl/src/init.cc

static ncclResult_t ncclInit() {
  NCCLCHECK(bootstrapNetInit());
  NCCLCHECK(ncclNetPluginInit());
  return ncclSuccess;
}
</code></pre>
<p>从定义</p>
<pre><code class="language-cpp">#define NCCL_UNIQUE_ID_BYTES 128
typedef struct { char internal[NCCL_UNIQUE_ID_BYTES]; } ncclUniqueId;
</code></pre>
<p>可以看出 <code>ncclUniqueId</code> 就是 128 个 char 构成的 struct。</p>
<pre><code class="language-cpp">// nccl/src/bootstrap.cc  

static union socketAddress bootstrapNetIfAddr;

ncclResult_t bootstrapGetUniqueId(ncclUniqueId* id) {
  memset(id, 0, sizeof(ncclUniqueId));

  char* env = getenv(&quot;NCCL_COMM_ID&quot;);
  if (env) {
    if (ncclGetSocketAddrFromString(connectAddr, env) != ncclSuccess) {
      return ncclInvalidArgument;
    }
  } else {
    memcpy(id, &amp;bootstrapNetIfAddr, sizeof(union ncclSocketAddress));
    NCCLCHECK(bootstrapCreateRoot(id, false));
  }

  return ncclSuccess;
}
</code></pre>
<p>创建主节点监听线程，<code>ncclUniqueId</code> 的本质是 <code>socketAddress</code>，</p>
<pre><code class="language-cpp">ncclResult_t bootstrapCreateRoot(ncclUniqueId* id, bool idFromEnv) {
  union socketAddress* connectAddr = (union socketAddress*) id;
  int listenFd;
  NCCLCHECK(createListenSocket(&amp;listenFd, connectAddr));
  pthread_t thread;
  pthread_create(&amp;thread, NULL, bootstrapRoot, (void*)(uint64_t)listenFd);
  return ncclSuccess;
}
</code></pre>
<blockquote>
<p>使用 <code>NCCL_COMM_ID</code> 时，该函数在 <code>ncclCommInitRankDev</code> 里调用启动 root 上的 tcp 监听服务。</p>
</blockquote>
<h3 id="ncclcomminitrank"><a class="header" href="#ncclcomminitrank">ncclCommInitRank</a></h3>
<p><code>ncclCommInitRank</code> 初始化调用 <code>ncclCommInitRankDev</code> 完成初始化，包括</p>
<ul>
<li>如果使用 <code>NCCL_COMM_ID</code> 且 rank 为 0 则需要启动 root 服务；</li>
<li>确保已经 <code>ncclInit</code></li>
<li>调用 <code>ncclCommInitRankFunc</code> 初始化，主要调用 <code>initTransportsRank</code> 完成 <code>rendezvous</code>.</li>
</ul>
<pre><code class="language-cpp">// nccl/src/init.cc

ncclResult_t ncclCommInitRank(ncclComm_t* newcomm, int nranks, ncclUniqueId commId, int myrank) {
  NCCLCHECK(ncclCommInitRankDev(newcomm, nranks, commId, myrank, cudaDev, NULL));
  return ncclSuccess;
}

static ncclResult_t ncclCommInitRankDev(ncclComm_t* newcomm, int nranks, ncclUniqueId commId, int myrank, int cudaDev, ncclConfig_t *config) {
  char* env = getenv(&quot;NCCL_COMM_ID&quot;);
  if (env &amp;&amp; myrank == 0) {
    NCCLCHECKGOTO(bootstrapCreateRoot(&amp;commId, true), res, fail);
  }

  NCCLCHECKGOTO(ncclInit(), res, fail);

  struct ncclCommInitRankAsyncJob *job = NULL;
  NCCLCHECKGOTO(ncclAsyncLaunch(&amp;job-&gt;base, ncclCommInitRankFunc, NULL, free, comm), res, fail);

  return ncclGroupErrCheck(res);
}

static ncclResult_t ncclCommInitRankFunc(struct ncclAsyncJob* job_) {
  NCCLCHECKGOTO(initTransportsRank(*newcomm, &amp;commId), res, cleanup);

  comm-&gt;initState = ncclSuccess;
  return ncclSuccess;
}
</code></pre>
<p><code>initTransportsRank</code> 是初始化中最为复杂的部分，主要包括</p>
<ul>
<li>通过 bootstrapAllGather 把所有 peer 的信息收集在一起</li>
<li>计算 3 个 ncclTopoGraph: ring/tree/colnet </li>
<li>建立 p2p/ring/tree 等链接</li>
</ul>
<pre><code class="language-cpp">
static ncclResult_t initTransportsRank(struct ncclComm* comm, ncclUniqueId* commId) {
  // We use 2 AllGathers
  // 1. { peerInfo, comm, compCap}
  // 2. { nChannels, graphInfo, topoRanks }

  NCCLCHECK(bootstrapInit(commId, comm));

  NCCLCHECK(bootstrapAllGather(comm-&gt;bootstrap, comm-&gt;peerInfo, sizeof(struct ncclPeerInfo)));

  // Topo detection / System graph creation
  NCCLCHECK(ncclTopoGetSystem(comm, &amp;comm-&gt;topo));
  // Compute paths between GPUs and NICs
  NCCLCHECK(ncclTopoComputePaths(comm-&gt;topo, comm));
  // Remove inaccessible GPUs and unused NICs
  NCCLCHECK(ncclTopoTrimSystem(comm-&gt;topo, comm));
  // Recompute paths after trimming
  NCCLCHECK(ncclTopoComputePaths(comm-&gt;topo, comm));
  // Init search
  NCCLCHECK(ncclTopoSearchInit(comm-&gt;topo));
  // Print final topology
  NCCLCHECK(ncclTopoPrint(comm-&gt;topo));

  // Set Affinity to a CPU local the our GPU, so that all memory we allocate
  // on the host is local.
  NCCLCHECK(ncclTopoGetCpuAffinity(comm-&gt;topo, comm-&gt;rank, &amp;comm-&gt;cpuAffinity));

  // Launch proxy service thread
  NCCLCHECK(ncclProxyCreate(comm));

  // Get rings and trees
  struct ncclTopoGraph ringGraph;
  NCCLCHECK(ncclTopoCompute(comm-&gt;topo, &amp;ringGraph));
  NCCLCHECK(ncclTopoPrintGraph(comm-&gt;topo, &amp;ringGraph));

  struct ncclTopoGraph treeGraph;
  NCCLCHECK(ncclTopoCompute(comm-&gt;topo, &amp;treeGraph));
  NCCLCHECK(ncclTopoPrintGraph(comm-&gt;topo, &amp;treeGraph));

  struct ncclTopoGraph collNetGraph;
  NCCLCHECK(ncclTopoCompute(comm-&gt;topo, &amp;collNetGraph));
  NCCLCHECK(ncclTopoPrintGraph(comm-&gt;topo, &amp;collNetGraph));

  // Determine local CollNet support before all-gather

  // AllGather3 - begin
  struct ncclGraphInfo {
    int pattern;
    int nChannels;
    int sameChannels;
    float bwIntra;
    float bwInter;
    int typeIntra;
    int typeInter;
  };

  struct {
    int netDev;
    int collNetSupport;
    struct ncclGraphInfo tree;
    struct ncclGraphInfo ring;
    struct ncclGraphInfo collNet;
    struct ncclTopoRanks topoRanks;
  } *allGather3Data;

  NCCLCHECK(bootstrapAllGather(comm-&gt;bootstrap, allGather3Data, sizeof(*allGather3Data)));

  // Connect with prev/next for each ring
  for (int c=0; c&lt;comm-&gt;nChannels; c++) {
    NCCLCHECKGOTO(setupChannel(comm, c, rank, nranks, rings+c*nranks), ret, affinity_restore);
    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, &amp;channel-&gt;ring.prev, 1, &amp;channel-&gt;ring.next, 0), ret, affinity_restore);
  }
  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, &amp;ringGraph, 0), ret, affinity_restore);

  // Connect Trees
  for (int c=0; c&lt;comm-&gt;nChannels; c++) {
    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, NCCL_MAX_TREE_ARITY, channel-&gt;tree.down, 1, &amp;channel-&gt;tree.up, 0), ret, affinity_restore);
    NCCLCHECKGOTO(ncclTransportP2pConnect(comm, c, 1, &amp;channel-&gt;tree.up, NCCL_MAX_TREE_ARITY, channel-&gt;tree.down, 0), ret, affinity_restore);
  }
  NCCLCHECKGOTO(ncclTransportP2pSetup(comm, &amp;treeGraph, 0), ret, affinity_restore);

  // Compute nChannels per peer for p2p
  NCCLCHECK(ncclTopoComputeP2pChannels(comm));

  /* Local intra-node barrier */
  NCCLCHECK(bootstrapBarrier(comm-&gt;bootstrap, comm-&gt;localRankToRank, comm-&gt;localRank, comm-&gt;localRanks, comm-&gt;localRankToRank[0]));

  return ncclSuccess;
}
</code></pre>
<p>其中 <code>bootstrapInit</code> 和 <code>bootstrapAllGather</code> 完成建立 socket 和连接的操作。</p>
<pre><code class="language-cpp">// src/bootstrap.cc

ncclResult_t bootstrapInit(ncclUniqueId * id, struct ncclComm* comm) {
  // Create socket for other ranks to contact me
  NCCLCHECK(ncclSocketListen(&amp;state-&gt;listenSock));
  memcpy(&amp;info.extAddressListen, &amp;state-&gt;listenSock.addr, sizeof(union ncclSocketAddress));

  // Create socket for root to contact me
  NCCLCHECK(ncclSocketListen(&amp;listenSockRoot));
  memcpy(&amp;info.extAddressListenRoot, &amp;listenSockRoot.addr, sizeof(union ncclSocketAddress));

  // send info on my listening socket to root
  NCCLCHECK(ncclSocketConnect(&amp;sock));
  NCCLCHECK(bootstrapNetSend(&amp;sock, &amp;info, sizeof(info)));

  // get info on my &quot;next&quot; rank in the bootstrap ring from root
  NCCLCHECK(ncclSocketAccept(&amp;sock, &amp;listenSockRoot));
  NCCLCHECK(bootstrapNetRecv(&amp;sock, &amp;state-&gt;ringSendSocket.addr, sizeof(union ncclSocketAddress)));

  NCCLCHECK(ncclSocketConnect(&amp;state-&gt;ringSendSocket));
  // Accept the connect request from the previous rank in the AllGather ring
  NCCLCHECK(ncclSocketAccept(&amp;state-&gt;ringRecvSocket, &amp;state-&gt;listenSock));

  // AllGather all listen handlers
  NCCLCHECK(ncclCalloc(&amp;state-&gt;peerCommAddresses, nranks));
  memcpy(state-&gt;peerCommAddresses+rank, &amp;state-&gt;listenSock.addr, sizeof(union ncclSocketAddress));
  NCCLCHECK(bootstrapAllGather(state, state-&gt;peerCommAddresses, sizeof(union ncclSocketAddress)));

  // Create the service proxy
  NCCLCHECK(ncclCalloc(&amp;state-&gt;peerProxyAddresses, nranks));
  struct ncclSocket* proxySocket;
  NCCLCHECK(ncclCalloc(&amp;proxySocket, 1));
  NCCLCHECK(ncclSocketInit(proxySocket, &amp;bootstrapNetIfAddr, NULL, 0));
  NCCLCHECK(ncclSocketListen(proxySocket));
  memcpy(state-&gt;peerProxyAddresses+rank, &amp;proxySocket-&gt;addr, sizeof(union ncclSocketAddress));
  NCCLCHECK(bootstrapAllGather(state, state-&gt;peerProxyAddresses, sizeof(union ncclSocketAddress)));
  NCCLCHECK(ncclProxyInit(comm, proxySocket, state-&gt;peerProxyAddresses));

  return ncclSuccess;
}

ncclResult_t bootstrapAllGather(void* commState, void* allData, int size) {
  /* Simple ring based AllGather
   * At each step i receive data from (rank-i-1) from left
   * and send previous step's data from (rank-i) to right
   */
  for (int i=0; i&lt;nranks-1; i++) {
    size_t rslice = (rank - i - 1 + nranks) % nranks;
    size_t sslice = (rank - i + nranks) % nranks;

    // Send slice to the right
    NCCLCHECK(bootstrapNetSend(&amp;state-&gt;ringSendSocket, data+sslice*size, size));
    // Recv slice from the left
    NCCLCHECK(bootstrapNetRecv(&amp;state-&gt;ringRecvSocket, data+rslice*size, size));
  }

  return ncclSuccess;
}
</code></pre>
<h2 id="cuda-graph"><a class="header" href="#cuda-graph">Cuda Graph</a></h2>
<pre><code class="language-cpp">cudaGraph_t graph;
cudaStreamBeginCapture(stream);
kernel_A&lt;&lt;&lt; ..., stream &gt;&gt;&gt;(...);
kernel_B&lt;&lt;&lt; ..., stream &gt;&gt;&gt;(...);
ncclAllreduce(..., stream);
kernel_C&lt;&lt;&lt; ..., stream &gt;&gt;&gt;(...);
cudaStreamEndCapture(stream, &amp;graph);

cudaGraphExec_t instance;
cudaGraphInstantiate(&amp;instance, graph, NULL, NULL, 0);
cudaGraphLaunch(instance, stream);
cudaStreamSynchronize(stream);
</code></pre>
<pre><code class="language-cpp">bool graphCreated=false;
cudaGraph_t graph;
cudaGraphExec_t instance;
for(int istep=0; istep&lt;NSTEP; istep++){
  if(!graphCreated){
    cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal);
    for(int ikrnl=0; ikrnl&lt;NKERNEL; ikrnl++){
      shortKernel&lt;&lt;&lt;blocks, threads, 0, stream&gt;&gt;&gt;(out_d, in_d);
    }
    cudaStreamEndCapture(stream, &amp;graph);
    cudaGraphInstantiate(&amp;instance, graph, NULL, NULL, 0);
    graphCreated=true;
  }
  cudaGraphLaunch(instance, stream);
  cudaStreamSynchronize(stream);
}
</code></pre>
<h2 id="env"><a class="header" href="#env">ENV</a></h2>
<ul>
<li><code>NCCL_GRAPH_DUMP_FILE</code> 可以保存网络拓扑信息到文件</li>
</ul>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/examples.html">examples</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="mpi"><a class="header" href="#mpi">mpi</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="nlp"><a class="header" href="#nlp">nlp</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="transformer"><a class="header" href="#transformer">Transformer</a></h1>
<h2 id="bert"><a class="header" href="#bert">BERT</a></h2>
<h3 id="bertmodel"><a class="header" href="#bertmodel">BertModel</a></h3>
<pre><code class="language-python">class BertModel(BertPreTrainedModel):
    def __init__(self, config, add_pooling_layer=True):
        self.config = config

        self.embeddings = BertEmbeddings(config)
        self.encoder = BertEncoder(config)

        self.pooler = BertPooler(config) if add_pooling_layer else None

    def forward(self, ...):
        embedding_output = self.embeddings(
            input_ids=input_ids,
            position_ids=position_ids,
            token_type_ids=token_type_ids,
            inputs_embeds=inputs_embeds,
            past_key_values_length=past_key_values_length,
        )
        encoder_outputs = self.encoder(
            embedding_output,
            attention_mask=extended_attention_mask,
            head_mask=head_mask,
            encoder_hidden_states=encoder_hidden_states,
            encoder_attention_mask=encoder_extended_attention_mask,
            past_key_values=past_key_values,
            use_cache=use_cache,
            output_attentions=output_attentions,
            output_hidden_states=output_hidden_states,
            return_dict=return_dict,
        )
        sequence_output = encoder_outputs[0]
        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None

        return BaseModelOutputWithPoolingAndCrossAttentions(
            last_hidden_state=sequence_output,
            pooler_output=pooled_output,
            past_key_values=encoder_outputs.past_key_values,
            hidden_states=encoder_outputs.hidden_states,
            attentions=encoder_outputs.attentions,
            cross_attentions=encoder_outputs.cross_attentions,
        )
</code></pre>
<h3 id="bertembeddings"><a class="header" href="#bertembeddings">BertEmbeddings</a></h3>
<pre><code class="language-python"># src/transformers/models/bert/modeling_bert.py

class BertEmbeddings(nn.Module):

    def __init__(self, config):
        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)
        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)
        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)

        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)
        self.dropout = nn.Dropout(config.hidden_dropout_prob)

    def forward(self, ...):
        inputs_embeds = self.word_embeddings(input_ids)
        token_type_embeddings = self.token_type_embeddings(token_type_ids)
        position_embeddings = self.position_embeddings(position_ids) # absolute
        embeddings = inputs_embeds + token_type_embeddings + position_embeddings
        embeddings = self.LayerNorm(embeddings)
        embeddings = self.dropout(embeddings)
        return embeddings
</code></pre>
<h3 id="bertencoder"><a class="header" href="#bertencoder">BertEncoder</a></h3>
<pre><code class="language-python">
class BertEncoder(nn.Module):
    def __init__(self, config):
        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])

    def forward(self, ...):
        for i, layer_module in enumerate(self.layer):
            if output_hidden_states:
                all_hidden_states = all_hidden_states + (hidden_states,)

            layer_head_mask = head_mask[i] if head_mask is not None else None
            past_key_value = past_key_values[i] if past_key_values is not None else None

            if self.gradient_checkpointing and self.training:

                if use_cache:
                    logger.warning(
                        &quot;`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...&quot;
                    )
                    use_cache = False

                def create_custom_forward(module):
                    def custom_forward(*inputs):
                        return module(*inputs, past_key_value, output_attentions)

                    return custom_forward

                layer_outputs = torch.utils.checkpoint.checkpoint(
                    create_custom_forward(layer_module),
                    hidden_states,
                    attention_mask,
                    layer_head_mask,
                    encoder_hidden_states,
                    encoder_attention_mask,
                )
            else:
                layer_outputs = layer_module(
                    hidden_states,
                    attention_mask,
                    layer_head_mask,
                    encoder_hidden_states,
                    encoder_attention_mask,
                    past_key_value,
                    output_attentions,
                )

            hidden_states = layer_outputs[0]
            if use_cache:
                next_decoder_cache += (layer_outputs[-1],)
            if output_attentions:
                all_self_attentions = all_self_attentions + (layer_outputs[1],)
                if self.config.add_cross_attention:
                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)

        if output_hidden_states:
            all_hidden_states = all_hidden_states + (hidden_states,)

        if not return_dict:
            return tuple(
                v
                for v in [
                    hidden_states,
                    next_decoder_cache,
                    all_hidden_states,
                    all_self_attentions,
                    all_cross_attentions,
                ]
                if v is not None
            )
        return BaseModelOutputWithPastAndCrossAttentions(
            last_hidden_state=hidden_states,
            past_key_values=next_decoder_cache,
            hidden_states=all_hidden_states,
            attentions=all_self_attentions,
            cross_attentions=all_cross_attentions,
        )


class BertPooler(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.hidden_size)
        self.activation = nn.Tanh()

    def forward(self, hidden_states: torch.Tensor) -&gt; torch.Tensor:
        # We &quot;pool&quot; the model by simply taking the hidden state corresponding
        # to the first token.
        first_token_tensor = hidden_states[:, 0]
        pooled_output = self.dense(first_token_tensor)
        pooled_output = self.activation(pooled_output)
        return pooled_output



```python
from transformers import BertTokenizer, BertModel
tokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)
model = BertModel.from_pretrained(&quot;bert-base-uncased&quot;)
</code></pre>
<pre><code class="language-python">&gt;&gt;&gt; model.config
BertConfig {
  &quot;_name_or_path&quot;: &quot;bert-base-uncased&quot;,
  &quot;architectures&quot;: [
    &quot;BertForMaskedLM&quot;
  ],
  &quot;attention_probs_dropout_prob&quot;: 0.1,
  &quot;classifier_dropout&quot;: null,
  &quot;gradient_checkpointing&quot;: false,
  &quot;hidden_act&quot;: &quot;gelu&quot;,
  &quot;hidden_dropout_prob&quot;: 0.1,
  &quot;hidden_size&quot;: 768,
  &quot;initializer_range&quot;: 0.02,
  &quot;intermediate_size&quot;: 3072,
  &quot;layer_norm_eps&quot;: 1e-12,
  &quot;max_position_embeddings&quot;: 512,
  &quot;model_type&quot;: &quot;bert&quot;,
  &quot;num_attention_heads&quot;: 12,
  &quot;num_hidden_layers&quot;: 12,
  &quot;pad_token_id&quot;: 0,
  &quot;position_embedding_type&quot;: &quot;absolute&quot;,
  &quot;transformers_version&quot;: &quot;4.22.2&quot;,
  &quot;type_vocab_size&quot;: 2,
  &quot;use_cache&quot;: true,
  &quot;vocab_size&quot;: 30522
}

</code></pre>
<pre><code class="language-python">&gt;&gt;&gt; model.eval()
BertModel(
  (embeddings): BertEmbeddings(
    (word_embeddings): Embedding(30522, 768, padding_idx=0)
    (position_embeddings): Embedding(512, 768)
    (token_type_embeddings): Embedding(2, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): BertEncoder(
    (layer): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      ...
      (11): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): BertPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
</code></pre>
<h2 id="t5"><a class="header" href="#t5">T5</a></h2>
<pre><code class="language-python">from transformers import T5Tokenizer, T5Model
model = T5Model.from_pretrained(&quot;t5-small&quot;)
</code></pre>
<pre><code class="language-python">&gt;&gt;&gt; model.config
T5Config {
  &quot;_name_or_path&quot;: &quot;t5-small&quot;,
  &quot;architectures&quot;: [
    &quot;T5WithLMHeadModel&quot;
  ],
  &quot;d_ff&quot;: 2048,
  &quot;d_kv&quot;: 64,
  &quot;d_model&quot;: 512,
  &quot;decoder_start_token_id&quot;: 0,
  &quot;dense_act_fn&quot;: &quot;relu&quot;,
  &quot;dropout_rate&quot;: 0.1,
  &quot;eos_token_id&quot;: 1,
  &quot;feed_forward_proj&quot;: &quot;relu&quot;,
  &quot;initializer_factor&quot;: 1.0,
  &quot;is_encoder_decoder&quot;: true,
  &quot;is_gated_act&quot;: false,
  &quot;layer_norm_epsilon&quot;: 1e-06,
  &quot;model_type&quot;: &quot;t5&quot;,
  &quot;n_positions&quot;: 512,
  &quot;num_decoder_layers&quot;: 6,
  &quot;num_heads&quot;: 8,
  &quot;num_layers&quot;: 6,
  &quot;output_past&quot;: true,
  &quot;pad_token_id&quot;: 0,
  &quot;relative_attention_max_distance&quot;: 128,
  &quot;relative_attention_num_buckets&quot;: 32,
  &quot;task_specific_params&quot;: {
    &quot;summarization&quot;: {
      &quot;early_stopping&quot;: true,
      &quot;length_penalty&quot;: 2.0,
      &quot;max_length&quot;: 200,
      &quot;min_length&quot;: 30,
      &quot;no_repeat_ngram_size&quot;: 3,
      &quot;num_beams&quot;: 4,
      &quot;prefix&quot;: &quot;summarize: &quot;
    },
    &quot;translation_en_to_de&quot;: {
      &quot;early_stopping&quot;: true,
      &quot;max_length&quot;: 300,
      &quot;num_beams&quot;: 4,
      &quot;prefix&quot;: &quot;translate English to German: &quot;
    },
    &quot;translation_en_to_fr&quot;: {
      &quot;early_stopping&quot;: true,
      &quot;max_length&quot;: 300,
      &quot;num_beams&quot;: 4,
      &quot;prefix&quot;: &quot;translate English to French: &quot;
    },
    &quot;translation_en_to_ro&quot;: {
      &quot;early_stopping&quot;: true,
      &quot;max_length&quot;: 300,
      &quot;num_beams&quot;: 4,
      &quot;prefix&quot;: &quot;translate English to Romanian: &quot;
    }
  },
  &quot;transformers_version&quot;: &quot;4.22.2&quot;,
  &quot;use_cache&quot;: true,
  &quot;vocab_size&quot;: 32128
}
</code></pre>
<pre><code class="language-python">&gt;&gt;&gt; model.eval()
T5Model(
  (shared): Embedding(32128, 512)
  (encoder): T5Stack(
    (embed_tokens): Embedding(32128, 512)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=512, out_features=512, bias=False)
              (k): Linear(in_features=512, out_features=512, bias=False)
              (v): Linear(in_features=512, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=512, bias=False)
              (relative_attention_bias): Embedding(32, 8)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=512, out_features=2048, bias=False)
              (wo): Linear(in_features=2048, out_features=512, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      ...
      (5): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=512, out_features=512, bias=False)
              (k): Linear(in_features=512, out_features=512, bias=False)
              (v): Linear(in_features=512, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=512, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=512, out_features=2048, bias=False)
              (wo): Linear(in_features=2048, out_features=512, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (decoder): T5Stack(
    (embed_tokens): Embedding(32128, 512)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=512, out_features=512, bias=False)
              (k): Linear(in_features=512, out_features=512, bias=False)
              (v): Linear(in_features=512, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=512, bias=False)
              (relative_attention_bias): Embedding(32, 8)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=512, out_features=512, bias=False)
              (k): Linear(in_features=512, out_features=512, bias=False)
              (v): Linear(in_features=512, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=512, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=512, out_features=2048, bias=False)
              (wo): Linear(in_features=2048, out_features=512, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      ...
      (5): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=512, out_features=512, bias=False)
              (k): Linear(in_features=512, out_features=512, bias=False)
              (v): Linear(in_features=512, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=512, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=512, out_features=512, bias=False)
              (k): Linear(in_features=512, out_features=512, bias=False)
              (v): Linear(in_features=512, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=512, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=512, out_features=2048, bias=False)
              (wo): Linear(in_features=2048, out_features=512, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
</code></pre>
<pre><code class="language-python">model = T5ForConditionalGeneration.from_pretrained(&quot;t5-small&quot;)
&gt;&gt;&gt; model.config
# same as T5Model
&gt;&gt;&gt; model.eval()
T5ForConditionalGeneration(
  ...
  (lm_head): Linear(in_features=512, out_features=32128, bias=False)
)
</code></pre>
<h2 id="gpt"><a class="header" href="#gpt">GPT</a></h2>
<pre><code class="language-python">model = OpenAIGPTModel.from_pretrained(&quot;openai-gpt&quot;)
&gt;&gt;&gt; model.config
OpenAIGPTConfig {
  &quot;_name_or_path&quot;: &quot;openai-gpt&quot;,
  &quot;afn&quot;: &quot;gelu&quot;,
  &quot;architectures&quot;: [
    &quot;OpenAIGPTLMHeadModel&quot;
  ],
  &quot;attn_pdrop&quot;: 0.1,
  &quot;embd_pdrop&quot;: 0.1,
  &quot;initializer_range&quot;: 0.02,
  &quot;layer_norm_epsilon&quot;: 1e-05,
  &quot;model_type&quot;: &quot;openai-gpt&quot;,
  &quot;n_ctx&quot;: 512,
  &quot;n_embd&quot;: 768,
  &quot;n_head&quot;: 12,
  &quot;n_layer&quot;: 12,
  &quot;n_positions&quot;: 512,
  &quot;n_special&quot;: 0,
  &quot;predict_special_tokens&quot;: true,
  &quot;resid_pdrop&quot;: 0.1,
  &quot;summary_activation&quot;: null,
  &quot;summary_first_dropout&quot;: 0.1,
  &quot;summary_proj_to_labels&quot;: true,
  &quot;summary_type&quot;: &quot;cls_index&quot;,
  &quot;summary_use_proj&quot;: true,
  &quot;task_specific_params&quot;: {
    &quot;text-generation&quot;: {
      &quot;do_sample&quot;: true,
      &quot;max_length&quot;: 50
    }
  },
  &quot;transformers_version&quot;: &quot;4.22.2&quot;,
  &quot;vocab_size&quot;: 40478
}
</code></pre>
<pre><code>OpenAIGPTModel(
  (tokens_embed): Embedding(40478, 768)
  (positions_embed): Embedding(512, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    ...
    (11): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
)
</code></pre>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><a href="https://huggingface.co/docs/transformers/model_doc/bert">huggingface bert doc</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
